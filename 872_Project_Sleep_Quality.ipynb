{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "04hQGyQF-uqL",
        "N1qhRnIs8lCe",
        "_KsAEojJyoZt",
        "0gqkxCVFzCh2",
        "SZeqBcdlw4et",
        "XT6dOZmT9QbP",
        "NqjdL3x89dan",
        "tmgG1XmW9s_K",
        "TNMCvIb_9ycl",
        "ghTkfGHo-TXH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ELEC 872 Project\n",
        "\n",
        "- Dustin Pulver 20106164 \n",
        "- Dean Sacoransky 20112296\n",
        "\n",
        "\n",
        "All Libraries used in this assignment are displayed in the cell below. Running the below cell should be all the is required to properly install these libraries into this environment.\n",
        "\n",
        "\n",
        "The github https://github.com/RossiAlessio/MMASH will need to be cloned to your local setup. The helper fucniton create_dataset was used from this github. Next you will need to visit https://physionet.org/content/mmash/1.0.0/ to download the dataset which can be found at the bottom on the webpage. Once the zip is extracted uou will get a folder named DataPaper.The path in the helper fucniton '/content/gdrive/MyDrive/872-Project/DataPaper/' will need to be reaplacede with your local path to the folder DataPaper. This path also appears in a few cells below just before displaying the users, you will need to replace this path with your local path. \n"
      ],
      "metadata": {
        "id": "o0tdotoi-1kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and Helper Funcitons "
      ],
      "metadata": {
        "id": "04hQGyQF-uqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbOzc8BPjk2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d018021-c650-4bf4-87d1-b77adc8dd863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "metadata": {
        "id": "eVTV_60DssyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ_s3-aI50oD",
        "outputId": "7c8d26d3-18ee-427f-984a-b8d32b813700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from pprint import pprint\n",
        "from sklearn import tree, svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from numpy.linalg import norm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob\n",
        "import datetime \n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from skopt.space import Real, Categorical, Integer"
      ],
      "metadata": {
        "id": "uy_camjpj8zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/872-Project/DataPaper/'"
      ],
      "metadata": {
        "id": "9XHGnQaokDoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users = os.listdir(path)[:-1] #access user folders directory \n",
        "users"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaU1WljQOOWw",
        "outputId": "1c74db99-6c86-4673-9375-f34b351343ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user_12',\n",
              " 'user_2',\n",
              " 'user_22',\n",
              " 'user_15',\n",
              " 'user_1',\n",
              " 'user_13',\n",
              " 'user_3',\n",
              " 'user_5',\n",
              " 'user_4',\n",
              " 'user_14',\n",
              " 'user_11',\n",
              " 'user_7',\n",
              " 'user_17',\n",
              " 'user_21',\n",
              " 'user_6',\n",
              " 'user_16',\n",
              " 'user_10',\n",
              " 'user_19',\n",
              " 'user_8',\n",
              " 'user_9',\n",
              " 'user_18']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(users,file_name,replace_na=True):\n",
        "    \"\"\"\n",
        "    Returns MMASH datafarame.\n",
        "    Parameters\n",
        "    ---------\n",
        "    nn_intervals : list\n",
        "        List of Normal to Normal Interval.\n",
        "    Returns\n",
        "    ---------\n",
        "    nni_tmstp : list\n",
        "        list of time intervals between first NN-interval and final NN-interval.\n",
        "    \"\"\"\n",
        "    import pandas\n",
        "    import numpy\n",
        "    \n",
        "    df_concat = pandas.DataFrame()\n",
        "    for user in users:\n",
        "        try:\n",
        "            df = pandas.read_csv('/content/gdrive/MyDrive/872-Project/DataPaper/%s/%s.csv'%(user,file_name))\n",
        "            df['user'] = user\n",
        "            df_concat = pandas.concat([df_concat,df])\n",
        "        except:\n",
        "            print('NO data for %s'%user)\n",
        "            pass\n",
        "    \n",
        "    del df_concat['Unnamed: 0']\n",
        "    df_concat = df_concat.set_index('user')\n",
        "\n",
        "    if replace_na == True:\n",
        "        df_concat = df_concat.replace(0,numpy.nan)\n",
        "\n",
        "    return(df_concat)"
      ],
      "metadata": {
        "id": "4DYeaW5oSs2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_info = create_dataset(users,'user_info')\n",
        "user_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "Bq4DIh8GZryU",
        "outputId": "b2928958-4300-4dfc-fa0c-cace9bae0d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Gender  Weight  Height   Age\n",
              "user                                \n",
              "user_12      M      67     170  27.0\n",
              "user_2       M      95     183  27.0\n",
              "user_22      M      92     205  32.0\n",
              "user_15      M      80     180  24.0\n",
              "user_1       M      65     169  29.0\n",
              "user_13      M      74     180  25.0\n",
              "user_3       M      70     174  34.0\n",
              "user_5       M      80     196  25.0\n",
              "user_4       M      76     180  27.0\n",
              "user_14      M      64     171  27.0\n",
              "user_11      M     115     186  27.0\n",
              "user_7       M      65     183  25.0\n",
              "user_17      M      60     175  24.0\n",
              "user_21      M      70     175  28.0\n",
              "user_6       M      62     178  27.0\n",
              "user_16      M      67     176  27.0\n",
              "user_10      M      85     180  27.0\n",
              "user_19      M      70     183  22.0\n",
              "user_8       M      74     184  40.0\n",
              "user_9       M      70     175  20.0\n",
              "user_18      M      80     180   NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cec53d0-dd38-449c-be59-02d89b64038c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>M</td>\n",
              "      <td>67</td>\n",
              "      <td>170</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>M</td>\n",
              "      <td>95</td>\n",
              "      <td>183</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>M</td>\n",
              "      <td>92</td>\n",
              "      <td>205</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>M</td>\n",
              "      <td>80</td>\n",
              "      <td>180</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>M</td>\n",
              "      <td>65</td>\n",
              "      <td>169</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>M</td>\n",
              "      <td>74</td>\n",
              "      <td>180</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>M</td>\n",
              "      <td>70</td>\n",
              "      <td>174</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>M</td>\n",
              "      <td>80</td>\n",
              "      <td>196</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>M</td>\n",
              "      <td>76</td>\n",
              "      <td>180</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>M</td>\n",
              "      <td>64</td>\n",
              "      <td>171</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_11</th>\n",
              "      <td>M</td>\n",
              "      <td>115</td>\n",
              "      <td>186</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>M</td>\n",
              "      <td>65</td>\n",
              "      <td>183</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>M</td>\n",
              "      <td>60</td>\n",
              "      <td>175</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>M</td>\n",
              "      <td>70</td>\n",
              "      <td>175</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>M</td>\n",
              "      <td>62</td>\n",
              "      <td>178</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>M</td>\n",
              "      <td>67</td>\n",
              "      <td>176</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>M</td>\n",
              "      <td>85</td>\n",
              "      <td>180</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>M</td>\n",
              "      <td>70</td>\n",
              "      <td>183</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>M</td>\n",
              "      <td>74</td>\n",
              "      <td>184</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>M</td>\n",
              "      <td>70</td>\n",
              "      <td>175</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>M</td>\n",
              "      <td>80</td>\n",
              "      <td>180</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cec53d0-dd38-449c-be59-02d89b64038c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cec53d0-dd38-449c-be59-02d89b64038c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cec53d0-dd38-449c-be59-02d89b64038c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actigraph"
      ],
      "metadata": {
        "id": "N1qhRnIs8lCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actigraph info is a good description of daily activity. Can be used as input to predict sleep quality, psych characteristics"
      ],
      "metadata": {
        "id": "C8QhsHhQWKM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actigraph = create_dataset(users,'Actigraph')\n",
        "actigraph "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "B4mrJbySkVh6",
        "outputId": "a5d6fada-fff5-41ae-e433-92208780021f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Axis1  Axis2  Axis3  Steps    HR  Inclinometer Off  \\\n",
              "user                                                          \n",
              "user_12  190.0   87.0  144.0    NaN  73.0               NaN   \n",
              "user_12   41.0  149.0  108.0    1.0  73.0               NaN   \n",
              "user_12   19.0  176.0   54.0    1.0  74.0               NaN   \n",
              "user_12  189.0  261.0  150.0    1.0  74.0               NaN   \n",
              "user_12  185.0  371.0  109.0    NaN  74.0               NaN   \n",
              "...        ...    ...    ...    ...   ...               ...   \n",
              "user_18    NaN    NaN    NaN    NaN  87.0               NaN   \n",
              "user_18    NaN    NaN    NaN    NaN  87.0               NaN   \n",
              "user_18    NaN    NaN    NaN    NaN  87.0               NaN   \n",
              "user_18    NaN    NaN    NaN    NaN  87.0               NaN   \n",
              "user_18    NaN    NaN    NaN    NaN  87.0               NaN   \n",
              "\n",
              "         Inclinometer Standing  Inclinometer Sitting  Inclinometer Lying  \\\n",
              "user                                                                       \n",
              "user_12                    1.0                   NaN                 NaN   \n",
              "user_12                    1.0                   NaN                 NaN   \n",
              "user_12                    1.0                   NaN                 NaN   \n",
              "user_12                    1.0                   NaN                 NaN   \n",
              "user_12                    1.0                   NaN                 NaN   \n",
              "...                        ...                   ...                 ...   \n",
              "user_18                    NaN                   NaN                 1.0   \n",
              "user_18                    NaN                   NaN                 1.0   \n",
              "user_18                    NaN                   NaN                 1.0   \n",
              "user_18                    NaN                   NaN                 1.0   \n",
              "user_18                    NaN                   NaN                 1.0   \n",
              "\n",
              "         Vector Magnitude  day      time  \n",
              "user                                      \n",
              "user_12            253.78    1  09:26:09  \n",
              "user_12            188.54    1  09:26:10  \n",
              "user_12            185.08    1  09:26:11  \n",
              "user_12            355.45    1  09:26:12  \n",
              "user_12            428.66    1  09:26:13  \n",
              "...                   ...  ...       ...  \n",
              "user_18               NaN    2  09:18:34  \n",
              "user_18               NaN    2  09:18:35  \n",
              "user_18               NaN    2  09:18:36  \n",
              "user_18               NaN    2  09:18:37  \n",
              "user_18               NaN    2  09:18:38  \n",
              "\n",
              "[1397938 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac3e2d1a-995a-4c6d-9bcc-29e4e105ed80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Axis1</th>\n",
              "      <th>Axis2</th>\n",
              "      <th>Axis3</th>\n",
              "      <th>Steps</th>\n",
              "      <th>HR</th>\n",
              "      <th>Inclinometer Off</th>\n",
              "      <th>Inclinometer Standing</th>\n",
              "      <th>Inclinometer Sitting</th>\n",
              "      <th>Inclinometer Lying</th>\n",
              "      <th>Vector Magnitude</th>\n",
              "      <th>day</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>190.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>253.78</td>\n",
              "      <td>1</td>\n",
              "      <td>09:26:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>41.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>188.54</td>\n",
              "      <td>1</td>\n",
              "      <td>09:26:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>19.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>185.08</td>\n",
              "      <td>1</td>\n",
              "      <td>09:26:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>189.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>355.45</td>\n",
              "      <td>1</td>\n",
              "      <td>09:26:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>185.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>428.66</td>\n",
              "      <td>1</td>\n",
              "      <td>09:26:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>09:18:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>09:18:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>09:18:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>09:18:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>09:18:38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1397938 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac3e2d1a-995a-4c6d-9bcc-29e4e105ed80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac3e2d1a-995a-4c6d-9bcc-29e4e105ed80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac3e2d1a-995a-4c6d-9bcc-29e4e105ed80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sleep\n"
      ],
      "metadata": {
        "id": "_KsAEojJyoZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what paper used\n",
        "\n",
        "# time when they went to bed \n",
        "# time got out of bed \n",
        "# the time to fall asleep \n",
        "# the time needed to fall asleep \n",
        "# total sleeping time \n",
        "# time in bed \n",
        "# Ratio between total sleep and total in-bed time \n",
        "# time spent awake after falling asleep for the frist time \n",
        "# the number of awakenings\n",
        "# awakening in minutes\n",
        "# time without/with movements\n",
        "# ratio between movement and fragmentation indices"
      ],
      "metadata": {
        "id": "ggdNO9jgyPFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sleep  = create_dataset(users,'sleep')\n",
        "sleep\n",
        "\n",
        "# TST = sleep['Total Sleep Time (TST)']\n",
        "# TST= TST.drop(index=['user_21'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "tkU7qzlyynYn",
        "outputId": "9cf39337-646c-4db4-f79a-e33eca7919e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         In Bed Date In Bed Time  Out Bed Date Out Bed Time  Onset Date  \\\n",
              "user                                                                      \n",
              "user_12            2       00:32             2        06:36           2   \n",
              "user_2             2       00:50             2        06:22           2   \n",
              "user_22            2       01:06             2        07:04           2   \n",
              "user_15            2       01:15             2        05:39           2   \n",
              "user_1             2       00:46             2        03:31           2   \n",
              "user_1             2       03:57             2        07:30           2   \n",
              "user_13            1       23:41             1        05:04           1   \n",
              "user_3             1       22:29             1        05:52           1   \n",
              "user_5             1       23:56             1        06:42           1   \n",
              "user_4             2       00:57             2        07:10           2   \n",
              "user_14            2       00:08             2        07:00           2   \n",
              "user_7             2       00:28             2        08:02           2   \n",
              "user_17            2       00:44             2        06:36           2   \n",
              "user_21            2       02:19             2        07:16           2   \n",
              "user_6             2       02:27             2        09:02           2   \n",
              "user_16            2       00:22             2        07:58           2   \n",
              "user_10            2       02:40             2        08:09           2   \n",
              "user_19            1       22:56             1        06:35           1   \n",
              "user_8             2       00:17             2        07:13           2   \n",
              "user_9             2       00:30             2        11:00           2   \n",
              "user_18            2       00:55             2        06:53           2   \n",
              "\n",
              "        Onset Time  Latency  Efficiency  Total Minutes in Bed  \\\n",
              "user                                                            \n",
              "user_12      00:32      NaN       94.23                   364   \n",
              "user_2       00:54      4.0       73.49                   332   \n",
              "user_22      01:09      3.0       84.92                   358   \n",
              "user_15      01:16      1.0       89.39                   264   \n",
              "user_1       00:46      NaN       87.27                   165   \n",
              "user_1       03:57      NaN       92.02                   213   \n",
              "user_13      23:41      NaN       76.47                   323   \n",
              "user_3       22:32      3.0       79.23                   443   \n",
              "user_5       23:56      NaN       85.71                   406   \n",
              "user_4       01:01      4.0       85.52                   373   \n",
              "user_14      00:08      NaN       90.78                   412   \n",
              "user_7       00:28      NaN       75.33                   454   \n",
              "user_17      00:44      NaN       86.93                   352   \n",
              "user_21      02:19      NaN       91.92                   297   \n",
              "user_6       02:27      NaN       84.30                   395   \n",
              "user_16      00:26      4.0       74.34                   456   \n",
              "user_10      02:44      4.0       75.08                   329   \n",
              "user_19      22:57      1.0       74.07                   459   \n",
              "user_8       00:20      3.0       80.77                   416   \n",
              "user_9       00:33      3.0       91.75                   630   \n",
              "user_18      00:58      3.0       84.36                   358   \n",
              "\n",
              "         Total Sleep Time (TST)  Wake After Sleep Onset (WASO)  \\\n",
              "user                                                             \n",
              "user_12                     343                             21   \n",
              "user_2                      244                             84   \n",
              "user_22                     304                             51   \n",
              "user_15                     236                             27   \n",
              "user_1                      144                             21   \n",
              "user_1                      196                             17   \n",
              "user_13                     247                             76   \n",
              "user_3                      351                             89   \n",
              "user_5                      348                             58   \n",
              "user_4                      319                             50   \n",
              "user_14                     374                             38   \n",
              "user_7                      342                            112   \n",
              "user_17                     306                             46   \n",
              "user_21                     273                             24   \n",
              "user_6                      333                             62   \n",
              "user_16                     339                            113   \n",
              "user_10                     247                             78   \n",
              "user_19                     340                            118   \n",
              "user_8                      336                             77   \n",
              "user_9                      578                             49   \n",
              "user_18                     302                             53   \n",
              "\n",
              "         Number of Awakenings  Average Awakening Length  Movement Index  \\\n",
              "user                                                                      \n",
              "user_12                    12                      1.75           9.066   \n",
              "user_2                     18                      4.67          15.060   \n",
              "user_22                    21                      2.43          14.804   \n",
              "user_15                    15                      1.80          18.561   \n",
              "user_1                      9                      2.33           9.091   \n",
              "user_1                      9                      1.89           8.920   \n",
              "user_13                    19                      4.00          17.957   \n",
              "user_3                     16                      5.56          18.962   \n",
              "user_5                     21                      2.76          11.576   \n",
              "user_4                     28                      1.79           8.847   \n",
              "user_14                    19                      2.00          11.408   \n",
              "user_7                     31                      3.61          17.401   \n",
              "user_17                    20                      2.30           9.375   \n",
              "user_21                    18                      1.33           6.734   \n",
              "user_6                     20                      3.10          10.633   \n",
              "user_16                    39                      2.90          16.228   \n",
              "user_10                    13                      6.00          20.669   \n",
              "user_19                    44                      2.68          18.954   \n",
              "user_8                     27                      2.85          17.308   \n",
              "user_9                      4                     12.25           8.095   \n",
              "user_18                     9                      5.89          16.480   \n",
              "\n",
              "         Fragmentation Index  Sleep Fragmentation Index  \n",
              "user                                                     \n",
              "user_12               15.385                     24.451  \n",
              "user_2                 5.556                     20.616  \n",
              "user_22               13.636                     28.440  \n",
              "user_15                  NaN                     18.561  \n",
              "user_1                10.000                     19.091  \n",
              "user_1                   NaN                      8.920  \n",
              "user_13               15.789                     33.746  \n",
              "user_3                   NaN                     18.962  \n",
              "user_5                 9.524                     21.100  \n",
              "user_4                14.286                     23.133  \n",
              "user_14                  NaN                     11.408  \n",
              "user_7                28.125                     45.526  \n",
              "user_17               19.048                     28.423  \n",
              "user_21                  NaN                      6.734  \n",
              "user_6                 4.762                     15.395  \n",
              "user_16               15.385                     31.613  \n",
              "user_10                7.692                     28.361  \n",
              "user_19               22.222                     41.176  \n",
              "user_8                25.926                     43.234  \n",
              "user_9                   NaN                      8.095  \n",
              "user_18               20.000                     36.480  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b88645a0-c36b-4cdd-a237-06094ecf75a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>In Bed Date</th>\n",
              "      <th>In Bed Time</th>\n",
              "      <th>Out Bed Date</th>\n",
              "      <th>Out Bed Time</th>\n",
              "      <th>Onset Date</th>\n",
              "      <th>Onset Time</th>\n",
              "      <th>Latency</th>\n",
              "      <th>Efficiency</th>\n",
              "      <th>Total Minutes in Bed</th>\n",
              "      <th>Total Sleep Time (TST)</th>\n",
              "      <th>Wake After Sleep Onset (WASO)</th>\n",
              "      <th>Number of Awakenings</th>\n",
              "      <th>Average Awakening Length</th>\n",
              "      <th>Movement Index</th>\n",
              "      <th>Fragmentation Index</th>\n",
              "      <th>Sleep Fragmentation Index</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>2</td>\n",
              "      <td>00:32</td>\n",
              "      <td>2</td>\n",
              "      <td>06:36</td>\n",
              "      <td>2</td>\n",
              "      <td>00:32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94.23</td>\n",
              "      <td>364</td>\n",
              "      <td>343</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>1.75</td>\n",
              "      <td>9.066</td>\n",
              "      <td>15.385</td>\n",
              "      <td>24.451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>2</td>\n",
              "      <td>00:50</td>\n",
              "      <td>2</td>\n",
              "      <td>06:22</td>\n",
              "      <td>2</td>\n",
              "      <td>00:54</td>\n",
              "      <td>4.0</td>\n",
              "      <td>73.49</td>\n",
              "      <td>332</td>\n",
              "      <td>244</td>\n",
              "      <td>84</td>\n",
              "      <td>18</td>\n",
              "      <td>4.67</td>\n",
              "      <td>15.060</td>\n",
              "      <td>5.556</td>\n",
              "      <td>20.616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>2</td>\n",
              "      <td>01:06</td>\n",
              "      <td>2</td>\n",
              "      <td>07:04</td>\n",
              "      <td>2</td>\n",
              "      <td>01:09</td>\n",
              "      <td>3.0</td>\n",
              "      <td>84.92</td>\n",
              "      <td>358</td>\n",
              "      <td>304</td>\n",
              "      <td>51</td>\n",
              "      <td>21</td>\n",
              "      <td>2.43</td>\n",
              "      <td>14.804</td>\n",
              "      <td>13.636</td>\n",
              "      <td>28.440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>2</td>\n",
              "      <td>01:15</td>\n",
              "      <td>2</td>\n",
              "      <td>05:39</td>\n",
              "      <td>2</td>\n",
              "      <td>01:16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.39</td>\n",
              "      <td>264</td>\n",
              "      <td>236</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>1.80</td>\n",
              "      <td>18.561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>2</td>\n",
              "      <td>00:46</td>\n",
              "      <td>2</td>\n",
              "      <td>03:31</td>\n",
              "      <td>2</td>\n",
              "      <td>00:46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.27</td>\n",
              "      <td>165</td>\n",
              "      <td>144</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>2.33</td>\n",
              "      <td>9.091</td>\n",
              "      <td>10.000</td>\n",
              "      <td>19.091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>2</td>\n",
              "      <td>03:57</td>\n",
              "      <td>2</td>\n",
              "      <td>07:30</td>\n",
              "      <td>2</td>\n",
              "      <td>03:57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>92.02</td>\n",
              "      <td>213</td>\n",
              "      <td>196</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>1.89</td>\n",
              "      <td>8.920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>1</td>\n",
              "      <td>23:41</td>\n",
              "      <td>1</td>\n",
              "      <td>05:04</td>\n",
              "      <td>1</td>\n",
              "      <td>23:41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>76.47</td>\n",
              "      <td>323</td>\n",
              "      <td>247</td>\n",
              "      <td>76</td>\n",
              "      <td>19</td>\n",
              "      <td>4.00</td>\n",
              "      <td>17.957</td>\n",
              "      <td>15.789</td>\n",
              "      <td>33.746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>1</td>\n",
              "      <td>22:29</td>\n",
              "      <td>1</td>\n",
              "      <td>05:52</td>\n",
              "      <td>1</td>\n",
              "      <td>22:32</td>\n",
              "      <td>3.0</td>\n",
              "      <td>79.23</td>\n",
              "      <td>443</td>\n",
              "      <td>351</td>\n",
              "      <td>89</td>\n",
              "      <td>16</td>\n",
              "      <td>5.56</td>\n",
              "      <td>18.962</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>1</td>\n",
              "      <td>23:56</td>\n",
              "      <td>1</td>\n",
              "      <td>06:42</td>\n",
              "      <td>1</td>\n",
              "      <td>23:56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85.71</td>\n",
              "      <td>406</td>\n",
              "      <td>348</td>\n",
              "      <td>58</td>\n",
              "      <td>21</td>\n",
              "      <td>2.76</td>\n",
              "      <td>11.576</td>\n",
              "      <td>9.524</td>\n",
              "      <td>21.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>2</td>\n",
              "      <td>00:57</td>\n",
              "      <td>2</td>\n",
              "      <td>07:10</td>\n",
              "      <td>2</td>\n",
              "      <td>01:01</td>\n",
              "      <td>4.0</td>\n",
              "      <td>85.52</td>\n",
              "      <td>373</td>\n",
              "      <td>319</td>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "      <td>1.79</td>\n",
              "      <td>8.847</td>\n",
              "      <td>14.286</td>\n",
              "      <td>23.133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>2</td>\n",
              "      <td>00:08</td>\n",
              "      <td>2</td>\n",
              "      <td>07:00</td>\n",
              "      <td>2</td>\n",
              "      <td>00:08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90.78</td>\n",
              "      <td>412</td>\n",
              "      <td>374</td>\n",
              "      <td>38</td>\n",
              "      <td>19</td>\n",
              "      <td>2.00</td>\n",
              "      <td>11.408</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>2</td>\n",
              "      <td>00:28</td>\n",
              "      <td>2</td>\n",
              "      <td>08:02</td>\n",
              "      <td>2</td>\n",
              "      <td>00:28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75.33</td>\n",
              "      <td>454</td>\n",
              "      <td>342</td>\n",
              "      <td>112</td>\n",
              "      <td>31</td>\n",
              "      <td>3.61</td>\n",
              "      <td>17.401</td>\n",
              "      <td>28.125</td>\n",
              "      <td>45.526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>2</td>\n",
              "      <td>00:44</td>\n",
              "      <td>2</td>\n",
              "      <td>06:36</td>\n",
              "      <td>2</td>\n",
              "      <td>00:44</td>\n",
              "      <td>NaN</td>\n",
              "      <td>86.93</td>\n",
              "      <td>352</td>\n",
              "      <td>306</td>\n",
              "      <td>46</td>\n",
              "      <td>20</td>\n",
              "      <td>2.30</td>\n",
              "      <td>9.375</td>\n",
              "      <td>19.048</td>\n",
              "      <td>28.423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>2</td>\n",
              "      <td>02:19</td>\n",
              "      <td>2</td>\n",
              "      <td>07:16</td>\n",
              "      <td>2</td>\n",
              "      <td>02:19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>91.92</td>\n",
              "      <td>297</td>\n",
              "      <td>273</td>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>1.33</td>\n",
              "      <td>6.734</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>2</td>\n",
              "      <td>02:27</td>\n",
              "      <td>2</td>\n",
              "      <td>09:02</td>\n",
              "      <td>2</td>\n",
              "      <td>02:27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>84.30</td>\n",
              "      <td>395</td>\n",
              "      <td>333</td>\n",
              "      <td>62</td>\n",
              "      <td>20</td>\n",
              "      <td>3.10</td>\n",
              "      <td>10.633</td>\n",
              "      <td>4.762</td>\n",
              "      <td>15.395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>2</td>\n",
              "      <td>00:22</td>\n",
              "      <td>2</td>\n",
              "      <td>07:58</td>\n",
              "      <td>2</td>\n",
              "      <td>00:26</td>\n",
              "      <td>4.0</td>\n",
              "      <td>74.34</td>\n",
              "      <td>456</td>\n",
              "      <td>339</td>\n",
              "      <td>113</td>\n",
              "      <td>39</td>\n",
              "      <td>2.90</td>\n",
              "      <td>16.228</td>\n",
              "      <td>15.385</td>\n",
              "      <td>31.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>2</td>\n",
              "      <td>02:40</td>\n",
              "      <td>2</td>\n",
              "      <td>08:09</td>\n",
              "      <td>2</td>\n",
              "      <td>02:44</td>\n",
              "      <td>4.0</td>\n",
              "      <td>75.08</td>\n",
              "      <td>329</td>\n",
              "      <td>247</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>6.00</td>\n",
              "      <td>20.669</td>\n",
              "      <td>7.692</td>\n",
              "      <td>28.361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>1</td>\n",
              "      <td>22:56</td>\n",
              "      <td>1</td>\n",
              "      <td>06:35</td>\n",
              "      <td>1</td>\n",
              "      <td>22:57</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.07</td>\n",
              "      <td>459</td>\n",
              "      <td>340</td>\n",
              "      <td>118</td>\n",
              "      <td>44</td>\n",
              "      <td>2.68</td>\n",
              "      <td>18.954</td>\n",
              "      <td>22.222</td>\n",
              "      <td>41.176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>2</td>\n",
              "      <td>00:17</td>\n",
              "      <td>2</td>\n",
              "      <td>07:13</td>\n",
              "      <td>2</td>\n",
              "      <td>00:20</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.77</td>\n",
              "      <td>416</td>\n",
              "      <td>336</td>\n",
              "      <td>77</td>\n",
              "      <td>27</td>\n",
              "      <td>2.85</td>\n",
              "      <td>17.308</td>\n",
              "      <td>25.926</td>\n",
              "      <td>43.234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>2</td>\n",
              "      <td>00:30</td>\n",
              "      <td>2</td>\n",
              "      <td>11:00</td>\n",
              "      <td>2</td>\n",
              "      <td>00:33</td>\n",
              "      <td>3.0</td>\n",
              "      <td>91.75</td>\n",
              "      <td>630</td>\n",
              "      <td>578</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "      <td>12.25</td>\n",
              "      <td>8.095</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>2</td>\n",
              "      <td>00:55</td>\n",
              "      <td>2</td>\n",
              "      <td>06:53</td>\n",
              "      <td>2</td>\n",
              "      <td>00:58</td>\n",
              "      <td>3.0</td>\n",
              "      <td>84.36</td>\n",
              "      <td>358</td>\n",
              "      <td>302</td>\n",
              "      <td>53</td>\n",
              "      <td>9</td>\n",
              "      <td>5.89</td>\n",
              "      <td>16.480</td>\n",
              "      <td>20.000</td>\n",
              "      <td>36.480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b88645a0-c36b-4cdd-a237-06094ecf75a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b88645a0-c36b-4cdd-a237-06094ecf75a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b88645a0-c36b-4cdd-a237-06094ecf75a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Survey (PSQ)"
      ],
      "metadata": {
        "id": "0gqkxCVFzCh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "survey = create_dataset(users,'questionnaire')\n",
        "survey"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IydO5evzBiD",
        "outputId": "c139ade3-0bad-4770-8bf8-fdfa321e03b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          MEQ  STAI1  STAI2  Pittsburgh  Daily_stress  BISBAS_bis  \\\n",
              "user                                                                \n",
              "user_12  50.0   27.0   33.0         4.0          48.0        20.0   \n",
              "user_2   52.0   24.0   39.0         7.0          26.0        26.0   \n",
              "user_22  52.0   41.0   48.0         5.0          41.0        24.0   \n",
              "user_15  58.0   52.0   42.0         5.0          35.0        25.0   \n",
              "user_1   47.0   41.0   43.0         5.0          23.0        22.0   \n",
              "user_13  48.0   30.0   43.0         4.0          27.0        22.0   \n",
              "user_3   59.0   27.0   27.0         8.0          11.0        19.0   \n",
              "user_5   52.0   54.0   47.0         8.0          41.0        25.0   \n",
              "user_4   60.0   28.0   40.0         4.0          10.0        20.0   \n",
              "user_14  59.0   48.0   45.0         2.0          26.0        24.0   \n",
              "user_11  38.0   36.0   43.0         7.0          17.0        23.0   \n",
              "user_7   46.0   33.0    NaN         7.0          69.0        19.0   \n",
              "user_17  49.0   34.0   49.0         3.0          20.0        22.0   \n",
              "user_21  55.0   38.0   35.0         4.0          30.0        23.0   \n",
              "user_6   48.0   32.0   47.0         9.0          41.0        19.0   \n",
              "user_16  45.0   29.0   41.0         5.0          32.0        26.0   \n",
              "user_10  38.0   39.0   46.0         4.0          14.0        19.0   \n",
              "user_19  44.0   26.0   35.0         4.0          31.0        21.0   \n",
              "user_8   64.0   32.0   39.0         3.0          74.0        24.0   \n",
              "user_9   44.0   36.0   41.0         9.0          38.0        20.0   \n",
              "user_18  55.0   33.0   44.0         5.0          32.0        26.0   \n",
              "\n",
              "         BISBAS_reward  BISBAS_drive  BISBAS_fun  panas_pos_10  panas_pos_14  \\\n",
              "user                                                                           \n",
              "user_12           22.0          10.0         8.0          30.0          27.0   \n",
              "user_2            21.0          12.0         6.0          37.0          32.0   \n",
              "user_22           21.0           9.0        11.0          24.0          29.0   \n",
              "user_15           25.0          16.0        16.0          28.0          29.0   \n",
              "user_1            21.0          14.0        14.0          21.0          17.0   \n",
              "user_13           19.0          14.0        12.0          22.0           NaN   \n",
              "user_3            18.0          12.0         6.0          35.0          34.0   \n",
              "user_5            23.0          14.0        15.0          30.0          25.0   \n",
              "user_4            17.0          13.0        14.0          30.0          27.0   \n",
              "user_14           14.0          11.0         5.0          25.0          13.0   \n",
              "user_11           19.0          11.0        13.0          23.0          16.0   \n",
              "user_7            19.0          12.0         6.0          22.0          13.0   \n",
              "user_17           24.0          14.0        13.0          22.0          24.0   \n",
              "user_21           17.0          10.0         7.0          25.0          20.0   \n",
              "user_6            19.0          13.0        15.0          27.0          25.0   \n",
              "user_16           19.0          11.0        13.0          29.0          23.0   \n",
              "user_10           16.0          16.0        14.0          28.0          23.0   \n",
              "user_19           20.0          12.0        11.0          21.0          22.0   \n",
              "user_8            18.0          12.0         9.0          36.0          25.0   \n",
              "user_9            18.0          14.0        10.0          29.0          34.0   \n",
              "user_18           18.0           8.0        11.0          28.0          18.0   \n",
              "\n",
              "         panas_pos_18  panas_pos_22  panas_pos_9+1  panas_neg_10  \\\n",
              "user                                                               \n",
              "user_12          30.0          20.0           29.0          14.0   \n",
              "user_2           24.0          27.0           33.0          11.0   \n",
              "user_22          25.0          22.0           20.0          24.0   \n",
              "user_15          36.0          18.0           22.0          12.0   \n",
              "user_1           12.0          18.0           17.0          11.0   \n",
              "user_13          26.0          14.0           23.0          13.0   \n",
              "user_3           31.0          28.0           35.0          11.0   \n",
              "user_5           31.0          27.0           31.0          26.0   \n",
              "user_4           22.0          19.0           26.0          11.0   \n",
              "user_14          22.0          15.0           18.0          14.0   \n",
              "user_11          22.0          30.0           13.0          15.0   \n",
              "user_7           13.0          11.0           13.0          11.0   \n",
              "user_17          29.0          23.0           24.0          15.0   \n",
              "user_21          21.0          16.0           24.0          10.0   \n",
              "user_6           30.0          25.0           14.0          13.0   \n",
              "user_16          29.0          24.0           25.0          12.0   \n",
              "user_10          21.0          18.0           23.0          15.0   \n",
              "user_19          19.0          17.0           22.0          11.0   \n",
              "user_8           30.0          21.0           24.0          14.0   \n",
              "user_9           35.0          22.0           24.0          11.0   \n",
              "user_18          19.0          13.0           25.0          13.0   \n",
              "\n",
              "         panas_neg_14  panas_neg_18  panas_neg_22  panas_neg_9+1  \n",
              "user                                                              \n",
              "user_12          16.0          14.0          23.0           13.0  \n",
              "user_2           10.0          16.0          17.0           18.0  \n",
              "user_22          15.0          18.0          13.0           13.0  \n",
              "user_15          19.0          22.0          15.0           11.0  \n",
              "user_1           13.0          13.0          10.0           10.0  \n",
              "user_13           NaN          11.0          13.0           12.0  \n",
              "user_3           12.0          11.0          12.0           11.0  \n",
              "user_5           17.0          17.0          15.0           16.0  \n",
              "user_4           13.0          15.0          14.0           14.0  \n",
              "user_14          13.0          11.0          13.0           10.0  \n",
              "user_11          15.0          11.0          13.0           14.0  \n",
              "user_7           13.0          16.0          14.0           13.0  \n",
              "user_17          11.0          10.0          10.0           10.0  \n",
              "user_21          12.0          14.0          12.0           13.0  \n",
              "user_6           12.0          13.0          15.0           16.0  \n",
              "user_16          13.0          18.0          15.0           17.0  \n",
              "user_10          23.0          23.0          27.0           12.0  \n",
              "user_19          11.0          17.0          15.0           13.0  \n",
              "user_8           11.0          10.0          12.0           10.0  \n",
              "user_9           11.0          13.0          16.0           15.0  \n",
              "user_18          15.0          24.0          16.0           12.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b96db691-fd29-42d2-adc8-695c02404a8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEQ</th>\n",
              "      <th>STAI1</th>\n",
              "      <th>STAI2</th>\n",
              "      <th>Pittsburgh</th>\n",
              "      <th>Daily_stress</th>\n",
              "      <th>BISBAS_bis</th>\n",
              "      <th>BISBAS_reward</th>\n",
              "      <th>BISBAS_drive</th>\n",
              "      <th>BISBAS_fun</th>\n",
              "      <th>panas_pos_10</th>\n",
              "      <th>panas_pos_14</th>\n",
              "      <th>panas_pos_18</th>\n",
              "      <th>panas_pos_22</th>\n",
              "      <th>panas_pos_9+1</th>\n",
              "      <th>panas_neg_10</th>\n",
              "      <th>panas_neg_14</th>\n",
              "      <th>panas_neg_18</th>\n",
              "      <th>panas_neg_22</th>\n",
              "      <th>panas_neg_9+1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>50.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>52.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>52.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>58.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>47.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>48.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>59.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>52.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>60.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>59.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_11</th>\n",
              "      <td>38.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>46.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>49.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>55.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>48.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>45.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>38.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>44.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>64.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>44.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>55.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b96db691-fd29-42d2-adc8-695c02404a8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b96db691-fd29-42d2-adc8-695c02404a8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b96db691-fd29-42d2-adc8-695c02404a8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PSQ = survey[['Pittsburgh']]\n",
        "PSQ.columns = ['PSQ']\n",
        "PSQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW9TsV8ozidt",
        "outputId": "bf596f1c-f395-4522-9093-dea4c63781fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         PSQ\n",
              "user        \n",
              "user_12  4.0\n",
              "user_2   7.0\n",
              "user_22  5.0\n",
              "user_15  5.0\n",
              "user_1   5.0\n",
              "user_13  4.0\n",
              "user_3   8.0\n",
              "user_5   8.0\n",
              "user_4   4.0\n",
              "user_14  2.0\n",
              "user_11  7.0\n",
              "user_7   7.0\n",
              "user_17  3.0\n",
              "user_21  4.0\n",
              "user_6   9.0\n",
              "user_16  5.0\n",
              "user_10  4.0\n",
              "user_19  4.0\n",
              "user_8   3.0\n",
              "user_9   9.0\n",
              "user_18  5.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d86c54ef-798f-438f-9b4d-d6e92054c3f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PSQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_11</th>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d86c54ef-798f-438f-9b4d-d6e92054c3f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d86c54ef-798f-438f-9b4d-d6e92054c3f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d86c54ef-798f-438f-9b4d-d6e92054c3f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = PSQ.hist(bins=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzNTVfCE1i6a",
        "outputId": "0dbb6450-7d25-4aa7-a42d-7775db9d1e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activity"
      ],
      "metadata": {
        "id": "SZeqBcdlw4et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activity = create_dataset(users,'Activity')"
      ],
      "metadata": {
        "id": "Iof5y6RswY5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVFglqQcFP1V",
        "outputId": "d9cf809c-6ea5-420f-8ff5-98b0b89c7857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Activity  Start    End  Day\n",
              "user                                \n",
              "user_12       3.0  10:00  10:20    1\n",
              "user_12       7.0  11:05  11:30    1\n",
              "user_12       8.0  11:30  12:10    1\n",
              "user_12       3.0  12:10  12:35    1\n",
              "user_12       8.0  12:35  13:05    1\n",
              "...           ...    ...    ...  ...\n",
              "user_18      11.0  20:00  21:00    1\n",
              "user_18       9.0  07:45  08:00    2\n",
              "user_18      12.0  00:15  00:30    2\n",
              "user_18      12.0  03:45  04:00    2\n",
              "user_18      12.0  07:30  07:45    2\n",
              "\n",
              "[438 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad6c4c12-b736-4ebf-983d-13a5bc486dfb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>Start</th>\n",
              "      <th>End</th>\n",
              "      <th>Day</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>3.0</td>\n",
              "      <td>10:00</td>\n",
              "      <td>10:20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>7.0</td>\n",
              "      <td>11:05</td>\n",
              "      <td>11:30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>8.0</td>\n",
              "      <td>11:30</td>\n",
              "      <td>12:10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>3.0</td>\n",
              "      <td>12:10</td>\n",
              "      <td>12:35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>8.0</td>\n",
              "      <td>12:35</td>\n",
              "      <td>13:05</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>11.0</td>\n",
              "      <td>20:00</td>\n",
              "      <td>21:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>9.0</td>\n",
              "      <td>07:45</td>\n",
              "      <td>08:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>12.0</td>\n",
              "      <td>00:15</td>\n",
              "      <td>00:30</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>12.0</td>\n",
              "      <td>03:45</td>\n",
              "      <td>04:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>12.0</td>\n",
              "      <td>07:30</td>\n",
              "      <td>07:45</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>438 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad6c4c12-b736-4ebf-983d-13a5bc486dfb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad6c4c12-b736-4ebf-983d-13a5bc486dfb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad6c4c12-b736-4ebf-983d-13a5bc486dfb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activity['Activity'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyr5C4WSGFYW",
        "outputId": "aa312935-2a11-4fe1-b074-820341f56919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0     84\n",
              "6.0     84\n",
              "2.0     76\n",
              "7.0     39\n",
              "9.0     32\n",
              "12.0    27\n",
              "8.0     16\n",
              "10.0    13\n",
              "1.0     12\n",
              "5.0     10\n",
              "4.0      7\n",
              "11.0     5\n",
              "Name: Activity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing"
      ],
      "metadata": {
        "id": "XT6dOZmT9QbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# values lower than 6 indicate good sleep quality\n",
        "# [output if condition else output for l in list]\n",
        "\n",
        "binary = []\n",
        "for index, row in PSQ.iterrows():\n",
        "  if row['PSQ'] < 6:\n",
        "    binary.append(1)\n",
        "  else:\n",
        "     binary.append(0)\n",
        "\n",
        "PSQ['PSQ'] = binary\n",
        "\n",
        "PSQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiumYKizzrse",
        "outputId": "1862aa7a-ab31-41b8-d704-e623c1486e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         PSQ\n",
              "user        \n",
              "user_12    1\n",
              "user_2     0\n",
              "user_22    1\n",
              "user_15    1\n",
              "user_1     1\n",
              "user_13    1\n",
              "user_3     0\n",
              "user_5     0\n",
              "user_4     1\n",
              "user_14    1\n",
              "user_11    0\n",
              "user_7     0\n",
              "user_17    1\n",
              "user_21    1\n",
              "user_6     0\n",
              "user_16    1\n",
              "user_10    1\n",
              "user_19    1\n",
              "user_8     1\n",
              "user_9     0\n",
              "user_18    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03b981b4-70fa-4c0b-8061-89e6908e7c91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PSQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_11</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03b981b4-70fa-4c0b-8061-89e6908e7c91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03b981b4-70fa-4c0b-8061-89e6908e7c91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03b981b4-70fa-4c0b-8061-89e6908e7c91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activity = activity[activity['End'].notna()]\n",
        "activity = activity[activity['Activity'].notna()]\n",
        "activity['End'].mask(activity['End'] == '24:00', '00:00', inplace=True)\n",
        "activity['Start'] =  pd.to_datetime(activity['Start'], format='%H:%M')\n",
        "activity['End'] =  pd.to_datetime(activity['End'], format='%H:%M')\n",
        "activity['End'] = activity['End'].dt.time\n",
        "activity['Start'] = activity['Start'].dt.time"
      ],
      "metadata": {
        "id": "spg7bLtVk4oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activity['time_spent'] = ''\n",
        "times = []\n",
        "for index, row in activity.iterrows():\n",
        "  end = row['End']\n",
        "  start = row['Start']\n",
        "  time = datetime.combine(date.today(),end) - datetime.combine(date.today(),start)  \n",
        "  time_sec = time.total_seconds()\n",
        "  if (time_sec < 0):\n",
        "   time_sec =  time_sec + 86400\n",
        "  times.append(time_sec)\n",
        "\n",
        "activity['time_spent'] = times"
      ],
      "metadata": {
        "id": "vAFjkXsQnOe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = activity.loc['user_1']\n",
        "u2 = activity.loc['user_2']\n",
        "u3 = activity.loc['user_3']\n",
        "u4 = activity.loc['user_4']\n",
        "u5 = activity.loc['user_5']\n",
        "u6 = activity.loc['user_6']\n",
        "u7 = activity.loc['user_7']\n",
        "u8 = activity.loc['user_8']\n",
        "u9 = activity.loc['user_9']\n",
        "u10 = activity.loc['user_10']\n",
        "u11 = activity.loc['user_11']\n",
        "u12 = activity.loc['user_12']\n",
        "u13 = activity.loc['user_13']\n",
        "u14 = activity.loc['user_14']\n",
        "u15 = activity.loc['user_15']\n",
        "u16 = activity.loc['user_16']\n",
        "u17 = activity.loc['user_17']\n",
        "u18 = activity.loc['user_18']\n",
        "u19 = activity.loc['user_19']\n",
        "u21 = activity.loc['user_21']\n",
        "u22 = activity.loc['user_22']\n",
        "\n",
        "users_list = [u1,u2,u3,u4,u5,u6,u7,u8,u9,u10,u11,u12,u13,u14,u15,u16,u17,u18,u19,u21,u22]"
      ],
      "metadata": {
        "id": "Pn6PxL3TnRKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg = []\n",
        "for i in users_list:\n",
        "  avg.append(len(i.index))\n",
        "print(sum(avg)/len(avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIXj5OM0KmjJ",
        "outputId": "127060f6-3a94-498e-b2a0-d659382c9628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.285714285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_activity = pd.DataFrame()\n",
        "\n",
        "for i in users_list:\n",
        "  count = 0\n",
        "  activites = {}\n",
        "  for index, row in i.iterrows():\n",
        "      if count == 0:\n",
        "        activites['User'] = index\n",
        "      count = count + 1\n",
        "      temp = row['Activity']\n",
        "      if(temp in activites ):\n",
        "          current = activites[temp] \n",
        "          temp1 = row['time_spent']\n",
        "          seconds = temp1\n",
        "          added = current + seconds\n",
        "          activites[temp] = added\n",
        "      else:\n",
        "        temp1 = row['time_spent']\n",
        "        seconds = temp1\n",
        "        activites[temp] = seconds\n",
        "  total_activity = total_activity.append(activites, ignore_index=True)"
      ],
      "metadata": {
        "id": "_HHkZmUFoTky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_activity = total_activity.set_index('User')"
      ],
      "metadata": {
        "id": "ewNK4jyb5K5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 sleep \n",
        "# 2 laying down \n",
        "# 3 sitting (studying, eatting , etc) \n",
        "# 4 light movement (slow walking, work, etc) \n",
        "# 5 medium movement ( fast wlak, bike) \n",
        "# 6 heavy movement ( gym, running) \n",
        "# 7 eatting \n",
        "# 8 small screen usage ( phone or computer0 \n",
        "# 9 large screen usage ( TV) \n",
        "# 10 caffeinated drink consumption \n",
        "# 11 smoking \n",
        "# 12 alcohol "
      ],
      "metadata": {
        "id": "KqqKzj-Oufrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_activity = total_activity.fillna(0)\n",
        "total_activity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9WgWldIuWKY",
        "outputId": "9e233300-5cda-4e8f-c35a-2eb07f3ff422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              2.0     9.0    10.0      6.0      7.0     4.0      3.0     5.0  \\\n",
              "User                                                                           \n",
              "user_1    15420.0   780.0  3000.0   7800.0   3600.0   600.0   3900.0   600.0   \n",
              "user_2     2640.0   120.0     0.0   3120.0   9600.0  1020.0   6060.0     0.0   \n",
              "user_3     9720.0  1200.0     0.0   3300.0   1500.0  1200.0  21660.0  3300.0   \n",
              "user_4    10500.0   600.0     0.0   6600.0  14100.0     0.0      0.0     0.0   \n",
              "user_5    18000.0  1200.0     0.0   7200.0   8100.0     0.0   3000.0     0.0   \n",
              "user_6    12780.0   120.0     0.0   5700.0  10020.0     0.0   5760.0   900.0   \n",
              "user_7     9300.0     0.0     0.0  10800.0      0.0     0.0  21900.0     0.0   \n",
              "user_8   174600.0  2400.0     0.0   4800.0      0.0     0.0  22200.0  4500.0   \n",
              "user_9      600.0     0.0     0.0   7200.0  21600.0     0.0  80400.0  3600.0   \n",
              "user_10    7200.0   900.0  1200.0   5400.0  16500.0  2400.0  18000.0     0.0   \n",
              "user_11   12900.0   840.0     0.0   4620.0   2940.0     0.0  33000.0     0.0   \n",
              "user_12   17700.0  2100.0     0.0   5700.0  11400.0     0.0   4800.0  2400.0   \n",
              "user_13   10800.0     0.0     0.0   9000.0      0.0     0.0  25200.0     0.0   \n",
              "user_14    6300.0     0.0     0.0   3480.0  35340.0     0.0   5520.0     0.0   \n",
              "user_15       0.0  1800.0     0.0   4200.0      0.0     0.0  21600.0  7200.0   \n",
              "user_16    9600.0  1800.0     0.0   5700.0      0.0     0.0  21000.0     0.0   \n",
              "user_17     960.0  3060.0     0.0   6300.0      0.0     0.0  24720.0  4200.0   \n",
              "user_18   16800.0   900.0     0.0   2400.0  30240.0     0.0   1800.0     0.0   \n",
              "user_19    6600.0     0.0     0.0   5700.0   7800.0     0.0  15900.0     0.0   \n",
              "user_21   81540.0  2400.0     0.0   4800.0      0.0     0.0   4500.0     0.0   \n",
              "user_22    1200.0     0.0     0.0   4800.0   7200.0     0.0  29400.0     0.0   \n",
              "\n",
              "             8.0     1.0    12.0    11.0  \n",
              "User                                      \n",
              "user_1    2700.0   300.0     0.0     0.0  \n",
              "user_2    1800.0   720.0  1200.0     0.0  \n",
              "user_3    2400.0  2700.0     0.0     0.0  \n",
              "user_4    7200.0    60.0   600.0     0.0  \n",
              "user_5       0.0     0.0     0.0     0.0  \n",
              "user_6   10440.0     0.0     0.0     0.0  \n",
              "user_7    7200.0     0.0   600.0     0.0  \n",
              "user_8    3300.0     0.0   600.0     0.0  \n",
              "user_9    5400.0   600.0  1200.0     0.0  \n",
              "user_10      0.0     0.0     0.0  1380.0  \n",
              "user_11      0.0     0.0  1140.0  1320.0  \n",
              "user_12   4200.0  3900.0   900.0     0.0  \n",
              "user_13      0.0     0.0     0.0     0.0  \n",
              "user_14   7080.0  2760.0   300.0     0.0  \n",
              "user_15      0.0     0.0  1200.0     0.0  \n",
              "user_16   7200.0  2400.0  1200.0     0.0  \n",
              "user_17   5700.0  2940.0   780.0     0.0  \n",
              "user_18      0.0     0.0  2700.0  3600.0  \n",
              "user_19   3900.0  2700.0   600.0     0.0  \n",
              "user_21      0.0     0.0     0.0     0.0  \n",
              "user_22      0.0     0.0     0.0   600.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44fc86e5-8459-4804-9904-8fc67bb7be9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2.0</th>\n",
              "      <th>9.0</th>\n",
              "      <th>10.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>4.0</th>\n",
              "      <th>3.0</th>\n",
              "      <th>5.0</th>\n",
              "      <th>8.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>12.0</th>\n",
              "      <th>11.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>User</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>15420.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>7800.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>3900.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>2640.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3120.0</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>6060.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>9720.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>21660.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>10500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6600.0</td>\n",
              "      <td>14100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>18000.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>8100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>12780.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>10020.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5760.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>10440.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>9300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>174600.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22200.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>21600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80400.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>7200.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>16500.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_11</th>\n",
              "      <td>12900.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4620.0</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>1320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>17700.0</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>3900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>10800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>6300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3480.0</td>\n",
              "      <td>35340.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5520.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7080.0</td>\n",
              "      <td>2760.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21600.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>9600.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>960.0</td>\n",
              "      <td>3060.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24720.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>16800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>30240.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>3600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>6600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>7800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3900.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>81540.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44fc86e5-8459-4804-9904-8fc67bb7be9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44fc86e5-8459-4804-9904-8fc67bb7be9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44fc86e5-8459-4804-9904-8fc67bb7be9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_activity[total_activity.columns[1:]].var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilG-fkSBSdG9",
        "outputId": "53adb8dd-d578-4ba8-944f-60243f99a2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.0     9.253714e+05\n",
              "10.0    4.800000e+05\n",
              "6.0     4.054783e+06\n",
              "7.0     1.041914e+08\n",
              "4.0     3.651429e+05\n",
              "3.0     3.115198e+08\n",
              "5.0     4.328143e+06\n",
              "8.0     1.063745e+07\n",
              "1.0     1.772383e+06\n",
              "12.0    4.612800e+05\n",
              "11.0    7.349829e+05\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = total_activity[10.0].var()\n",
        "var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcbsKytYUJTE",
        "outputId": "9c5bd2e6-5fa6-4fd4-f493-c1ef1ac27360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480000.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(total_activity.corr(), annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufufqJ0uQEaW",
        "outputId": "9567b730-f92e-4851-b85b-b616c4e2d9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc1671778e0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alcohol(12) and smoking(11) have strong correlation.\n",
        "\n",
        "Medium movement(5) and large screen usage(9) have moderate correlation\n",
        "\n",
        "Laying down(2) and large screen usage(9) have moderate correlation\n",
        "\n",
        "light movement(4) and caffeinated drink consumption (10) have moderate correlation\n"
      ],
      "metadata": {
        "id": "XU6ucRfwQbP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activity_PSQ = total_activity.join(PSQ)\n",
        "activity_PSQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO2l2-oR4MdZ",
        "outputId": "da4782a6-498a-45c2-c1e2-48833228cf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              2.0     9.0    10.0      6.0      7.0     4.0      3.0     5.0  \\\n",
              "User                                                                           \n",
              "user_1    15420.0   780.0  3000.0   7800.0   3600.0   600.0   3900.0   600.0   \n",
              "user_2     2640.0   120.0     0.0   3120.0   9600.0  1020.0   6060.0     0.0   \n",
              "user_3     9720.0  1200.0     0.0   3300.0   1500.0  1200.0  21660.0  3300.0   \n",
              "user_4    10500.0   600.0     0.0   6600.0  14100.0     0.0      0.0     0.0   \n",
              "user_5    18000.0  1200.0     0.0   7200.0   8100.0     0.0   3000.0     0.0   \n",
              "user_6    12780.0   120.0     0.0   5700.0  10020.0     0.0   5760.0   900.0   \n",
              "user_7     9300.0     0.0     0.0  10800.0      0.0     0.0  21900.0     0.0   \n",
              "user_8   174600.0  2400.0     0.0   4800.0      0.0     0.0  22200.0  4500.0   \n",
              "user_9      600.0     0.0     0.0   7200.0  21600.0     0.0  80400.0  3600.0   \n",
              "user_10    7200.0   900.0  1200.0   5400.0  16500.0  2400.0  18000.0     0.0   \n",
              "user_11   12900.0   840.0     0.0   4620.0   2940.0     0.0  33000.0     0.0   \n",
              "user_12   17700.0  2100.0     0.0   5700.0  11400.0     0.0   4800.0  2400.0   \n",
              "user_13   10800.0     0.0     0.0   9000.0      0.0     0.0  25200.0     0.0   \n",
              "user_14    6300.0     0.0     0.0   3480.0  35340.0     0.0   5520.0     0.0   \n",
              "user_15       0.0  1800.0     0.0   4200.0      0.0     0.0  21600.0  7200.0   \n",
              "user_16    9600.0  1800.0     0.0   5700.0      0.0     0.0  21000.0     0.0   \n",
              "user_17     960.0  3060.0     0.0   6300.0      0.0     0.0  24720.0  4200.0   \n",
              "user_18   16800.0   900.0     0.0   2400.0  30240.0     0.0   1800.0     0.0   \n",
              "user_19    6600.0     0.0     0.0   5700.0   7800.0     0.0  15900.0     0.0   \n",
              "user_21   81540.0  2400.0     0.0   4800.0      0.0     0.0   4500.0     0.0   \n",
              "user_22    1200.0     0.0     0.0   4800.0   7200.0     0.0  29400.0     0.0   \n",
              "\n",
              "             8.0     1.0    12.0    11.0  PSQ  \n",
              "User                                           \n",
              "user_1    2700.0   300.0     0.0     0.0    1  \n",
              "user_2    1800.0   720.0  1200.0     0.0    0  \n",
              "user_3    2400.0  2700.0     0.0     0.0    0  \n",
              "user_4    7200.0    60.0   600.0     0.0    1  \n",
              "user_5       0.0     0.0     0.0     0.0    0  \n",
              "user_6   10440.0     0.0     0.0     0.0    0  \n",
              "user_7    7200.0     0.0   600.0     0.0    0  \n",
              "user_8    3300.0     0.0   600.0     0.0    1  \n",
              "user_9    5400.0   600.0  1200.0     0.0    0  \n",
              "user_10      0.0     0.0     0.0  1380.0    1  \n",
              "user_11      0.0     0.0  1140.0  1320.0    0  \n",
              "user_12   4200.0  3900.0   900.0     0.0    1  \n",
              "user_13      0.0     0.0     0.0     0.0    1  \n",
              "user_14   7080.0  2760.0   300.0     0.0    1  \n",
              "user_15      0.0     0.0  1200.0     0.0    1  \n",
              "user_16   7200.0  2400.0  1200.0     0.0    1  \n",
              "user_17   5700.0  2940.0   780.0     0.0    1  \n",
              "user_18      0.0     0.0  2700.0  3600.0    1  \n",
              "user_19   3900.0  2700.0   600.0     0.0    1  \n",
              "user_21      0.0     0.0     0.0     0.0    1  \n",
              "user_22      0.0     0.0     0.0   600.0    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed93b698-d611-4efd-8503-834700f599c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2.0</th>\n",
              "      <th>9.0</th>\n",
              "      <th>10.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>4.0</th>\n",
              "      <th>3.0</th>\n",
              "      <th>5.0</th>\n",
              "      <th>8.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>12.0</th>\n",
              "      <th>11.0</th>\n",
              "      <th>PSQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>User</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_1</th>\n",
              "      <td>15420.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>7800.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>3900.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_2</th>\n",
              "      <td>2640.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3120.0</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>6060.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_3</th>\n",
              "      <td>9720.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>21660.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_4</th>\n",
              "      <td>10500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6600.0</td>\n",
              "      <td>14100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_5</th>\n",
              "      <td>18000.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>8100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_6</th>\n",
              "      <td>12780.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>10020.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5760.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>10440.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_7</th>\n",
              "      <td>9300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_8</th>\n",
              "      <td>174600.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22200.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_9</th>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>21600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80400.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_10</th>\n",
              "      <td>7200.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>16500.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1380.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_11</th>\n",
              "      <td>12900.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4620.0</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_12</th>\n",
              "      <td>17700.0</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>3900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_13</th>\n",
              "      <td>10800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_14</th>\n",
              "      <td>6300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3480.0</td>\n",
              "      <td>35340.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5520.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7080.0</td>\n",
              "      <td>2760.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21600.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_16</th>\n",
              "      <td>9600.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_17</th>\n",
              "      <td>960.0</td>\n",
              "      <td>3060.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24720.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_18</th>\n",
              "      <td>16800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>30240.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_19</th>\n",
              "      <td>6600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>7800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3900.0</td>\n",
              "      <td>2700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_21</th>\n",
              "      <td>81540.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_22</th>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>7200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed93b698-d611-4efd-8503-834700f599c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed93b698-d611-4efd-8503-834700f599c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed93b698-d611-4efd-8503-834700f599c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activity_PSQ[activity_PSQ.columns[1:]].corr()['PSQ'][:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u6T_xwdRzWo",
        "outputId": "5165985e-605d-43b5-c0be-45ae31d6b3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.0     0.350785\n",
              "10.0    0.209165\n",
              "6.0    -0.123370\n",
              "7.0     0.063075\n",
              "4.0    -0.082223\n",
              "3.0    -0.283495\n",
              "5.0     0.054730\n",
              "8.0    -0.139642\n",
              "1.0     0.181936\n",
              "12.0    0.030481\n",
              "11.0    0.118323\n",
              "PSQ     1.000000\n",
              "Name: PSQ, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training and tetsig"
      ],
      "metadata": {
        "id": "NqjdL3x89dan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = activity_PSQ.drop(columns=['PSQ'])\n",
        "y = activity_PSQ['PSQ']"
      ],
      "metadata": {
        "id": "sW_meNbz7O3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "M9dkkpF77KxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feature importnace"
      ],
      "metadata": {
        "id": "tmgG1XmW9s_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "model_1 = XGBClassifier(objective='binary:logistic', seed=1)\n",
        "model_1.fit(X,y)\n",
        "print(model_1.feature_importances_)\n",
        "x = model_1.feature_importances_[:-1]\n",
        "x[10], x[9] = x[9], x[10]\n",
        "xi = ['Sleeping', 'Laying Down', 'Sitting', 'Light Movement','Medium Movement','Heavy Movement','Eatting', 'Small Screen', 'Large Screen', 'Caffeine', 'Alcohol']\n",
        "\n",
        "df = pd.DataFrame(x)\n",
        "df['Activity ID'] = xi\n",
        "df = df.set_index('Activity ID')\n",
        "print(df)\n",
        "df.plot(kind='bar', legend = None)\n",
        "plt.ylabel(\"Feature Importance Scores\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# pyplot.xticks(xi)\n",
        "# pyplot.bar(range(len(x)), x)\n",
        "# pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "ZTntOh-FaitC",
        "outputId": "479de2e5-2207-4eb0-dda4-cda00d414167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07352155 0.20761003 0.         0.09992662 0.0939341  0.\n",
            " 0.09890941 0.12896118 0.13807729 0.         0.15905981 0.        ]\n",
            "                        0\n",
            "Activity ID              \n",
            "Sleeping         0.073522\n",
            "Laying Down      0.207610\n",
            "Sitting          0.000000\n",
            "Light Movement   0.099927\n",
            "Medium Movement  0.093934\n",
            "Heavy Movement   0.000000\n",
            "Eatting          0.098909\n",
            "Small Screen     0.128961\n",
            "Large Screen     0.138077\n",
            "Caffeine         0.159060\n",
            "Alcohol          0.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start of training"
      ],
      "metadata": {
        "id": "TNMCvIb_9ycl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegressionTUNING WITH CV = 5 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', LogisticRegression(C = 1,penalty = 'l1',solver = 'liblinear'))]) # solver = liblinear best for small datasets look at documentation\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__C': Real(0.2,1),\n",
        "    'my_classifier__penalty': Categorical(['l2','l1']),\n",
        "    'pca__n_components':Real(0.75,0.95)\n",
        "}\n",
        "\n",
        "bayes_search_5 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "     scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_5.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_5.best_score_))\n",
        "print('best score {}'.format(bayes_search_5.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFukwIoYqp_q",
        "outputId": "39306603-c76f-429a-adc2-7f63cb4cd2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8169006492691391, my_classifier__penalty=l2, pca__n_components=0.8467477161965998;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8169006492691391, my_classifier__penalty=l2, pca__n_components=0.8467477161965998;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8169006492691391, my_classifier__penalty=l2, pca__n_components=0.8467477161965998;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8169006492691391, my_classifier__penalty=l2, pca__n_components=0.8467477161965998;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8169006492691391, my_classifier__penalty=l2, pca__n_components=0.8467477161965998;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9708542267677889, my_classifier__penalty=l1, pca__n_components=0.9006045249509275;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9708542267677889, my_classifier__penalty=l1, pca__n_components=0.9006045249509275;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9708542267677889, my_classifier__penalty=l1, pca__n_components=0.9006045249509275;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9708542267677889, my_classifier__penalty=l1, pca__n_components=0.9006045249509275;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9708542267677889, my_classifier__penalty=l1, pca__n_components=0.9006045249509275;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.28592723885793786, my_classifier__penalty=l1, pca__n_components=0.9401986960921764;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.28592723885793786, my_classifier__penalty=l1, pca__n_components=0.9401986960921764;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.28592723885793786, my_classifier__penalty=l1, pca__n_components=0.9401986960921764;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.28592723885793786, my_classifier__penalty=l1, pca__n_components=0.9401986960921764;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.28592723885793786, my_classifier__penalty=l1, pca__n_components=0.9401986960921764;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6735802091797516, my_classifier__penalty=l1, pca__n_components=0.8653990175037074;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6735802091797516, my_classifier__penalty=l1, pca__n_components=0.8653990175037074;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6735802091797516, my_classifier__penalty=l1, pca__n_components=0.8653990175037074;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6735802091797516, my_classifier__penalty=l1, pca__n_components=0.8653990175037074;, score=(train=0.462, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6735802091797516, my_classifier__penalty=l1, pca__n_components=0.8653990175037074;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.25962235506623377, my_classifier__penalty=l2, pca__n_components=0.8330932531260044;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.25962235506623377, my_classifier__penalty=l2, pca__n_components=0.8330932531260044;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.25962235506623377, my_classifier__penalty=l2, pca__n_components=0.8330932531260044;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.25962235506623377, my_classifier__penalty=l2, pca__n_components=0.8330932531260044;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.25962235506623377, my_classifier__penalty=l2, pca__n_components=0.8330932531260044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6191811197236278, my_classifier__penalty=l1, pca__n_components=0.8346850067826143;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6191811197236278, my_classifier__penalty=l1, pca__n_components=0.8346850067826143;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6191811197236278, my_classifier__penalty=l1, pca__n_components=0.8346850067826143;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6191811197236278, my_classifier__penalty=l1, pca__n_components=0.8346850067826143;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6191811197236278, my_classifier__penalty=l1, pca__n_components=0.8346850067826143;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6670466978450413, my_classifier__penalty=l1, pca__n_components=0.9029315623292702;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6670466978450413, my_classifier__penalty=l1, pca__n_components=0.9029315623292702;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6670466978450413, my_classifier__penalty=l1, pca__n_components=0.9029315623292702;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6670466978450413, my_classifier__penalty=l1, pca__n_components=0.9029315623292702;, score=(train=0.462, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6670466978450413, my_classifier__penalty=l1, pca__n_components=0.9029315623292702;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9944575095802679, my_classifier__penalty=l2, pca__n_components=0.8638499179380107;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9944575095802679, my_classifier__penalty=l2, pca__n_components=0.8638499179380107;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9944575095802679, my_classifier__penalty=l2, pca__n_components=0.8638499179380107;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9944575095802679, my_classifier__penalty=l2, pca__n_components=0.8638499179380107;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9944575095802679, my_classifier__penalty=l2, pca__n_components=0.8638499179380107;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8596011155319698, my_classifier__penalty=l2, pca__n_components=0.8055787558145938;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8596011155319698, my_classifier__penalty=l2, pca__n_components=0.8055787558145938;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8596011155319698, my_classifier__penalty=l2, pca__n_components=0.8055787558145938;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8596011155319698, my_classifier__penalty=l2, pca__n_components=0.8055787558145938;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8596011155319698, my_classifier__penalty=l2, pca__n_components=0.8055787558145938;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.7386803862394047, my_classifier__penalty=l1, pca__n_components=0.7787545339548805;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.7386803862394047, my_classifier__penalty=l1, pca__n_components=0.7787545339548805;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.7386803862394047, my_classifier__penalty=l1, pca__n_components=0.7787545339548805;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.7386803862394047, my_classifier__penalty=l1, pca__n_components=0.7787545339548805;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.7386803862394047, my_classifier__penalty=l1, pca__n_components=0.7787545339548805;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.943924807480115;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.943924807480115;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.943924807480115;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.943924807480115;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.943924807480115;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.24382997737044743, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.24382997737044743, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.24382997737044743, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.24382997737044743, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.24382997737044743, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.645400926055487, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.645400926055487, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.645400926055487, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.645400926055487, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.645400926055487, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.24666297037715676, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.24666297037715676, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.24666297037715676, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.24666297037715676, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.24666297037715676, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6433121250994294, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6433121250994294, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6433121250994294, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6433121250994294, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6433121250994294, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8610463746996442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8610463746996442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8610463746996442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8610463746996442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8610463746996442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.33617814398703316, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.33617814398703316, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.33617814398703316, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.33617814398703316, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.33617814398703316, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9261264294253837, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9261264294253837, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9261264294253837, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9261264294253837, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9261264294253837, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.29691481528898, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.29691481528898, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.29691481528898, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.29691481528898, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.29691481528898, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8886274714562009;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8886274714562009;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8886274714562009;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8886274714562009;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8886274714562009;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.33707760644217355, my_classifier__penalty=l1, pca__n_components=0.9139082664980067;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.33707760644217355, my_classifier__penalty=l1, pca__n_components=0.9139082664980067;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.33707760644217355, my_classifier__penalty=l1, pca__n_components=0.9139082664980067;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.33707760644217355, my_classifier__penalty=l1, pca__n_components=0.9139082664980067;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.33707760644217355, my_classifier__penalty=l1, pca__n_components=0.9139082664980067;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.22416782919636913, my_classifier__penalty=l1, pca__n_components=0.9420533704470997;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.22416782919636913, my_classifier__penalty=l1, pca__n_components=0.9420533704470997;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.22416782919636913, my_classifier__penalty=l1, pca__n_components=0.9420533704470997;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.22416782919636913, my_classifier__penalty=l1, pca__n_components=0.9420533704470997;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.22416782919636913, my_classifier__penalty=l1, pca__n_components=0.9420533704470997;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.829433478895874;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.829433478895874;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.829433478895874;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.829433478895874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.829433478895874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.9032765928788029;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.9032765928788029;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.9032765928788029;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.9032765928788029;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.9032765928788029;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7829216908511097;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7829216908511097;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7829216908511097;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7829216908511097;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7829216908511097;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.7099408343113363, my_classifier__penalty=l2, pca__n_components=0.8934672988974655;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.7099408343113363, my_classifier__penalty=l2, pca__n_components=0.8934672988974655;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.7099408343113363, my_classifier__penalty=l2, pca__n_components=0.8934672988974655;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.7099408343113363, my_classifier__penalty=l2, pca__n_components=0.8934672988974655;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.7099408343113363, my_classifier__penalty=l2, pca__n_components=0.8934672988974655;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.9063389919706849;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.9063389919706849;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.9063389919706849;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.9063389919706849;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.9063389919706849;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5278410336267855, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5278410336267855, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5278410336267855, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5278410336267855, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5278410336267855, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.7140342249018821, my_classifier__penalty=l2, pca__n_components=0.7764310485759233;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.7140342249018821, my_classifier__penalty=l2, pca__n_components=0.7764310485759233;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.7140342249018821, my_classifier__penalty=l2, pca__n_components=0.7764310485759233;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.7140342249018821, my_classifier__penalty=l2, pca__n_components=0.7764310485759233;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.7140342249018821, my_classifier__penalty=l2, pca__n_components=0.7764310485759233;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.44581807663127876, my_classifier__penalty=l1, pca__n_components=0.9451286609018077;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.44581807663127876, my_classifier__penalty=l1, pca__n_components=0.9451286609018077;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.44581807663127876, my_classifier__penalty=l1, pca__n_components=0.9451286609018077;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.44581807663127876, my_classifier__penalty=l1, pca__n_components=0.9451286609018077;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.44581807663127876, my_classifier__penalty=l1, pca__n_components=0.9451286609018077;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8467756052442412, my_classifier__penalty=l2, pca__n_components=0.8799237653664734;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8467756052442412, my_classifier__penalty=l2, pca__n_components=0.8799237653664734;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8467756052442412, my_classifier__penalty=l2, pca__n_components=0.8799237653664734;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8467756052442412, my_classifier__penalty=l2, pca__n_components=0.8799237653664734;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8467756052442412, my_classifier__penalty=l2, pca__n_components=0.8799237653664734;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.45504003539925547, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.45504003539925547, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.45504003539925547, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.45504003539925547, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.45504003539925547, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9052145229637087;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9052145229637087;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9052145229637087;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9052145229637087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9052145229637087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6854034308904079, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6854034308904079, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6854034308904079, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6854034308904079, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6854034308904079, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8130607349400287, my_classifier__penalty=l2, pca__n_components=0.9138846549300453;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8130607349400287, my_classifier__penalty=l2, pca__n_components=0.9138846549300453;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8130607349400287, my_classifier__penalty=l2, pca__n_components=0.9138846549300453;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8130607349400287, my_classifier__penalty=l2, pca__n_components=0.9138846549300453;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8130607349400287, my_classifier__penalty=l2, pca__n_components=0.9138846549300453;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8942330949571977;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8942330949571977;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8942330949571977;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8942330949571977;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8942330949571977;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8878045919889854;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8878045919889854;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8878045919889854;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8878045919889854;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8878045919889854;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879476355332209;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879476355332209;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879476355332209;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879476355332209;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879476355332209;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877224170235753;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877224170235753;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877224170235753;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877224170235753;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877224170235753;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879110291653476;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879110291653476;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879110291653476;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879110291653476;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879110291653476;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8884149379752531;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8884149379752531;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8884149379752531;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8884149379752531;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8884149379752531;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877354243890733;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877354243890733;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877354243890733;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877354243890733;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877354243890733;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879216762236138;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879216762236138;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879216762236138;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879216762236138;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8879216762236138;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877299438450845;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877299438450845;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877299438450845;, score=(train=0.600, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877299438450845;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8877299438450845;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "best score 0.4333333333333333\n",
            "best score OrderedDict([('my_classifier__C', 0.28592723885793786), ('my_classifier__penalty', 'l1'), ('pca__n_components', 0.9401986960921764)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_5.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnaPrewxJnJC",
        "outputId": "bf676663-9275-41d8-d1d4-72962c3c2d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression TUNING WITH CV = 5 NOPCA\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', LogisticRegression(C = 1,penalty = 'l1',solver = 'liblinear'))]) # solver = liblinear best for small datasets look at documentation\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__C': Real(0.2,1),\n",
        "    'my_classifier__penalty': Categorical(['l2','l1']),\n",
        "}\n",
        "\n",
        "bayes_search_5_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "     scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_5_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_5_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_5_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9lAo-jlO9aX",
        "outputId": "4dbd1e5b-baa5-467a-ac69-dc3d521a3ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2926691999906146, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2926691999906146, my_classifier__penalty=l2;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2926691999906146, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2926691999906146, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2926691999906146, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.7888014499015874, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.7888014499015874, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.7888014499015874, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.7888014499015874, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.7888014499015874, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8834194829452322, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8834194829452322, my_classifier__penalty=l2;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8834194829452322, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8834194829452322, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8834194829452322, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5401675146665054, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5401675146665054, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5401675146665054, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5401675146665054, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5401675146665054, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6442110719731882, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6442110719731882, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6442110719731882, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6442110719731882, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6442110719731882, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.7767498344063928, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.7767498344063928, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.7767498344063928, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.7767498344063928, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.7767498344063928, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5713514768800096, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5713514768800096, my_classifier__penalty=l2;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5713514768800096, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5713514768800096, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5713514768800096, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9743743329779553, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9743743329779553, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9743743329779553, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9743743329779553, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9743743329779553, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.3524889506372492, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.3524889506372492, my_classifier__penalty=l2;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.3524889506372492, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.3524889506372492, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.3524889506372492, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8582517777752376, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8582517777752376, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8582517777752376, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8582517777752376, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8582517777752376, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2001345125366986, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2001345125366986, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2001345125366986, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2001345125366986, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2001345125366986, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2000848163917043, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2000848163917043, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2000848163917043, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2000848163917043, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2000848163917043, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.7970577862815111, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.7970577862815111, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.7970577862815111, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.7970577862815111, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.7970577862815111, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8653422258071473, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8653422258071473, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8653422258071473, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8653422258071473, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8653422258071473, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8617969892684645, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8617969892684645, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8617969892684645, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8617969892684645, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8617969892684645, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9668471480069187, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9668471480069187, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9668471480069187, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9668471480069187, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9668471480069187, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5299705000542552, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5299705000542552, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5299705000542552, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5299705000542552, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5299705000542552, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5350690073766795, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5350690073766795, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5350690073766795, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5350690073766795, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5350690073766795, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9706107404923263, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9706107404923263, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9706107404923263, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9706107404923263, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9706107404923263, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5195093778002382, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5195093778002382, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5195093778002382, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5195093778002382, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5195093778002382, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5241013132069097, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5241013132069097, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5241013132069097, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5241013132069097, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5241013132069097, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9534909857104021, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9534909857104021, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9534909857104021, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9534909857104021, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9534909857104021, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9413754404288419, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9413754404288419, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9413754404288419, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9413754404288419, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9413754404288419, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9255823619379533, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9255823619379533, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9255823619379533, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9255823619379533, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9255823619379533, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9325889978872819, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9325889978872819, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9325889978872819, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9325889978872819, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9325889978872819, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9235014559590582, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9235014559590582, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9235014559590582, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9235014559590582, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9235014559590582, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9437889099024239, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9437889099024239, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9437889099024239, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9437889099024239, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9437889099024239, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8773969880340415, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8773969880340415, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8773969880340415, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8773969880340415, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8773969880340415, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.8909379429529685, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.8909379429529685, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.8909379429529685, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.8909379429529685, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.8909379429529685, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5552268829046232, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5552268829046232, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5552268829046232, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5552268829046232, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5552268829046232, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.568792854026871, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.568792854026871, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.568792854026871, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.568792854026871, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.568792854026871, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5826530667145977, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5826530667145977, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5826530667145977, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5826530667145977, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5826530667145977, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5935632431915746, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5935632431915746, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5935632431915746, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5935632431915746, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5935632431915746, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.6077884954710037, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.6077884954710037, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.6077884954710037, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.6077884954710037, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.6077884954710037, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.5037298087698814, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.5037298087698814, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.5037298087698814, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.5037298087698814, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.5037298087698814, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.9589341685535151, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.9589341685535151, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.9589341685535151, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.9589341685535151, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.9589341685535151, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.4896052405888188, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.4896052405888188, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.4896052405888188, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.4896052405888188, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.4896052405888188, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.49632658331942164, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.49632658331942164, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.49632658331942164, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.49632658331942164, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.49632658331942164, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.4740686869522634, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.4740686869522634, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.4740686869522634, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.4740686869522634, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.4740686869522634, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.45967817199751393, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.45967817199751393, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.45967817199751393, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.45967817199751393, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.45967817199751393, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.44809487336146725, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.44809487336146725, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.44809487336146725, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.44809487336146725, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.44809487336146725, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.4330567718179952, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.4330567718179952, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.4330567718179952, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.4330567718179952, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.4330567718179952, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.4183815566839885, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.4183815566839885, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.4183815566839885, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.4183815566839885, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.4183815566839885, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.40356071706395436, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.40356071706395436, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.40356071706395436, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.40356071706395436, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.40356071706395436, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.3917365830329154, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.3917365830329154, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.3917365830329154, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.3917365830329154, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.3917365830329154, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.37642338683132603, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.37642338683132603, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.37642338683132603, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.37642338683132603, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.37642338683132603, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.287796717657637, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.287796717657637, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.287796717657637, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.287796717657637, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.287796717657637, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.3835042786486694, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.3835042786486694, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.3835042786486694, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.3835042786486694, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.3835042786486694, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__C=0.37429444167888665, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__C=0.37429444167888665, my_classifier__penalty=l1;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__C=0.37429444167888665, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__C=0.37429444167888665, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__C=0.37429444167888665, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "best score 0.4666666666666666\n",
            "best score OrderedDict([('my_classifier__C', 0.7888014499015874), ('my_classifier__penalty', 'l1')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_score = bayes_search_5_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_DRF8PLPukD",
        "outputId": "3e539b43-f19d-4370-ee62-3ad05fd021ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression TUNING WITH CV = 8 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', LogisticRegression(C = 1,penalty = 'l1',solver = 'liblinear'))]) # solver = liblinear best for small datasets look at documentation\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__C': Real(0.2,1),\n",
        "    'my_classifier__penalty': Categorical(['l2','l1']),\n",
        "    'pca__n_components':Real(0.75,0.95)\n",
        "}\n",
        "\n",
        "bayes_search_LG_8 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "     scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_LG_8.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_LG_8.best_score_))\n",
        "print('best score {}'.format(bayes_search_LG_8.best_params_))"
      ],
      "metadata": {
        "id": "MfdpemMxK66K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8322f29-94c3-4008-a81a-73c041e23c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.8135700248688471, my_classifier__penalty=l1, pca__n_components=0.8381142609860758;, score=(train=0.308, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.36493054118956914, my_classifier__penalty=l1, pca__n_components=0.8675972216732523;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.30556705273573476, my_classifier__penalty=l1, pca__n_components=0.898496752923518;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.4477158403907716, my_classifier__penalty=l2, pca__n_components=0.7883622682684989;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.37941509312674426, my_classifier__penalty=l2, pca__n_components=0.854419757781806;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.9206689921265527, my_classifier__penalty=l2, pca__n_components=0.8126124894316367;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.45148247572755573, my_classifier__penalty=l2, pca__n_components=0.8585152829240796;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.28364674855017696, my_classifier__penalty=l1, pca__n_components=0.7870905328226715;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.4209023753507196, my_classifier__penalty=l1, pca__n_components=0.7559793498787895;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.8737365933289765, my_classifier__penalty=l2, pca__n_components=0.8030204200023757;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.615, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.9780603993932282, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.571, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.571, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.7576644776198649, my_classifier__penalty=l1, pca__n_components=0.9478202544489265;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.8304611287476005, my_classifier__penalty=l1, pca__n_components=0.8062357055465261;, score=(train=0.429, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.615, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.8784769912732062, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.9231976683336203, my_classifier__penalty=l1, pca__n_components=0.8225748868319493;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.9399710469904192, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7861907786718831;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.571, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.571, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.6928252864226536, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.250, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7680828294198709;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8086831488278954;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7674980153428277;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7980501825893073;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.571, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.545, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.95;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7606254207992095;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7983204196809598;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.816865555191275;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.5995903061975836, my_classifier__penalty=l2, pca__n_components=0.9077458759558851;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.807836493320314;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8074823714631674;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7756914179914083;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7603902283116389;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8208066762711994;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8126886618603869;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7798339977837655;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8121502601527868;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7615582729884462;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7876625411425365;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7708830724262979;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.810443290940603;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8235749282034754;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.400, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.7890771520357667, my_classifier__penalty=l2, pca__n_components=0.7674780851386434;, score=(train=0.533, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8171908021411759;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7594581154922307;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.7790600302963554;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.75;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.333, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.364, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.8158801930148223;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "best score 0.7083333333333333\n",
            "best score OrderedDict([('my_classifier__C', 1.0), ('my_classifier__penalty', 'l1'), ('pca__n_components', 0.75)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_LG_8.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuYaNyJ0LrU8",
        "outputId": "1b5572ae-d8bf-46ae-e804-2b39a8c00445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression TUNING WITH CV = 8 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', LogisticRegression(C = 1,penalty = 'l1',solver = 'liblinear'))]) # solver = liblinear best for small datasets look at documentation\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__C': Real(0.2,1),\n",
        "    'my_classifier__penalty': Categorical(['l2','l1'])\n",
        "}\n",
        "\n",
        "bayes_search_LG_8_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "     scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_LG_8_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_LG_8_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_LG_8_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnudi52KZIu1",
        "outputId": "c84c6ad4-1db9-4618-fd59-201688202162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.26209592476645754, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.375760913415443, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.22499007950364727, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.7935365119322899, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.6828273201562103, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.286655781546488, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.8589492040386117, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.35774348199876926, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.45878637042100817, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.45365758247461724, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2450539033019249, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.882568241403989, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=1.0, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.33244381476344853, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.3129854168134967, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.624497355741606, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.22040026828267084, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.37083669918449025, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.3092283989711918, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2651594237044308, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.5634415032341518, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.7812737709377944, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.9589826794130805, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.3243943253650544, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.20924661925566312, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.5377708300314687, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.7091498726202294, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.23340554096734262, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.9293281092591421, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.27596050214714446, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.29744237686719327, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2550159010015689, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.3288806617630734, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.6234264716775113, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.22689393917387177, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.5083784444620651, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.20416593244117606, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.3034456236042643, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.23925213572386902, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "best score 0.3333333333333333\n",
            "best score OrderedDict([('my_classifier__C', 0.286655781546488), ('my_classifier__penalty', 'l1')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_LG_8_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89gugFcdrdeQ",
        "outputId": "a61890cb-fb38-4195-a080-f6e72b0a7cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4444444444444444"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression TUNING WITH CV = 3 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', LogisticRegression(C = 1,penalty = 'l1',solver = 'liblinear'))]) # solver = liblinear best for small datasets look at documentation\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__C': Real(0.2,1),\n",
        "    'my_classifier__penalty': Categorical(['l2','l1']),\n",
        "    'pca__n_components':Real(0.75,0.95)\n",
        "}\n",
        "\n",
        "bayes_search_LG_3 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "     scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_LG_3.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_LG_3.best_score_))\n",
        "print('best score {}'.format(bayes_search_LG_3.best_params_))"
      ],
      "metadata": {
        "id": "iXgCeqbEM30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1065a4-4d70-49b4-f1d0-62ba3e0ee803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.33406692043892317, my_classifier__penalty=l2, pca__n_components=0.9259830557480151;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.33406692043892317, my_classifier__penalty=l2, pca__n_components=0.9259830557480151;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.33406692043892317, my_classifier__penalty=l2, pca__n_components=0.9259830557480151;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.3493046885197497, my_classifier__penalty=l2, pca__n_components=0.8602270757756838;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.3493046885197497, my_classifier__penalty=l2, pca__n_components=0.8602270757756838;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.3493046885197497, my_classifier__penalty=l2, pca__n_components=0.8602270757756838;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.49012749270900907, my_classifier__penalty=l2, pca__n_components=0.8563860632634542;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.49012749270900907, my_classifier__penalty=l2, pca__n_components=0.8563860632634542;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.49012749270900907, my_classifier__penalty=l2, pca__n_components=0.8563860632634542;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.5862418004275325, my_classifier__penalty=l2, pca__n_components=0.784454385242886;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.5862418004275325, my_classifier__penalty=l2, pca__n_components=0.784454385242886;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.5862418004275325, my_classifier__penalty=l2, pca__n_components=0.784454385242886;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.962043788948499, my_classifier__penalty=l1, pca__n_components=0.7827637314466953;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.962043788948499, my_classifier__penalty=l1, pca__n_components=0.7827637314466953;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.962043788948499, my_classifier__penalty=l1, pca__n_components=0.7827637314466953;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7863255541012901, my_classifier__penalty=l2, pca__n_components=0.8615065910397389;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7863255541012901, my_classifier__penalty=l2, pca__n_components=0.8615065910397389;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7863255541012901, my_classifier__penalty=l2, pca__n_components=0.8615065910397389;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.9770458086410232, my_classifier__penalty=l1, pca__n_components=0.8263213783912229;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.9770458086410232, my_classifier__penalty=l1, pca__n_components=0.8263213783912229;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.9770458086410232, my_classifier__penalty=l1, pca__n_components=0.8263213783912229;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8521379787340868, my_classifier__penalty=l2, pca__n_components=0.8095107795249771;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8521379787340868, my_classifier__penalty=l2, pca__n_components=0.8095107795249771;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8521379787340868, my_classifier__penalty=l2, pca__n_components=0.8095107795249771;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.312617507370775, my_classifier__penalty=l1, pca__n_components=0.8004908236203683;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.312617507370775, my_classifier__penalty=l1, pca__n_components=0.8004908236203683;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.312617507370775, my_classifier__penalty=l1, pca__n_components=0.8004908236203683;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.9579333560329892, my_classifier__penalty=l1, pca__n_components=0.8019727633978703;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.9579333560329892, my_classifier__penalty=l1, pca__n_components=0.8019727633978703;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.9579333560329892, my_classifier__penalty=l1, pca__n_components=0.8019727633978703;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.20759398568736415, my_classifier__penalty=l1, pca__n_components=0.9485447819361974;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.20759398568736415, my_classifier__penalty=l1, pca__n_components=0.9485447819361974;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.20759398568736415, my_classifier__penalty=l1, pca__n_components=0.9485447819361974;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.95;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2022779030541516, my_classifier__penalty=l1, pca__n_components=0.7527176923604549;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2022779030541516, my_classifier__penalty=l1, pca__n_components=0.7527176923604549;, score=(train=0.333, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2022779030541516, my_classifier__penalty=l1, pca__n_components=0.7527176923604549;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8136604191317942, my_classifier__penalty=l1, pca__n_components=0.7777586725963356;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8136604191317942, my_classifier__penalty=l1, pca__n_components=0.7777586725963356;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8136604191317942, my_classifier__penalty=l1, pca__n_components=0.7777586725963356;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.6652145284436182, my_classifier__penalty=l1, pca__n_components=0.7665593174481393;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.6652145284436182, my_classifier__penalty=l1, pca__n_components=0.7665593174481393;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.6652145284436182, my_classifier__penalty=l1, pca__n_components=0.7665593174481393;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.3815848039372498, my_classifier__penalty=l1, pca__n_components=0.7561745467902945;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.3815848039372498, my_classifier__penalty=l1, pca__n_components=0.7561745467902945;, score=(train=0.333, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.3815848039372498, my_classifier__penalty=l1, pca__n_components=0.7561745467902945;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.9911669626759112, my_classifier__penalty=l2, pca__n_components=0.9494941611486325;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.9911669626759112, my_classifier__penalty=l2, pca__n_components=0.9494941611486325;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.9911669626759112, my_classifier__penalty=l2, pca__n_components=0.9494941611486325;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.20013261735420207, my_classifier__penalty=l2, pca__n_components=0.9492092043938088;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.20013261735420207, my_classifier__penalty=l2, pca__n_components=0.9492092043938088;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.20013261735420207, my_classifier__penalty=l2, pca__n_components=0.9492092043938088;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4107599334397445, my_classifier__penalty=l2, pca__n_components=0.7998580398664508;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4107599334397445, my_classifier__penalty=l2, pca__n_components=0.7998580398664508;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4107599334397445, my_classifier__penalty=l2, pca__n_components=0.7998580398664508;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.6699789295522078, my_classifier__penalty=l1, pca__n_components=0.8562528730257967;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.6699789295522078, my_classifier__penalty=l1, pca__n_components=0.8562528730257967;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.6699789295522078, my_classifier__penalty=l1, pca__n_components=0.8562528730257967;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.44199570998452503, my_classifier__penalty=l2, pca__n_components=0.7531008193830908;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.44199570998452503, my_classifier__penalty=l2, pca__n_components=0.7531008193830908;, score=(train=0.769, test=0.667) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.44199570998452503, my_classifier__penalty=l2, pca__n_components=0.7531008193830908;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7394516170868173, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7394516170868173, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7394516170868173, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.6729887009985195, my_classifier__penalty=l1, pca__n_components=0.9027147026324753;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.6729887009985195, my_classifier__penalty=l1, pca__n_components=0.9027147026324753;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.6729887009985195, my_classifier__penalty=l1, pca__n_components=0.9027147026324753;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8356559148724265, my_classifier__penalty=l2, pca__n_components=0.893908993570181;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8356559148724265, my_classifier__penalty=l2, pca__n_components=0.893908993570181;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8356559148724265, my_classifier__penalty=l2, pca__n_components=0.893908993570181;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8612029234259648, my_classifier__penalty=l2, pca__n_components=0.8327475455917299;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8612029234259648, my_classifier__penalty=l2, pca__n_components=0.8327475455917299;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8612029234259648, my_classifier__penalty=l2, pca__n_components=0.8327475455917299;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.333, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8742661516445933, my_classifier__penalty=l2, pca__n_components=0.7546965287087142;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8742661516445933, my_classifier__penalty=l2, pca__n_components=0.7546965287087142;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8742661516445933, my_classifier__penalty=l2, pca__n_components=0.7546965287087142;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.872882242688733, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.872882242688733, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.872882242688733, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7586367042363069;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7586367042363069;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7586367042363069;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8574406451388836, my_classifier__penalty=l1, pca__n_components=0.7524552653183844;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8574406451388836, my_classifier__penalty=l1, pca__n_components=0.7524552653183844;, score=(train=0.333, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8574406451388836, my_classifier__penalty=l1, pca__n_components=0.7524552653183844;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8700144387023196, my_classifier__penalty=l2, pca__n_components=0.7523761514563349;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8700144387023196, my_classifier__penalty=l2, pca__n_components=0.7523761514563349;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8700144387023196, my_classifier__penalty=l2, pca__n_components=0.7523761514563349;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8650927387459011, my_classifier__penalty=l2, pca__n_components=0.7510345363528927;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8650927387459011, my_classifier__penalty=l2, pca__n_components=0.7510345363528927;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8650927387459011, my_classifier__penalty=l2, pca__n_components=0.7510345363528927;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8011496273447547, my_classifier__penalty=l2, pca__n_components=0.753848132406189;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8011496273447547, my_classifier__penalty=l2, pca__n_components=0.753848132406189;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8011496273447547, my_classifier__penalty=l2, pca__n_components=0.753848132406189;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7535141040998412;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7535141040998412;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.7535141040998412;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.751671745705626;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.751671745705626;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=1.0, my_classifier__penalty=l2, pca__n_components=0.751671745705626;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.878080338957594;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.878080338957594;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1, pca__n_components=0.878080338957594;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9168356394999511;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9168356394999511;, score=(train=0.750, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=1.0, my_classifier__penalty=l1, pca__n_components=0.9168356394999511;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.9006684690155375, my_classifier__penalty=l2, pca__n_components=0.7537571619542861;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.9006684690155375, my_classifier__penalty=l2, pca__n_components=0.7537571619542861;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.9006684690155375, my_classifier__penalty=l2, pca__n_components=0.7537571619542861;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7917577025208442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7917577025208442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7917577025208442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8003395584825037, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8003395584825037, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8003395584825037, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7986934323008292, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7986934323008292, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7986934323008292, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.790359587531237, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.790359587531237, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.790359587531237, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7911811693876736, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7911811693876736, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7911811693876736, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8058124486155573, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8058124486155573, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8058124486155573, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8057692558496099, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8057692558496099, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8057692558496099, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8025251511965081, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8025251511965081, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8025251511965081, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8048460440391614, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8048460440391614, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8048460440391614, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8079814760385442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8079814760385442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8079814760385442, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7896932325012309, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.571, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7896932325012309, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7896932325012309, my_classifier__penalty=l2, pca__n_components=0.75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "best score 0.5079365079365079\n",
            "best score OrderedDict([('my_classifier__C', 0.7394516170868173), ('my_classifier__penalty', 'l2'), ('pca__n_components', 0.75)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_LG_3.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOi8enK9N7so",
        "outputId": "a95fb12f-fab0-470e-f3fb-091935a388a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression TUNING WITH CV = 3 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', LogisticRegression(C = 1,penalty = 'l1',solver = 'liblinear'))]) # solver = liblinear best for small datasets look at documentation\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__C': Real(0.2,1),\n",
        "    'my_classifier__penalty': Categorical(['l2','l1']),\n",
        "}\n",
        "\n",
        "bayes_search_LG_3_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "     scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_LG_3_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_LG_3_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_LG_3_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TO68_8VzfLA",
        "outputId": "b74ce246-f38a-4be0-b59e-f8d88c63f5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.38922052150226755, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.38922052150226755, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.38922052150226755, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.39842177584253446, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.39842177584253446, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.39842177584253446, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7872796966352802, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7872796966352802, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7872796966352802, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.3174733576942668, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.3174733576942668, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.3174733576942668, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4448246319428657, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4448246319428657, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4448246319428657, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.9445468899261387, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.9445468899261387, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.9445468899261387, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.46679638357883996, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.46679638357883996, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.46679638357883996, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.6779984816282134, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.6779984816282134, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.6779984816282134, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.31697945495659685, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.31697945495659685, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.31697945495659685, my_classifier__penalty=l2;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8652413053233767, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8652413053233767, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8652413053233767, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.9999828987518105, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.9999828987518105, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.9999828987518105, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7092450467633087, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7092450467633087, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7092450467633087, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8006458015207123, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8006458015207123, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8006458015207123, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.7865602882129039, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.7865602882129039, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.7865602882129039, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.593696564789749, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.593696564789749, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.593696564789749, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.25013562000779194, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.25013562000779194, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.25013562000779194, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.531946809946706, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.531946809946706, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.531946809946706, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.6529472056306251, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.6529472056306251, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.6529472056306251, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8351642332495022, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8351642332495022, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8351642332495022, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.3707107971075778, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.3707107971075778, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.3707107971075778, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4198081175106312, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4198081175106312, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4198081175106312, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.41460854273777054, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.41460854273777054, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.41460854273777054, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4209483686785087, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4209483686785087, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4209483686785087, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.8960966196219045, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.8960966196219045, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.8960966196219045, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.37260454955601924, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.37260454955601924, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.37260454955601924, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4322750567760546, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4322750567760546, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4322750567760546, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4074701715789148, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4074701715789148, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4074701715789148, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4265246637851793, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4265246637851793, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4265246637851793, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4144488858720963, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4144488858720963, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4144488858720963, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4192309653350599, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4192309653350599, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4192309653350599, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4466044045176068, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4466044045176068, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4466044045176068, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.43554160062471303, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.43554160062471303, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.43554160062471303, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4594904193523501, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4594904193523501, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4594904193523501, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4649700660546752, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4649700660546752, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4649700660546752, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4576765947141366, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4576765947141366, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4576765947141366, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.4854559056937741, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.4854559056937741, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.4854559056937741, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.49915944892979935, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.49915944892979935, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.49915944892979935, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.5184072075682054, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.5184072075682054, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.5184072075682054, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__C=0.2, my_classifier__penalty=l1;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "best score 0.26666666666666666\n",
            "best score OrderedDict([('my_classifier__C', 0.38922052150226755), ('my_classifier__penalty', 'l1')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_LG_3_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnJpmjWQzpFA",
        "outputId": "4512fd03-bf68-4623-d457-7a8474145e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4444444444444444"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN TUNING CV = 5 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', KNeighborsClassifier(n_neighbors=9,\n",
        "                                               algorithm='ball_tree')),\n",
        "    ]\n",
        ")\n",
        "#XGBClassifier(objective='binary:logistic', seed=1)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_neighbors': Integer(2,9),\n",
        "    'my_classifier__p': Integer(1,2),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "\n",
        "# but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
        "# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n",
        "# n_iter is the parameter set to the number of parameter settings tried. \n",
        "# in previous trials 30 fits were used so i will use n_iter to 6. \n",
        "\n",
        "bayes_search_KNN_CV5 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=100, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_KNN_CV5.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_KNN_CV5.best_score_))\n",
        "print('best score {}'.format(bayes_search_KNN_CV5.best_params_))"
      ],
      "metadata": {
        "id": "aZj9w3Da9QcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b791d898-7cfe-457a-ee6f-acffd99a46d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7559632828098387;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7559632828098387;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7559632828098387;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7559632828098387;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7559632828098387;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7791736710730228;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7791736710730228;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7791736710730228;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7791736710730228;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7791736710730228;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8712507066552064;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8712507066552064;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8712507066552064;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8712507066552064;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8712507066552064;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7911206588171227;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7911206588171227;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7911206588171227;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7911206588171227;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7911206588171227;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8694286397624821;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8694286397624821;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8694286397624821;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8694286397624821;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8694286397624821;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7784432027874575;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7784432027874575;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7784432027874575;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7784432027874575;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7784432027874575;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7853927806337877;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7853927806337877;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7853927806337877;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7853927806337877;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7853927806337877;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8157994309530429;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8157994309530429;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8157994309530429;, score=(train=0.615, test=0.667) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8157994309530429;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8157994309530429;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.823882340996873;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.823882340996873;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.823882340996873;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.823882340996873;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.823882340996873;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.7608090657581772;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.7608090657581772;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.7608090657581772;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.7608090657581772;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.7608090657581772;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8494118392969723;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8494118392969723;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8494118392969723;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8494118392969723;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8494118392969723;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8537819175410923;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8537819175410923;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8537819175410923;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8537819175410923;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8537819175410923;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8582925080498486;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8582925080498486;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8582925080498486;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8582925080498486;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8582925080498486;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8597409343143881;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8597409343143881;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8597409343143881;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8597409343143881;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8597409343143881;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8659345437289367;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8659345437289367;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8659345437289367;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8659345437289367;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8659345437289367;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7002696942915793;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7002696942915793;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7002696942915793;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7002696942915793;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7002696942915793;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.7394130885563079;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.7394130885563079;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.7394130885563079;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.7394130885563079;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.7394130885563079;, score=(train=0.857, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999382761848516;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999382761848516;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999382761848516;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999382761848516;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999382761848516;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002215283219838;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002215283219838;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002215283219838;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002215283219838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002215283219838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001170827975622;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001170827975622;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001170827975622;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001170827975622;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001170827975622;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994753123810549;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994753123810549;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994753123810549;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994753123810549;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994753123810549;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7043741664279408;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7043741664279408;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7043741664279408;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7043741664279408;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7043741664279408;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7642179057127914;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7642179057127914;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7642179057127914;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7642179057127914;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7642179057127914;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7999836180237134;, score=(train=0.500, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7999836180237134;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7999836180237134;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7999836180237134;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7999836180237134;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7195592727317642;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7195592727317642;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7195592727317642;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7195592727317642;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7195592727317642;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.894025433890065;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.894025433890065;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.894025433890065;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.894025433890065;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.894025433890065;, score=(train=0.857, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999980955754625;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999980955754625;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999980955754625;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999980955754625;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999980955754625;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700043999230613;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700043999230613;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700043999230613;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700043999230613;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700043999230613;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998174869784679;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998174869784679;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998174869784679;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998174869784679;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998174869784679;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999594588047112;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999594588047112;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999594588047112;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999594588047112;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999594588047112;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000588662379443;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000588662379443;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000588662379443;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000588662379443;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000588662379443;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7001863662503413;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7001863662503413;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7001863662503413;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7001863662503413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7001863662503413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.899988142192837;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.899988142192837;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.899988142192837;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.899988142192837;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.899988142192837;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999533969510588;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999533969510588;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999533969510588;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999533969510588;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999533969510588;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999815000991209;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999815000991209;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999815000991209;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999815000991209;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999815000991209;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000043584525075;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000043584525075;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000043584525075;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000043584525075;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000043584525075;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8995107824045233;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8995107824045233;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8995107824045233;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8995107824045233;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8995107824045233;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999347169487137;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999347169487137;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999347169487137;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999347169487137;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8999347169487137;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001664653498535;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001664653498535;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001664653498535;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001664653498535;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001664653498535;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000564543079362;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000564543079362;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000564543079362;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000564543079362;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000564543079362;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "best score 0.7866666666666666\n",
            "best score OrderedDict([('my_classifier__n_neighbors', 9), ('my_classifier__p', 1), ('pca__n_components', 0.7002696942915793)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_KNN_CV5.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "id": "ZvrX819-JboE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3763e6f-4028-40f1-813d-c2f182a4f0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN TUNING CV = 5 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', KNeighborsClassifier(n_neighbors=9,\n",
        "                                               algorithm='ball_tree')),\n",
        "    ]\n",
        ")\n",
        "#XGBClassifier(objective='binary:logistic', seed=1)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_neighbors': Integer(2,9),\n",
        "    'my_classifier__p': Integer(1,2),\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "bayes_search_KNN_CV5_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=100, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_KNN_CV5_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_KNN_CV5_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_KNN_CV5_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRaaFBnBCHxz",
        "outputId": "2ab72990-0e1a-4379-b43a-582a39fb15a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.667, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.714, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.769, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.769, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.714, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.769, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.714, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.667, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.714, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.667, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.714, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.875, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.750, test=1.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "best score 0.7866666666666666\n",
            "best score OrderedDict([('my_classifier__n_neighbors', 9), ('my_classifier__p', 2)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_KNN_CV5_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZfwwrQVCVTA",
        "outputId": "c890ca04-a049-4e9c-e528-fcdea6e4fc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN TUNING CV = 8 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', KNeighborsClassifier(n_neighbors=9,\n",
        "                                               algorithm='ball_tree')),\n",
        "    ]\n",
        ")\n",
        "#XGBClassifier(objective='binary:logistic', seed=1)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_neighbors': Integer(2,9),\n",
        "    'my_classifier__p': Integer(1,2),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "\n",
        "# but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
        "# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n",
        "# n_iter is the parameter set to the number of parameter settings tried. \n",
        "# in previous trials 30 fits were used so i will use n_iter to 6. \n",
        "\n",
        "bayes_search_KNN_CV8 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=100, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_KNN_CV8.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_KNN_CV8.best_score_))\n",
        "print('best score {}'.format(bayes_search_KNN_CV8.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biRo5wbdCzlb",
        "outputId": "9abcf356-9ae1-4a1c-8a46-5a8b64c00804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8180491356470827;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.745782960425685;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8810872718157637;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8619587559785331;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.7112393126562273;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.833157032830292;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=4, my_classifier__p=2, pca__n_components=0.8103960415736708;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.8603973595994798;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.8720948372583526;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.8940113433692787;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.72429818191579;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.7693556533934599;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=5, my_classifier__p=2, pca__n_components=0.895154857487012;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8994915308746021;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7004565955502475;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.700376092980565;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.899724532551192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8991615377580018;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8602457639065576;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999835135201246;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002425516212692;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8999485516480896;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7000302285805987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002302752756947;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001756272510036;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8998258584153801;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7002721574352562;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000668347351595;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997795175030499;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7003481912233168;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.8997209618391192;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8993716583939992;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000907455632047;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7001749662220497;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7004343181411318;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.9;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.7009527301116987;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2, pca__n_components=0.89861153657885;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.7000007088918452;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1, pca__n_components=0.8997791712745308;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "best score 0.8333333333333333\n",
            "best score OrderedDict([('my_classifier__n_neighbors', 9), ('my_classifier__p', 2), ('pca__n_components', 0.8619587559785331)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_KNN_CV8.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDPbL3MgC_Rg",
        "outputId": "d6017772-2d48-44d9-be06-42b2b0c35844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN TUNING CV = 8 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', KNeighborsClassifier(n_neighbors=9,\n",
        "                                               algorithm='ball_tree'))\n",
        "    ]\n",
        ")\n",
        "#XGBClassifier(objective='binary:logistic', seed=1)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_neighbors': Integer(2,9),\n",
        "    'my_classifier__p': Integer(1,2),\n",
        "}\n",
        "\n",
        "\n",
        "# but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
        "# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n",
        "# n_iter is the parameter set to the number of parameter settings tried. \n",
        "# in previous trials 30 fits were used so i will use n_iter to 6. \n",
        "\n",
        "bayes_search_KNN_CV8_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_KNN_CV8_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_KNN_CV8_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_KNN_CV8_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AZY1xHsDfd5",
        "outputId": "55370015-d035-4966-f565-ced48eb4970f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.750, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.750, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.714, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.714, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.750, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.857, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.714, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.625, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.706, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.625, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.706, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.857, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.714, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.714, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.600, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.727, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.625, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.706, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.625, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.706, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=2;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__n_neighbors=9, my_classifier__p=1;, score=(train=0.778, test=1.000) total time=   0.0s\n",
            "best score 0.8333333333333333\n",
            "best score OrderedDict([('my_classifier__n_neighbors', 9), ('my_classifier__p', 2)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_KNN_CV8_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dbpy7MrGEWL",
        "outputId": "fa0eecaf-7b55-400d-efce-e659c7827b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN TUNING CV = 3 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', KNeighborsClassifier(n_neighbors=9,\n",
        "                                               algorithm='ball_tree')),\n",
        "    ]\n",
        ")\n",
        "#XGBClassifier(objective='binary:logistic', seed=1)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_neighbors': Integer(2,8),\n",
        "    'my_classifier__p': Integer(1,2),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "\n",
        "# but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
        "# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n",
        "# n_iter is the parameter set to the number of parameter settings tried. \n",
        "# in previous trials 30 fits were used so i will use n_iter to 6. \n",
        "\n",
        "bayes_search_KNN_CV3 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_KNN_CV3.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_KNN_CV3.best_score_))\n",
        "print('best score {}'.format(bayes_search_KNN_CV3.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVWTewVPEIYy",
        "outputId": "84d59fef-e50d-44dc-9d58-e9e3da040e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8874334885396616;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8874334885396616;, score=(train=0.333, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8874334885396616;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.711874390418785;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.711874390418785;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.711874390418785;, score=(train=0.727, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8785229125973736;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8785229125973736;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8785229125973736;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8779019946653619;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8779019946653619;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8779019946653619;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7316611432819822;, score=(train=0.750, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7316611432819822;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7316611432819822;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.7037208599125533;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.7037208599125533;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.7037208599125533;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8995566839533518;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8995566839533518;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8995566839533518;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.719579439237539;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.719579439237539;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.719579439237539;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.7189493989859026;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.7189493989859026;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=4, my_classifier__p=1, pca__n_components=0.7189493989859026;, score=(train=0.727, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7913338359079487;, score=(train=0.750, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7913338359079487;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=3, my_classifier__p=2, pca__n_components=0.7913338359079487;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8620472383259626;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8620472383259626;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8620472383259626;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.861728086275819;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.861728086275819;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=2, my_classifier__p=1, pca__n_components=0.861728086275819;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8111441499050539;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8111441499050539;, score=(train=0.333, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1, pca__n_components=0.8111441499050539;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7015560824384858;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7015560824384858;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7015560824384858;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8992984741595504;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8992984741595504;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8992984741595504;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.7012776993891706;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.7012776993891706;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.7012776993891706;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7003300861751462;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7003300861751462;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7003300861751462;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.700654422064004;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.700654422064004;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.700654422064004;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8986915404125867;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8986915404125867;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8986915404125867;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8999578298911713;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8999578298911713;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8999578298911713;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7005511825381509;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7005511825381509;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7005511825381509;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8997587282637037;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8997587282637037;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8997587282637037;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7008630997336175;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7008630997336175;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7008630997336175;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.7000111597119526;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.7000111597119526;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.7000111597119526;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.899664621518061;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.899664621518061;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.899664621518061;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8999755126012857;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8999755126012857;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.8999755126012857;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7000363053605249;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7000363053605249;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.7000363053605249;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8640918043401458;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8640918043401458;, score=(train=0.333, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=6, my_classifier__p=1, pca__n_components=0.8640918043401458;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8998966561390174;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8998966561390174;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1, pca__n_components=0.8998966561390174;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8980358699265891;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8980358699265891;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8980358699265891;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.7000101995115042;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.7000101995115042;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.7000101995115042;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7002726140989675;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7002726140989675;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2, pca__n_components=0.7002726140989675;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8204993361032639;, score=(train=0.750, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8204993361032639;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=3, my_classifier__p=1, pca__n_components=0.8204993361032639;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8993566829113415;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8993566829113415;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8993566829113415;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.898508730847958;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.898508730847958;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.898508730847958;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8962284688556474;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8962284688556474;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8962284688556474;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8986621997378063;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8986621997378063;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8986621997378063;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8979014771585258;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8979014771585258;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8979014771585258;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.776980564841004;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.776980564841004;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=2, my_classifier__p=2, pca__n_components=0.776980564841004;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8978460286482003;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8978460286482003;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2, pca__n_components=0.8978460286482003;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7263988696047126;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7263988696047126;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=6, my_classifier__p=2, pca__n_components=0.7263988696047126;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8975559971926766;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8975559971926766;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8975559971926766;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8978653574335576;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8978653574335576;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8978653574335576;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8993104994246536;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8993104994246536;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8993104994246536;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8991872837882244;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8991872837882244;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8991872837882244;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8989708358936253;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8989708358936253;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8989708358936253;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.899288222206792;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.899288222206792;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.899288222206792;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8992111590844407;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8992111590844407;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8992111590844407;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8987412368028668;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8987412368028668;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8987412368028668;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8987158471643866;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8987158471643866;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1, pca__n_components=0.8987158471643866;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "best score 0.7936507936507936\n",
            "best score OrderedDict([('my_classifier__n_neighbors', 7), ('my_classifier__p', 1), ('pca__n_components', 0.8785229125973736)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_KNN_CV3.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNljEEMDotE",
        "outputId": "ef330f91-3e4f-4635-9d85-758f18e0a36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN TUNING CV = 3 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', KNeighborsClassifier(n_neighbors=9,\n",
        "                                               algorithm='ball_tree')),\n",
        "    ]\n",
        ")\n",
        "#XGBClassifier(objective='binary:logistic', seed=1)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_neighbors': Integer(2,8),\n",
        "    'my_classifier__p': Integer(1,2),\n",
        "}\n",
        "\n",
        "\n",
        "# but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
        "# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n",
        "# n_iter is the parameter set to the number of parameter settings tried. \n",
        "# in previous trials 30 fits were used so i will use n_iter to 6. \n",
        "\n",
        "bayes_search_KNN_CV3_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_KNN_CV3_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_KNN_CV3_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_KNN_CV3_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgb0VTJGG7pO",
        "outputId": "0ec16f15-88e5-4cbf-8cb6-71935deb0a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.571, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=4, my_classifier__p=2;, score=(train=0.833, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.727, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.571, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.833, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=3, my_classifier__p=2;, score=(train=0.923, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.333, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.333, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=6, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=6, my_classifier__p=2;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=6, my_classifier__p=2;, score=(train=0.333, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=6, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=2, my_classifier__p=2;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.857, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=2, my_classifier__p=1;, score=(train=0.571, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=2, my_classifier__p=1;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=2, my_classifier__p=1;, score=(train=0.667, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=8, my_classifier__p=2;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=3, my_classifier__p=1;, score=(train=0.857, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=4, my_classifier__p=1;, score=(train=0.833, test=0.400) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.727, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=5, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__n_neighbors=7, my_classifier__p=1;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "best score 0.7936507936507936\n",
            "best score OrderedDict([('my_classifier__n_neighbors', 8), ('my_classifier__p', 2)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_KNN_CV3_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wESX4D6dHLGy",
        "outputId": "231341b8-fe31-4adf-f101-5444372d325a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADA CV 5 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', AdaBoostClassifier(n_estimators=20,learning_rate=0.001)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(20,50),\n",
        "    'my_classifier__learning_rate': Real(0.0001,0.001),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "bayes_search_ADA_CV5 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_ADA_CV5.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_ADA_CV5.best_score_))\n",
        "print('best score {}'.format(bayes_search_ADA_CV5.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVew7GW6HuwA",
        "outputId": "b9b94971-b004-4c4d-b6be-e9579acb56c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000423141555743155, my_classifier__n_estimators=24, pca__n_components=0.7088766265157999;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000423141555743155, my_classifier__n_estimators=24, pca__n_components=0.7088766265157999;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000423141555743155, my_classifier__n_estimators=24, pca__n_components=0.7088766265157999;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000423141555743155, my_classifier__n_estimators=24, pca__n_components=0.7088766265157999;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000423141555743155, my_classifier__n_estimators=24, pca__n_components=0.7088766265157999;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008135581120732217, my_classifier__n_estimators=50, pca__n_components=0.8720224577331509;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008135581120732217, my_classifier__n_estimators=50, pca__n_components=0.8720224577331509;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008135581120732217, my_classifier__n_estimators=50, pca__n_components=0.8720224577331509;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008135581120732217, my_classifier__n_estimators=50, pca__n_components=0.8720224577331509;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008135581120732217, my_classifier__n_estimators=50, pca__n_components=0.8720224577331509;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009397541686532161, my_classifier__n_estimators=28, pca__n_components=0.8809832855018458;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009397541686532161, my_classifier__n_estimators=28, pca__n_components=0.8809832855018458;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009397541686532161, my_classifier__n_estimators=28, pca__n_components=0.8809832855018458;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009397541686532161, my_classifier__n_estimators=28, pca__n_components=0.8809832855018458;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009397541686532161, my_classifier__n_estimators=28, pca__n_components=0.8809832855018458;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008077735912844402, my_classifier__n_estimators=49, pca__n_components=0.7220174905121591;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008077735912844402, my_classifier__n_estimators=49, pca__n_components=0.7220174905121591;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008077735912844402, my_classifier__n_estimators=49, pca__n_components=0.7220174905121591;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008077735912844402, my_classifier__n_estimators=49, pca__n_components=0.7220174905121591;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008077735912844402, my_classifier__n_estimators=49, pca__n_components=0.7220174905121591;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000614270211333445, my_classifier__n_estimators=32, pca__n_components=0.8758909228960273;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000614270211333445, my_classifier__n_estimators=32, pca__n_components=0.8758909228960273;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000614270211333445, my_classifier__n_estimators=32, pca__n_components=0.8758909228960273;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000614270211333445, my_classifier__n_estimators=32, pca__n_components=0.8758909228960273;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000614270211333445, my_classifier__n_estimators=32, pca__n_components=0.8758909228960273;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005678667745911209, my_classifier__n_estimators=32, pca__n_components=0.8643309422020535;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005678667745911209, my_classifier__n_estimators=32, pca__n_components=0.8643309422020535;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005678667745911209, my_classifier__n_estimators=32, pca__n_components=0.8643309422020535;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005678667745911209, my_classifier__n_estimators=32, pca__n_components=0.8643309422020535;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005678667745911209, my_classifier__n_estimators=32, pca__n_components=0.8643309422020535;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005517769116803871, my_classifier__n_estimators=41, pca__n_components=0.77406583144855;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005517769116803871, my_classifier__n_estimators=41, pca__n_components=0.77406583144855;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005517769116803871, my_classifier__n_estimators=41, pca__n_components=0.77406583144855;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005517769116803871, my_classifier__n_estimators=41, pca__n_components=0.77406583144855;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005517769116803871, my_classifier__n_estimators=41, pca__n_components=0.77406583144855;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0007797497082503, my_classifier__n_estimators=50, pca__n_components=0.8667377804701137;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0007797497082503, my_classifier__n_estimators=50, pca__n_components=0.8667377804701137;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0007797497082503, my_classifier__n_estimators=50, pca__n_components=0.8667377804701137;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0007797497082503, my_classifier__n_estimators=50, pca__n_components=0.8667377804701137;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0007797497082503, my_classifier__n_estimators=50, pca__n_components=0.8667377804701137;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0007359025476744375, my_classifier__n_estimators=36, pca__n_components=0.8863196288086672;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0007359025476744375, my_classifier__n_estimators=36, pca__n_components=0.8863196288086672;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0007359025476744375, my_classifier__n_estimators=36, pca__n_components=0.8863196288086672;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0007359025476744375, my_classifier__n_estimators=36, pca__n_components=0.8863196288086672;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0007359025476744375, my_classifier__n_estimators=36, pca__n_components=0.8863196288086672;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0006742782551033776, my_classifier__n_estimators=40, pca__n_components=0.8358580144192713;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0006742782551033776, my_classifier__n_estimators=40, pca__n_components=0.8358580144192713;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0006742782551033776, my_classifier__n_estimators=40, pca__n_components=0.8358580144192713;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0006742782551033776, my_classifier__n_estimators=40, pca__n_components=0.8358580144192713;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0006742782551033776, my_classifier__n_estimators=40, pca__n_components=0.8358580144192713;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0003099996983473141, my_classifier__n_estimators=45, pca__n_components=0.7444858926187035;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0003099996983473141, my_classifier__n_estimators=45, pca__n_components=0.7444858926187035;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0003099996983473141, my_classifier__n_estimators=45, pca__n_components=0.7444858926187035;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0003099996983473141, my_classifier__n_estimators=45, pca__n_components=0.7444858926187035;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0003099996983473141, my_classifier__n_estimators=45, pca__n_components=0.7444858926187035;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0007691999002145103, my_classifier__n_estimators=36, pca__n_components=0.8142211521218978;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0007691999002145103, my_classifier__n_estimators=36, pca__n_components=0.8142211521218978;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0007691999002145103, my_classifier__n_estimators=36, pca__n_components=0.8142211521218978;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0007691999002145103, my_classifier__n_estimators=36, pca__n_components=0.8142211521218978;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0007691999002145103, my_classifier__n_estimators=36, pca__n_components=0.8142211521218978;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0002609758059269027, my_classifier__n_estimators=31, pca__n_components=0.8614469373782958;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0002609758059269027, my_classifier__n_estimators=31, pca__n_components=0.8614469373782958;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0002609758059269027, my_classifier__n_estimators=31, pca__n_components=0.8614469373782958;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0002609758059269027, my_classifier__n_estimators=31, pca__n_components=0.8614469373782958;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0002609758059269027, my_classifier__n_estimators=31, pca__n_components=0.8614469373782958;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0006656049184012835, my_classifier__n_estimators=26, pca__n_components=0.7974438696484;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0006656049184012835, my_classifier__n_estimators=26, pca__n_components=0.7974438696484;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0006656049184012835, my_classifier__n_estimators=26, pca__n_components=0.7974438696484;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0006656049184012835, my_classifier__n_estimators=26, pca__n_components=0.7974438696484;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0006656049184012835, my_classifier__n_estimators=26, pca__n_components=0.7974438696484;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00031233002332917115, my_classifier__n_estimators=28, pca__n_components=0.7487998363860963;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00031233002332917115, my_classifier__n_estimators=28, pca__n_components=0.7487998363860963;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00031233002332917115, my_classifier__n_estimators=28, pca__n_components=0.7487998363860963;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00031233002332917115, my_classifier__n_estimators=28, pca__n_components=0.7487998363860963;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00031233002332917115, my_classifier__n_estimators=28, pca__n_components=0.7487998363860963;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000889321202251766, my_classifier__n_estimators=50, pca__n_components=0.8067351144956741;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000889321202251766, my_classifier__n_estimators=50, pca__n_components=0.8067351144956741;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000889321202251766, my_classifier__n_estimators=50, pca__n_components=0.8067351144956741;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000889321202251766, my_classifier__n_estimators=50, pca__n_components=0.8067351144956741;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000889321202251766, my_classifier__n_estimators=50, pca__n_components=0.8067351144956741;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00011628993144895757, my_classifier__n_estimators=21, pca__n_components=0.7009218988575587;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00011628993144895757, my_classifier__n_estimators=21, pca__n_components=0.7009218988575587;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00011628993144895757, my_classifier__n_estimators=21, pca__n_components=0.7009218988575587;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00011628993144895757, my_classifier__n_estimators=21, pca__n_components=0.7009218988575587;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00011628993144895757, my_classifier__n_estimators=21, pca__n_components=0.7009218988575587;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000993148267505199, my_classifier__n_estimators=21, pca__n_components=0.7021162809935745;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000993148267505199, my_classifier__n_estimators=21, pca__n_components=0.7021162809935745;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000993148267505199, my_classifier__n_estimators=21, pca__n_components=0.7021162809935745;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000993148267505199, my_classifier__n_estimators=21, pca__n_components=0.7021162809935745;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000993148267505199, my_classifier__n_estimators=21, pca__n_components=0.7021162809935745;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00010790608845436458, my_classifier__n_estimators=50, pca__n_components=0.7030370211303647;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00010790608845436458, my_classifier__n_estimators=50, pca__n_components=0.7030370211303647;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00010790608845436458, my_classifier__n_estimators=50, pca__n_components=0.7030370211303647;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00010790608845436458, my_classifier__n_estimators=50, pca__n_components=0.7030370211303647;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00010790608845436458, my_classifier__n_estimators=50, pca__n_components=0.7030370211303647;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00011051153828429786, my_classifier__n_estimators=20, pca__n_components=0.8964256596347875;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00011051153828429786, my_classifier__n_estimators=20, pca__n_components=0.8964256596347875;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00011051153828429786, my_classifier__n_estimators=20, pca__n_components=0.8964256596347875;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00011051153828429786, my_classifier__n_estimators=20, pca__n_components=0.8964256596347875;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00011051153828429786, my_classifier__n_estimators=20, pca__n_components=0.8964256596347875;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00084112451528081, my_classifier__n_estimators=39, pca__n_components=0.8940152100756518;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00084112451528081, my_classifier__n_estimators=39, pca__n_components=0.8940152100756518;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00084112451528081, my_classifier__n_estimators=39, pca__n_components=0.8940152100756518;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00084112451528081, my_classifier__n_estimators=39, pca__n_components=0.8940152100756518;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00084112451528081, my_classifier__n_estimators=39, pca__n_components=0.8940152100756518;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000540421900635354, my_classifier__n_estimators=37, pca__n_components=0.8674349460283378;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000540421900635354, my_classifier__n_estimators=37, pca__n_components=0.8674349460283378;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000540421900635354, my_classifier__n_estimators=37, pca__n_components=0.8674349460283378;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000540421900635354, my_classifier__n_estimators=37, pca__n_components=0.8674349460283378;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000540421900635354, my_classifier__n_estimators=37, pca__n_components=0.8674349460283378;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00012950019978832152, my_classifier__n_estimators=30, pca__n_components=0.728851222957006;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00012950019978832152, my_classifier__n_estimators=30, pca__n_components=0.728851222957006;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00012950019978832152, my_classifier__n_estimators=30, pca__n_components=0.728851222957006;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00012950019978832152, my_classifier__n_estimators=30, pca__n_components=0.728851222957006;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00012950019978832152, my_classifier__n_estimators=30, pca__n_components=0.728851222957006;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0007244564900306302, my_classifier__n_estimators=49, pca__n_components=0.8023473442785938;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0007244564900306302, my_classifier__n_estimators=49, pca__n_components=0.8023473442785938;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0007244564900306302, my_classifier__n_estimators=49, pca__n_components=0.8023473442785938;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0007244564900306302, my_classifier__n_estimators=49, pca__n_components=0.8023473442785938;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0007244564900306302, my_classifier__n_estimators=49, pca__n_components=0.8023473442785938;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00011501100030275205, my_classifier__n_estimators=50, pca__n_components=0.7077144745031415;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00011501100030275205, my_classifier__n_estimators=50, pca__n_components=0.7077144745031415;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00011501100030275205, my_classifier__n_estimators=50, pca__n_components=0.7077144745031415;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00011501100030275205, my_classifier__n_estimators=50, pca__n_components=0.7077144745031415;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00011501100030275205, my_classifier__n_estimators=50, pca__n_components=0.7077144745031415;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000976785730218305, my_classifier__n_estimators=34, pca__n_components=0.7087756918305166;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000976785730218305, my_classifier__n_estimators=34, pca__n_components=0.7087756918305166;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000976785730218305, my_classifier__n_estimators=34, pca__n_components=0.7087756918305166;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000976785730218305, my_classifier__n_estimators=34, pca__n_components=0.7087756918305166;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000976785730218305, my_classifier__n_estimators=34, pca__n_components=0.7087756918305166;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00021130612466820585, my_classifier__n_estimators=36, pca__n_components=0.7081810224805402;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00021130612466820585, my_classifier__n_estimators=36, pca__n_components=0.7081810224805402;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00021130612466820585, my_classifier__n_estimators=36, pca__n_components=0.7081810224805402;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00021130612466820585, my_classifier__n_estimators=36, pca__n_components=0.7081810224805402;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00021130612466820585, my_classifier__n_estimators=36, pca__n_components=0.7081810224805402;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0003727185577453925, my_classifier__n_estimators=48, pca__n_components=0.8134568138750178;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0003727185577453925, my_classifier__n_estimators=48, pca__n_components=0.8134568138750178;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0003727185577453925, my_classifier__n_estimators=48, pca__n_components=0.8134568138750178;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0003727185577453925, my_classifier__n_estimators=48, pca__n_components=0.8134568138750178;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0003727185577453925, my_classifier__n_estimators=48, pca__n_components=0.8134568138750178;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005626721865166198, my_classifier__n_estimators=39, pca__n_components=0.8949835032971898;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005626721865166198, my_classifier__n_estimators=39, pca__n_components=0.8949835032971898;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005626721865166198, my_classifier__n_estimators=39, pca__n_components=0.8949835032971898;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005626721865166198, my_classifier__n_estimators=39, pca__n_components=0.8949835032971898;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005626721865166198, my_classifier__n_estimators=39, pca__n_components=0.8949835032971898;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00021267479688895558, my_classifier__n_estimators=39, pca__n_components=0.8292883467678028;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00021267479688895558, my_classifier__n_estimators=39, pca__n_components=0.8292883467678028;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00021267479688895558, my_classifier__n_estimators=39, pca__n_components=0.8292883467678028;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00021267479688895558, my_classifier__n_estimators=39, pca__n_components=0.8292883467678028;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00021267479688895558, my_classifier__n_estimators=39, pca__n_components=0.8292883467678028;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009897411637826766, my_classifier__n_estimators=35, pca__n_components=0.7905432298198334;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009897411637826766, my_classifier__n_estimators=35, pca__n_components=0.7905432298198334;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009897411637826766, my_classifier__n_estimators=35, pca__n_components=0.7905432298198334;, score=(train=0.909, test=0.000) total time=   0.2s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009897411637826766, my_classifier__n_estimators=35, pca__n_components=0.7905432298198334;, score=(train=0.727, test=1.000) total time=   0.3s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009897411637826766, my_classifier__n_estimators=35, pca__n_components=0.7905432298198334;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005081735044890531, my_classifier__n_estimators=41, pca__n_components=0.8973799519317802;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005081735044890531, my_classifier__n_estimators=41, pca__n_components=0.8973799519317802;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005081735044890531, my_classifier__n_estimators=41, pca__n_components=0.8973799519317802;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005081735044890531, my_classifier__n_estimators=41, pca__n_components=0.8973799519317802;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005081735044890531, my_classifier__n_estimators=41, pca__n_components=0.8973799519317802;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009774587755677626, my_classifier__n_estimators=43, pca__n_components=0.8530691094950487;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009774587755677626, my_classifier__n_estimators=43, pca__n_components=0.8530691094950487;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009774587755677626, my_classifier__n_estimators=43, pca__n_components=0.8530691094950487;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009774587755677626, my_classifier__n_estimators=43, pca__n_components=0.8530691094950487;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009774587755677626, my_classifier__n_estimators=43, pca__n_components=0.8530691094950487;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0006078528202565089, my_classifier__n_estimators=41, pca__n_components=0.897199239278025;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0006078528202565089, my_classifier__n_estimators=41, pca__n_components=0.897199239278025;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0006078528202565089, my_classifier__n_estimators=41, pca__n_components=0.897199239278025;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0006078528202565089, my_classifier__n_estimators=41, pca__n_components=0.897199239278025;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0006078528202565089, my_classifier__n_estimators=41, pca__n_components=0.897199239278025;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0006103328032151681, my_classifier__n_estimators=45, pca__n_components=0.7304591417191407;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0006103328032151681, my_classifier__n_estimators=45, pca__n_components=0.7304591417191407;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0006103328032151681, my_classifier__n_estimators=45, pca__n_components=0.7304591417191407;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0006103328032151681, my_classifier__n_estimators=45, pca__n_components=0.7304591417191407;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0006103328032151681, my_classifier__n_estimators=45, pca__n_components=0.7304591417191407;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005207583599644017, my_classifier__n_estimators=24, pca__n_components=0.7900567007439794;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005207583599644017, my_classifier__n_estimators=24, pca__n_components=0.7900567007439794;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005207583599644017, my_classifier__n_estimators=24, pca__n_components=0.7900567007439794;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005207583599644017, my_classifier__n_estimators=24, pca__n_components=0.7900567007439794;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005207583599644017, my_classifier__n_estimators=24, pca__n_components=0.7900567007439794;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00032137465511958714, my_classifier__n_estimators=29, pca__n_components=0.7692223873949132;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00032137465511958714, my_classifier__n_estimators=29, pca__n_components=0.7692223873949132;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00032137465511958714, my_classifier__n_estimators=29, pca__n_components=0.7692223873949132;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00032137465511958714, my_classifier__n_estimators=29, pca__n_components=0.7692223873949132;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00032137465511958714, my_classifier__n_estimators=29, pca__n_components=0.7692223873949132;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00022711332463025153, my_classifier__n_estimators=46, pca__n_components=0.7392809023073844;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00022711332463025153, my_classifier__n_estimators=46, pca__n_components=0.7392809023073844;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00022711332463025153, my_classifier__n_estimators=46, pca__n_components=0.7392809023073844;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00022711332463025153, my_classifier__n_estimators=46, pca__n_components=0.7392809023073844;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00022711332463025153, my_classifier__n_estimators=46, pca__n_components=0.7392809023073844;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00012657493497138686, my_classifier__n_estimators=34, pca__n_components=0.7587705639861515;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00012657493497138686, my_classifier__n_estimators=34, pca__n_components=0.7587705639861515;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00012657493497138686, my_classifier__n_estimators=34, pca__n_components=0.7587705639861515;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00012657493497138686, my_classifier__n_estimators=34, pca__n_components=0.7587705639861515;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00012657493497138686, my_classifier__n_estimators=34, pca__n_components=0.7587705639861515;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00011794255349004244, my_classifier__n_estimators=34, pca__n_components=0.7384329766111173;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00011794255349004244, my_classifier__n_estimators=34, pca__n_components=0.7384329766111173;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00011794255349004244, my_classifier__n_estimators=34, pca__n_components=0.7384329766111173;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00011794255349004244, my_classifier__n_estimators=34, pca__n_components=0.7384329766111173;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00011794255349004244, my_classifier__n_estimators=34, pca__n_components=0.7384329766111173;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005186849081727691, my_classifier__n_estimators=28, pca__n_components=0.8558066264278186;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005186849081727691, my_classifier__n_estimators=28, pca__n_components=0.8558066264278186;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005186849081727691, my_classifier__n_estimators=28, pca__n_components=0.8558066264278186;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005186849081727691, my_classifier__n_estimators=28, pca__n_components=0.8558066264278186;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005186849081727691, my_classifier__n_estimators=28, pca__n_components=0.8558066264278186;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00020952716979307043, my_classifier__n_estimators=29, pca__n_components=0.7783454041552219;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00020952716979307043, my_classifier__n_estimators=29, pca__n_components=0.7783454041552219;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00020952716979307043, my_classifier__n_estimators=29, pca__n_components=0.7783454041552219;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00020952716979307043, my_classifier__n_estimators=29, pca__n_components=0.7783454041552219;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00020952716979307043, my_classifier__n_estimators=29, pca__n_components=0.7783454041552219;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00012375889612205974, my_classifier__n_estimators=30, pca__n_components=0.8924788002914366;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00012375889612205974, my_classifier__n_estimators=30, pca__n_components=0.8924788002914366;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00012375889612205974, my_classifier__n_estimators=30, pca__n_components=0.8924788002914366;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00012375889612205974, my_classifier__n_estimators=30, pca__n_components=0.8924788002914366;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00012375889612205974, my_classifier__n_estimators=30, pca__n_components=0.8924788002914366;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "best score 0.6\n",
            "best score OrderedDict([('my_classifier__learning_rate', 0.000423141555743155), ('my_classifier__n_estimators', 24), ('pca__n_components', 0.7088766265157999)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_ADA_CV5.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxK7gpB3I1Fw",
        "outputId": "abb7e5dd-881d-47b4-c4fc-dce36213429b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADA CV 5 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', AdaBoostClassifier(n_estimators=20,learning_rate=0.001)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(20,50),\n",
        "    'my_classifier__learning_rate': Real(0.0001,0.001),\n",
        "}\n",
        "\n",
        "bayes_search_ADA_CV5_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_ADA_CV5_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_ADA_CV5_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_ADA_CV5_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZnwZqWxJe6z",
        "outputId": "56fe1997-c08b-4026-e757-ea1109fb95dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0006961925128924297, my_classifier__n_estimators=35;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0006961925128924297, my_classifier__n_estimators=35;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0006961925128924297, my_classifier__n_estimators=35;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0006961925128924297, my_classifier__n_estimators=35;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0006961925128924297, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0002794885210279957, my_classifier__n_estimators=26;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0002794885210279957, my_classifier__n_estimators=26;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0002794885210279957, my_classifier__n_estimators=26;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0002794885210279957, my_classifier__n_estimators=26;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0002794885210279957, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005836520655892349, my_classifier__n_estimators=33;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005836520655892349, my_classifier__n_estimators=33;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005836520655892349, my_classifier__n_estimators=33;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005836520655892349, my_classifier__n_estimators=33;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005836520655892349, my_classifier__n_estimators=33;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0004875232479557219, my_classifier__n_estimators=45;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0004875232479557219, my_classifier__n_estimators=45;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0004875232479557219, my_classifier__n_estimators=45;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0004875232479557219, my_classifier__n_estimators=45;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0004875232479557219, my_classifier__n_estimators=45;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00026572936605523964, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00026572936605523964, my_classifier__n_estimators=46;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00026572936605523964, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00026572936605523964, my_classifier__n_estimators=46;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00026572936605523964, my_classifier__n_estimators=46;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008531519775458523, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008531519775458523, my_classifier__n_estimators=46;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008531519775458523, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008531519775458523, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008531519775458523, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.00039991129415184326, my_classifier__n_estimators=32;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.00039991129415184326, my_classifier__n_estimators=32;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.00039991129415184326, my_classifier__n_estimators=32;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.00039991129415184326, my_classifier__n_estimators=32;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.00039991129415184326, my_classifier__n_estimators=32;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0006967142160320439, my_classifier__n_estimators=25;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0006967142160320439, my_classifier__n_estimators=25;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0006967142160320439, my_classifier__n_estimators=25;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0006967142160320439, my_classifier__n_estimators=25;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0006967142160320439, my_classifier__n_estimators=25;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0002574456172981344, my_classifier__n_estimators=21;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0002574456172981344, my_classifier__n_estimators=21;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0002574456172981344, my_classifier__n_estimators=21;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0002574456172981344, my_classifier__n_estimators=21;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0002574456172981344, my_classifier__n_estimators=21;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005367296230614813, my_classifier__n_estimators=35;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005367296230614813, my_classifier__n_estimators=35;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005367296230614813, my_classifier__n_estimators=35;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005367296230614813, my_classifier__n_estimators=35;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005367296230614813, my_classifier__n_estimators=35;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000906117581199849, my_classifier__n_estimators=48;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000906117581199849, my_classifier__n_estimators=48;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000906117581199849, my_classifier__n_estimators=48;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000906117581199849, my_classifier__n_estimators=48;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000906117581199849, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008020364283210557, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008020364283210557, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008020364283210557, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008020364283210557, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008020364283210557, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008474543273458656, my_classifier__n_estimators=43;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008474543273458656, my_classifier__n_estimators=43;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008474543273458656, my_classifier__n_estimators=43;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008474543273458656, my_classifier__n_estimators=43;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008474543273458656, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008578783312479533, my_classifier__n_estimators=48;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008578783312479533, my_classifier__n_estimators=48;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008578783312479533, my_classifier__n_estimators=48;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008578783312479533, my_classifier__n_estimators=48;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008578783312479533, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008859307189727683, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008859307189727683, my_classifier__n_estimators=46;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008859307189727683, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008859307189727683, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008859307189727683, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0007846966633249815, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0007846966633249815, my_classifier__n_estimators=46;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0007846966633249815, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0007846966633249815, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0007846966633249815, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009666827677414656, my_classifier__n_estimators=48;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009666827677414656, my_classifier__n_estimators=48;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009666827677414656, my_classifier__n_estimators=48;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009666827677414656, my_classifier__n_estimators=48;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009666827677414656, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009309648986033851, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009309648986033851, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009309648986033851, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009309648986033851, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009309648986033851, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=43;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=43;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=43;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=43;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009695903011559723, my_classifier__n_estimators=45;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009695903011559723, my_classifier__n_estimators=45;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009695903011559723, my_classifier__n_estimators=45;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009695903011559723, my_classifier__n_estimators=45;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009695903011559723, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=35;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=35;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=35;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=35;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=35;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0007284291945419215, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0007284291945419215, my_classifier__n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0007284291945419215, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0007284291945419215, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0007284291945419215, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.000842762857755487, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.000842762857755487, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.000842762857755487, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.000842762857755487, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.000842762857755487, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0005000092710595735, my_classifier__n_estimators=20;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0005000092710595735, my_classifier__n_estimators=20;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0005000092710595735, my_classifier__n_estimators=20;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0005000092710595735, my_classifier__n_estimators=20;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0005000092710595735, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008995521598205312, my_classifier__n_estimators=30;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008995521598205312, my_classifier__n_estimators=30;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008995521598205312, my_classifier__n_estimators=30;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008995521598205312, my_classifier__n_estimators=30;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008995521598205312, my_classifier__n_estimators=30;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008431268419094291, my_classifier__n_estimators=47;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008431268419094291, my_classifier__n_estimators=47;, score=(train=0.909, test=0.500) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008431268419094291, my_classifier__n_estimators=47;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008431268419094291, my_classifier__n_estimators=47;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008431268419094291, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008544725830216921, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008544725830216921, my_classifier__n_estimators=46;, score=(train=0.909, test=0.500) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008544725830216921, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008544725830216921, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008544725830216921, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009885206203379174, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009885206203379174, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009885206203379174, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009885206203379174, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009885206203379174, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009998719417899124, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009998719417899124, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009998719417899124, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009998719417899124, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009998719417899124, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008451688621162138, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008451688621162138, my_classifier__n_estimators=46;, score=(train=0.800, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008451688621162138, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008451688621162138, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008451688621162138, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008506392574107976, my_classifier__n_estimators=47;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008506392574107976, my_classifier__n_estimators=47;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008506392574107976, my_classifier__n_estimators=47;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008506392574107976, my_classifier__n_estimators=47;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008506392574107976, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008525307377045466, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008525307377045466, my_classifier__n_estimators=46;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008525307377045466, my_classifier__n_estimators=46;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008525307377045466, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008525307377045466, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0009324481056040472, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0009324481056040472, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0009324481056040472, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0009324481056040472, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0009324481056040472, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__learning_rate=0.0008517135950468244, my_classifier__n_estimators=47;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__learning_rate=0.0008517135950468244, my_classifier__n_estimators=47;, score=(train=0.909, test=1.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__learning_rate=0.0008517135950468244, my_classifier__n_estimators=47;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__learning_rate=0.0008517135950468244, my_classifier__n_estimators=47;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 5/5] END my_classifier__learning_rate=0.0008517135950468244, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "best score 0.4666666666666666\n",
            "best score OrderedDict([('my_classifier__learning_rate', 0.0008531519775458523), ('my_classifier__n_estimators', 46)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_ADA_CV5_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjfwKo8UJo6Y",
        "outputId": "ddbff83d-7efe-48bf-9f82-f3cd3369cbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5454545454545454"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADA CV 8 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', AdaBoostClassifier(n_estimators=20,learning_rate=0.001)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(20,50),\n",
        "    'my_classifier__learning_rate': Real(0.0001,0.001),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "bayes_search_ADA_CV8 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_ADA_CV8.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_ADA_CV8.best_score_))\n",
        "print('best score {}'.format(bayes_search_ADA_CV8.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt9ml93_JwrD",
        "outputId": "0df60cd6-71fe-4071-fdef-e49b61ba86c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009045532482646951, my_classifier__n_estimators=30, pca__n_components=0.8899344991516559;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001124005376123999, my_classifier__n_estimators=43, pca__n_components=0.7189725937409956;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0005838844983924415, my_classifier__n_estimators=44, pca__n_components=0.7918257052545015;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00017916730044012643, my_classifier__n_estimators=24, pca__n_components=0.7605191726796316;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009766485023131504, my_classifier__n_estimators=45, pca__n_components=0.7278934303433607;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0002482597959454726, my_classifier__n_estimators=29, pca__n_components=0.783716782319454;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009658558846165342, my_classifier__n_estimators=21, pca__n_components=0.7090179193974612;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008920874304133699, my_classifier__n_estimators=25, pca__n_components=0.7813588796704414;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0003212485543495387, my_classifier__n_estimators=39, pca__n_components=0.8488932537583946;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006024517072116748, my_classifier__n_estimators=48, pca__n_components=0.8932021928485259;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00010014285173159278, my_classifier__n_estimators=22, pca__n_components=0.8996316609114741;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.727, test=1.000) total time=   0.2s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001242711070088968, my_classifier__n_estimators=50, pca__n_components=0.7013538247061729;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009936435753352439, my_classifier__n_estimators=20, pca__n_components=0.7150808500269353;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000974998485242641, my_classifier__n_estimators=49, pca__n_components=0.8958164089685687;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009772244027387643, my_classifier__n_estimators=20, pca__n_components=0.8994877104580705;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00010449985714411109, my_classifier__n_estimators=20, pca__n_components=0.7061078555871164;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00012116606462102321, my_classifier__n_estimators=50, pca__n_components=0.8976377574003298;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009783802635074678, my_classifier__n_estimators=49, pca__n_components=0.7044375768882379;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001083459725123198, my_classifier__n_estimators=22, pca__n_components=0.8976136050534442;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000988747281669487, my_classifier__n_estimators=50, pca__n_components=0.8957879252795928;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000128590261690912, my_classifier__n_estimators=50, pca__n_components=0.7049531184733445;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009889572773768359, my_classifier__n_estimators=20, pca__n_components=0.8949152659813923;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009962755202864862, my_classifier__n_estimators=20, pca__n_components=0.7066446382863483;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009529507359907634, my_classifier__n_estimators=50, pca__n_components=0.7017574200836131;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00012377111083996517, my_classifier__n_estimators=21, pca__n_components=0.8992512840183899;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00012398450839561006, my_classifier__n_estimators=21, pca__n_components=0.7031891240500655;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00014093590355319875, my_classifier__n_estimators=50, pca__n_components=0.8928905237950409;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009993545443173894, my_classifier__n_estimators=50, pca__n_components=0.8984671999642352;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00010549516599413407, my_classifier__n_estimators=50, pca__n_components=0.7016286481540099;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009988523880646906, my_classifier__n_estimators=50, pca__n_components=0.70123452431819;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00010578245314176563, my_classifier__n_estimators=20, pca__n_components=0.8986601304893447;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009712148875636994, my_classifier__n_estimators=20, pca__n_components=0.8989432578201165;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009839569949890163, my_classifier__n_estimators=50, pca__n_components=0.8947586639116478;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00010720170310090442, my_classifier__n_estimators=20, pca__n_components=0.7035699018677398;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00011360152164104234, my_classifier__n_estimators=49, pca__n_components=0.8993309649794583;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009870051835596213, my_classifier__n_estimators=20, pca__n_components=0.89991673119465;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00011569442981888119, my_classifier__n_estimators=21, pca__n_components=0.7026594970139436;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.727, test=1.000) total time=   0.2s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00010815474207841218, my_classifier__n_estimators=49, pca__n_components=0.8996760855235668;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009716099654317788, my_classifier__n_estimators=50, pca__n_components=0.7057309841170157;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009932824520441411, my_classifier__n_estimators=20, pca__n_components=0.7062467642228903;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001147836299393601, my_classifier__n_estimators=49, pca__n_components=0.7039585759258618;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00012699725989210843, my_classifier__n_estimators=20, pca__n_components=0.894258293438187;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00011189238470693079, my_classifier__n_estimators=49, pca__n_components=0.7010562272841306;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009757919094419265, my_classifier__n_estimators=49, pca__n_components=0.8975380191136487;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009960839263888095, my_classifier__n_estimators=21, pca__n_components=0.7051672716863537;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "best score 0.625\n",
            "best score OrderedDict([('my_classifier__learning_rate', 0.0009045532482646951), ('my_classifier__n_estimators', 30), ('pca__n_components', 0.8899344991516559)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_ADA_CV8.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IRT6dKgHjRA",
        "outputId": "b1c87034-58f6-4a41-9d26-95428ec8f9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADA CV 8 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', AdaBoostClassifier(n_estimators=20,learning_rate=0.001)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(20,50),\n",
        "    'my_classifier__learning_rate': Real(0.0001,0.001),\n",
        "}\n",
        "\n",
        "bayes_search_ADA_CV8_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_ADA_CV8_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_ADA_CV8_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_ADA_CV8_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_hczwruJ6eT",
        "outputId": "87fcdf50-ecf3-4909-d3ee-b4899baa4284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0003639183195257233, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00043621639278150536, my_classifier__n_estimators=47;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0005414332983090017, my_classifier__n_estimators=32;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0004596235226750826, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0005439477364054267, my_classifier__n_estimators=40;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0007083893378606697, my_classifier__n_estimators=30;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008475005482461859, my_classifier__n_estimators=49;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006032847547056007, my_classifier__n_estimators=46;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008153424697815966, my_classifier__n_estimators=25;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000775812076222585, my_classifier__n_estimators=38;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008577951317750011, my_classifier__n_estimators=44;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0007628038745856146, my_classifier__n_estimators=35;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006139626762680571, my_classifier__n_estimators=42;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006421753775732101, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008931406444469952, my_classifier__n_estimators=47;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006305191242545049, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0007655953981667256, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006795423738377758, my_classifier__n_estimators=44;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009228449610505054, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006358330903295603, my_classifier__n_estimators=43;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008340352815385603, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000374906154576737, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009446035037576396, my_classifier__n_estimators=41;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=29;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=22;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001938929807925169, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00011674868069251871, my_classifier__n_estimators=26;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=37;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=48;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=43;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000907778508393062, my_classifier__n_estimators=45;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0008758795952548327, my_classifier__n_estimators=45;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009854660722997876, my_classifier__n_estimators=35;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009613847245988106, my_classifier__n_estimators=42;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00020066594212533157, my_classifier__n_estimators=33;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00018785690101527332, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006090566991436485, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=39;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00016897671123016308, my_classifier__n_estimators=23;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=46;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0006938564388189655, my_classifier__n_estimators=40;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0001642539726807877, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0009305103287757629, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.727, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0002638327136164232, my_classifier__n_estimators=24;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0007249404996239701, my_classifier__n_estimators=42;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.000510449548237723, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=0.933, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=0.923, test=1.000) total time=   0.1s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.0005877760323300846, my_classifier__n_estimators=50;, score=(train=0.833, test=0.000) total time=   0.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.727, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__learning_rate=0.00013580646216244534, my_classifier__n_estimators=20;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "best score 0.4583333333333333\n",
            "best score OrderedDict([('my_classifier__learning_rate', 0.0008475005482461859), ('my_classifier__n_estimators', 49)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_ADA_CV8.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHHUYgdRJ8t0",
        "outputId": "dbaab530-9bdd-42d4-a136-96c37f7fb995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADA CV 3 PCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', AdaBoostClassifier(n_estimators=20,learning_rate=0.001)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(20,50),\n",
        "    'my_classifier__learning_rate': Real(0.0001,0.001),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "bayes_search_ADA_CV3 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_ADA_CV3.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_ADA_CV3.best_score_))\n",
        "print('best score {}'.format(bayes_search_ADA_CV3.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X67Ow_9KJ7WG",
        "outputId": "e4187992-ef97-4fb8-8495-ce835ff2dc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00020809736056394054, my_classifier__n_estimators=28, pca__n_components=0.8310361558010824;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00020809736056394054, my_classifier__n_estimators=28, pca__n_components=0.8310361558010824;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00020809736056394054, my_classifier__n_estimators=28, pca__n_components=0.8310361558010824;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0003775447965247461, my_classifier__n_estimators=44, pca__n_components=0.7706682077979372;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0003775447965247461, my_classifier__n_estimators=44, pca__n_components=0.7706682077979372;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0003775447965247461, my_classifier__n_estimators=44, pca__n_components=0.7706682077979372;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0002880685661163184, my_classifier__n_estimators=43, pca__n_components=0.7210837435125135;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0002880685661163184, my_classifier__n_estimators=43, pca__n_components=0.7210837435125135;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0002880685661163184, my_classifier__n_estimators=43, pca__n_components=0.7210837435125135;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006469939855237906, my_classifier__n_estimators=41, pca__n_components=0.7355127891697606;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006469939855237906, my_classifier__n_estimators=41, pca__n_components=0.7355127891697606;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006469939855237906, my_classifier__n_estimators=41, pca__n_components=0.7355127891697606;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00045329250284265775, my_classifier__n_estimators=35, pca__n_components=0.8684260716044101;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00045329250284265775, my_classifier__n_estimators=35, pca__n_components=0.8684260716044101;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00045329250284265775, my_classifier__n_estimators=35, pca__n_components=0.8684260716044101;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006343106795939532, my_classifier__n_estimators=41, pca__n_components=0.7373343424619961;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006343106795939532, my_classifier__n_estimators=41, pca__n_components=0.7373343424619961;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006343106795939532, my_classifier__n_estimators=41, pca__n_components=0.7373343424619961;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0008132281119151569, my_classifier__n_estimators=26, pca__n_components=0.8179580901320463;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0008132281119151569, my_classifier__n_estimators=26, pca__n_components=0.8179580901320463;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0008132281119151569, my_classifier__n_estimators=26, pca__n_components=0.8179580901320463;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0004766347568745052, my_classifier__n_estimators=22, pca__n_components=0.8145623817608332;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0004766347568745052, my_classifier__n_estimators=22, pca__n_components=0.8145623817608332;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0004766347568745052, my_classifier__n_estimators=22, pca__n_components=0.8145623817608332;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00046035515734697, my_classifier__n_estimators=42, pca__n_components=0.8601877608154795;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00046035515734697, my_classifier__n_estimators=42, pca__n_components=0.8601877608154795;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00046035515734697, my_classifier__n_estimators=42, pca__n_components=0.8601877608154795;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00031802816498857015, my_classifier__n_estimators=41, pca__n_components=0.8349448705635614;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00031802816498857015, my_classifier__n_estimators=41, pca__n_components=0.8349448705635614;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00031802816498857015, my_classifier__n_estimators=41, pca__n_components=0.8349448705635614;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.000987372425319185, my_classifier__n_estimators=21, pca__n_components=0.8977184570415506;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.000987372425319185, my_classifier__n_estimators=21, pca__n_components=0.8977184570415506;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.000987372425319185, my_classifier__n_estimators=21, pca__n_components=0.8977184570415506;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=32, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=32, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=32, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009875480702937296, my_classifier__n_estimators=38, pca__n_components=0.8932581633590797;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009875480702937296, my_classifier__n_estimators=38, pca__n_components=0.8932581633590797;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009875480702937296, my_classifier__n_estimators=38, pca__n_components=0.8932581633590797;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010299244031750478, my_classifier__n_estimators=34, pca__n_components=0.8842577725600617;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010299244031750478, my_classifier__n_estimators=34, pca__n_components=0.8842577725600617;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010299244031750478, my_classifier__n_estimators=34, pca__n_components=0.8842577725600617;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0007259884245052404, my_classifier__n_estimators=20, pca__n_components=0.8822261583027318;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0007259884245052404, my_classifier__n_estimators=20, pca__n_components=0.8822261583027318;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0007259884245052404, my_classifier__n_estimators=20, pca__n_components=0.8822261583027318;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0007884652639947166, my_classifier__n_estimators=35, pca__n_components=0.8991454251158193;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0007884652639947166, my_classifier__n_estimators=35, pca__n_components=0.8991454251158193;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0007884652639947166, my_classifier__n_estimators=35, pca__n_components=0.8991454251158193;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=47, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=47, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=47, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=24, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=24, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=24, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0003778870746183268, my_classifier__n_estimators=50, pca__n_components=0.8889337978317975;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0003778870746183268, my_classifier__n_estimators=50, pca__n_components=0.8889337978317975;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0003778870746183268, my_classifier__n_estimators=50, pca__n_components=0.8889337978317975;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0005418196078142377, my_classifier__n_estimators=28, pca__n_components=0.8906810833859802;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0005418196078142377, my_classifier__n_estimators=28, pca__n_components=0.8906810833859802;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0005418196078142377, my_classifier__n_estimators=28, pca__n_components=0.8906810833859802;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0002496755980841564, my_classifier__n_estimators=49, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0002496755980841564, my_classifier__n_estimators=49, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0002496755980841564, my_classifier__n_estimators=49, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00028231537658800996, my_classifier__n_estimators=20, pca__n_components=0.7015426652940446;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00028231537658800996, my_classifier__n_estimators=20, pca__n_components=0.7015426652940446;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00028231537658800996, my_classifier__n_estimators=20, pca__n_components=0.7015426652940446;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=40, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=40, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=40, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006279168706016071, my_classifier__n_estimators=47, pca__n_components=0.898518709076027;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006279168706016071, my_classifier__n_estimators=47, pca__n_components=0.898518709076027;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006279168706016071, my_classifier__n_estimators=47, pca__n_components=0.898518709076027;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00027184179317863685, my_classifier__n_estimators=34, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00027184179317863685, my_classifier__n_estimators=34, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00027184179317863685, my_classifier__n_estimators=34, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0005275056393758495, my_classifier__n_estimators=46, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0005275056393758495, my_classifier__n_estimators=46, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0005275056393758495, my_classifier__n_estimators=46, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00036386466428526415, my_classifier__n_estimators=26, pca__n_components=0.7018168479525115;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00036386466428526415, my_classifier__n_estimators=26, pca__n_components=0.7018168479525115;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00036386466428526415, my_classifier__n_estimators=26, pca__n_components=0.7018168479525115;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0005916999202147693, my_classifier__n_estimators=50, pca__n_components=0.7053073095820779;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0005916999202147693, my_classifier__n_estimators=50, pca__n_components=0.7053073095820779;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0005916999202147693, my_classifier__n_estimators=50, pca__n_components=0.7053073095820779;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009999668349738558, my_classifier__n_estimators=26, pca__n_components=0.7121858311292181;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009999668349738558, my_classifier__n_estimators=26, pca__n_components=0.7121858311292181;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009999668349738558, my_classifier__n_estimators=26, pca__n_components=0.7121858311292181;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009021004897995409, my_classifier__n_estimators=37, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009021004897995409, my_classifier__n_estimators=37, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009021004897995409, my_classifier__n_estimators=37, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006580743954706478, my_classifier__n_estimators=24, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006580743954706478, my_classifier__n_estimators=24, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006580743954706478, my_classifier__n_estimators=24, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006474388254415562, my_classifier__n_estimators=33, pca__n_components=0.704591510150649;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006474388254415562, my_classifier__n_estimators=33, pca__n_components=0.704591510150649;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006474388254415562, my_classifier__n_estimators=33, pca__n_components=0.704591510150649;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0008518637323484768, my_classifier__n_estimators=43, pca__n_components=0.8949331287359439;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0008518637323484768, my_classifier__n_estimators=43, pca__n_components=0.8949331287359439;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0008518637323484768, my_classifier__n_estimators=43, pca__n_components=0.8949331287359439;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0008223155040304998, my_classifier__n_estimators=40, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0008223155040304998, my_classifier__n_estimators=40, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0008223155040304998, my_classifier__n_estimators=40, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010043361345828731, my_classifier__n_estimators=30, pca__n_components=0.7426941785283033;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010043361345828731, my_classifier__n_estimators=30, pca__n_components=0.7426941785283033;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010043361345828731, my_classifier__n_estimators=30, pca__n_components=0.7426941785283033;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009978858528431726, my_classifier__n_estimators=42, pca__n_components=0.7178570827076479;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009978858528431726, my_classifier__n_estimators=42, pca__n_components=0.7178570827076479;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009978858528431726, my_classifier__n_estimators=42, pca__n_components=0.7178570827076479;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0008312712458432409, my_classifier__n_estimators=30, pca__n_components=0.8959510701663301;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0008312712458432409, my_classifier__n_estimators=30, pca__n_components=0.8959510701663301;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0008312712458432409, my_classifier__n_estimators=30, pca__n_components=0.8959510701663301;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00040436774737656123, my_classifier__n_estimators=31, pca__n_components=0.7003919529115612;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00040436774737656123, my_classifier__n_estimators=31, pca__n_components=0.7003919529115612;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00040436774737656123, my_classifier__n_estimators=31, pca__n_components=0.7003919529115612;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0005230105219769242, my_classifier__n_estimators=20, pca__n_components=0.7004434756688026;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0005230105219769242, my_classifier__n_estimators=20, pca__n_components=0.7004434756688026;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0005230105219769242, my_classifier__n_estimators=20, pca__n_components=0.7004434756688026;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0008575936377464938, my_classifier__n_estimators=22, pca__n_components=0.7218764557709234;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0008575936377464938, my_classifier__n_estimators=22, pca__n_components=0.7218764557709234;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0008575936377464938, my_classifier__n_estimators=22, pca__n_components=0.7218764557709234;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006070601828986935, my_classifier__n_estimators=37, pca__n_components=0.7035436311915603;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006070601828986935, my_classifier__n_estimators=37, pca__n_components=0.7035436311915603;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006070601828986935, my_classifier__n_estimators=37, pca__n_components=0.7035436311915603;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0005060724028580456, my_classifier__n_estimators=49, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0005060724028580456, my_classifier__n_estimators=49, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0005060724028580456, my_classifier__n_estimators=49, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0002551919035364465, my_classifier__n_estimators=23, pca__n_components=0.8946998521098302;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0002551919035364465, my_classifier__n_estimators=23, pca__n_components=0.8946998521098302;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0002551919035364465, my_classifier__n_estimators=23, pca__n_components=0.8946998521098302;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009418630996669083, my_classifier__n_estimators=41, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009418630996669083, my_classifier__n_estimators=41, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009418630996669083, my_classifier__n_estimators=41, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00020095866229209134, my_classifier__n_estimators=37, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00020095866229209134, my_classifier__n_estimators=37, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00020095866229209134, my_classifier__n_estimators=37, pca__n_components=0.9;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010359213670931513, my_classifier__n_estimators=43, pca__n_components=0.8912421264437723;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010359213670931513, my_classifier__n_estimators=43, pca__n_components=0.8912421264437723;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010359213670931513, my_classifier__n_estimators=43, pca__n_components=0.8912421264437723;, score=(train=0.800, test=0.667) total time=   0.1s\n",
            "best score 0.5555555555555555\n",
            "best score OrderedDict([('my_classifier__learning_rate', 0.00020809736056394054), ('my_classifier__n_estimators', 28), ('pca__n_components', 0.8310361558010824)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_ADA_CV3.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMt5bDhhK1jL",
        "outputId": "0f9a2e40-c4df-4fb9-e0c2-5b04c2486130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADA CV 3 NOPCA\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', AdaBoostClassifier(n_estimators=20,learning_rate=0.001)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(20,50),\n",
        "    'my_classifier__learning_rate': Real(0.0001,0.001),\n",
        "}\n",
        "\n",
        "bayes_search_ADA_CV3_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_ADA_CV3_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_ADA_CV3_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_ADA_CV3_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o7_dHBmK5dS",
        "outputId": "006ba971-a4ba-4735-cf44-3d10b77b8b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009347720373534687, my_classifier__n_estimators=36;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009347720373534687, my_classifier__n_estimators=36;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009347720373534687, my_classifier__n_estimators=36;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00044431284330044503, my_classifier__n_estimators=26;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00044431284330044503, my_classifier__n_estimators=26;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00044431284330044503, my_classifier__n_estimators=26;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001516777091948141, my_classifier__n_estimators=35;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001516777091948141, my_classifier__n_estimators=35;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001516777091948141, my_classifier__n_estimators=35;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0004310675150758739, my_classifier__n_estimators=37;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0004310675150758739, my_classifier__n_estimators=37;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0004310675150758739, my_classifier__n_estimators=37;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.000664267507068017, my_classifier__n_estimators=22;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.000664267507068017, my_classifier__n_estimators=22;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.000664267507068017, my_classifier__n_estimators=22;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00013058726221074277, my_classifier__n_estimators=24;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00013058726221074277, my_classifier__n_estimators=24;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00013058726221074277, my_classifier__n_estimators=24;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001537334293833218, my_classifier__n_estimators=34;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001537334293833218, my_classifier__n_estimators=34;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001537334293833218, my_classifier__n_estimators=34;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0005266700578835828, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0005266700578835828, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0005266700578835828, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0006963650815855674, my_classifier__n_estimators=43;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0006963650815855674, my_classifier__n_estimators=43;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0006963650815855674, my_classifier__n_estimators=43;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0008428655819539998, my_classifier__n_estimators=48;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0008428655819539998, my_classifier__n_estimators=48;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0008428655819539998, my_classifier__n_estimators=48;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009962085076589688, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009962085076589688, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009962085076589688, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010168656016574205, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010168656016574205, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010168656016574205, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010704467835215944, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010704467835215944, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010704467835215944, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.000993577237315663, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.000993577237315663, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.000993577237315663, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010227994628856795, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010227994628856795, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010227994628856795, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009961084983615802, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009961084983615802, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009961084983615802, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00011072761604759568, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00011072761604759568, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00011072761604759568, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.000994420609296708, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.000994420609296708, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.000994420609296708, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010099727205414025, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010099727205414025, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010099727205414025, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00011086734659523257, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00011086734659523257, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00011086734659523257, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010760010882270039, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010760010882270039, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010760010882270039, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009987692627540675, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009987692627540675, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009987692627540675, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001046566595129296, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001046566595129296, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001046566595129296, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.000998581894045286, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.000998581894045286, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.000998581894045286, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001155900651080181, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001155900651080181, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001155900651080181, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009897668730308334, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009897668730308334, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009897668730308334, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010209937153623034, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010209937153623034, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010209937153623034, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009998768309657162, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009998768309657162, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009998768309657162, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010024495006603115, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010024495006603115, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010024495006603115, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010272072031020133, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010272072031020133, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010272072031020133, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009987359592576303, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009987359592576303, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009987359592576303, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009997622639227163, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009997622639227163, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009997622639227163, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010083402201227817, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010083402201227817, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010083402201227817, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010494036508294667, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010494036508294667, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010494036508294667, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0009977101541728635, my_classifier__n_estimators=50;, score=(train=0.889, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0009977101541728635, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0009977101541728635, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.0001, my_classifier__n_estimators=20;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__learning_rate=0.00010080379391125091, my_classifier__n_estimators=50;, score=(train=0.750, test=0.500) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__learning_rate=0.00010080379391125091, my_classifier__n_estimators=50;, score=(train=1.000, test=0.400) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__learning_rate=0.00010080379391125091, my_classifier__n_estimators=50;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "best score 0.5222222222222223\n",
            "best score OrderedDict([('my_classifier__learning_rate', 0.0009347720373534687), ('my_classifier__n_estimators', 36)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_ADA_CV3_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQUVILCSK-ZT",
        "outputId": "9ced5aa4-2ba1-4a2d-c7dc-1efff5be9642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5454545454545454"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV = 5 PCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', XGBClassifier(objective='binary:logistic', seed=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(10,100),\n",
        "    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "\n",
        "bayes_search_XGB_PC5 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_XGB_PC5.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_XGB_PC5.best_score_))\n",
        "print('best score {}'.format(bayes_search_XGB_PC5.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOOvAjj7LQWq",
        "outputId": "439dea55-a85d-41f9-e722-277c69079b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.800, test=0.800) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.800, test=0.800) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7044009407172488;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7044009407172488;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7044009407172488;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7044009407172488;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7044009407172488;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8962023461778487;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8962023461778487;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8962023461778487;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8962023461778487;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8962023461778487;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7014391086619107;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7014391086619107;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7014391086619107;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7014391086619107;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7014391086619107;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.8985377781302781;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.8985377781302781;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.8985377781302781;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.8985377781302781;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.8985377781302781;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8987810757653747;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8987810757653747;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8987810757653747;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8987810757653747;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8987810757653747;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8989908717718388;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8989908717718388;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8989908717718388;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8989908717718388;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8989908717718388;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7022054000062525;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7022054000062525;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7022054000062525;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7022054000062525;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7022054000062525;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8990657877994086;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8990657877994086;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8990657877994086;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8990657877994086;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8990657877994086;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8997152711810135;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8997152711810135;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8997152711810135;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8997152711810135;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8997152711810135;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8984253813642871;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8984253813642871;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8984253813642871;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8984253813642871;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8984253813642871;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7014135094527317;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7014135094527317;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7014135094527317;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7014135094527317;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.7014135094527317;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.7852845258643264;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.7852845258643264;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.7852845258643264;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.7852845258643264;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.7852845258643264;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=50, pca__n_components=0.8644123581566416;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=50, pca__n_components=0.8644123581566416;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=50, pca__n_components=0.8644123581566416;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=50, pca__n_components=0.8644123581566416;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=50, pca__n_components=0.8644123581566416;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7011585196463116;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7011585196463116;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7011585196463116;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7011585196463116;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7011585196463116;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.8971788955105525;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.8971788955105525;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.8971788955105525;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.8971788955105525;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.8971788955105525;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.895513564828782;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.895513564828782;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.895513564828782;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.895513564828782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.895513564828782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.701451778065156;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.701451778065156;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.701451778065156;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.701451778065156;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.701451778065156;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.700110792104161;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.700110792104161;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.700110792104161;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.700110792104161;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.700110792104161;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.8960757977351306;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.8960757977351306;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.8960757977351306;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.8960757977351306;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.8960757977351306;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.800, test=0.800) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.909, test=0.000) total time=   0.1s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=98, pca__n_components=0.7000441380444967;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=98, pca__n_components=0.7000441380444967;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=98, pca__n_components=0.7000441380444967;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=98, pca__n_components=0.7000441380444967;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=98, pca__n_components=0.7000441380444967;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.899626566368207;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.899626566368207;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.899626566368207;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.899626566368207;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=99, pca__n_components=0.899626566368207;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7012358738662229;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7012358738662229;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7012358738662229;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7012358738662229;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7012358738662229;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.8992116099232161;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.8992116099232161;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.8992116099232161;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.8992116099232161;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.8992116099232161;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=61, pca__n_components=0.809155781415445;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=61, pca__n_components=0.809155781415445;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=61, pca__n_components=0.809155781415445;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=61, pca__n_components=0.809155781415445;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=61, pca__n_components=0.809155781415445;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8994631648133902;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8994631648133902;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8994631648133902;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8994631648133902;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8994631648133902;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.8161491261977474;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.8161491261977474;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.8161491261977474;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.8161491261977474;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.8161491261977474;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.7169245941957146;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.7169245941957146;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.7169245941957146;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.7169245941957146;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.7169245941957146;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "best score 0.5866666666666667\n",
            "best score OrderedDict([('my_classifier__max_depth', 15), ('my_classifier__n_estimators', 84), ('pca__n_components', 0.8245419505258874)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_XGB_PC5.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otqvv4AALlYu",
        "outputId": "d0e429be-06e2-405a-e39b-b68e44a1dfef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV = 5 NOPCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', XGBClassifier(objective='binary:logistic', seed=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(10,100),\n",
        "    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n",
        "}\n",
        "\n",
        "\n",
        "bayes_search_XGB_PC5_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_XGB_PC5_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_XGB_PC5_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_XGB_PC5_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtBhFmYGLn1Z",
        "outputId": "aa076a67-f04a-4159-8e22-c1389291c25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=39;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=39;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=39;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=39;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=39;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=64;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=64;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=64;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=64;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=64;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=35;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=35;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=35;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=35;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=35;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=85;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=85;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=85;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=85;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=34;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=34;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=34;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=34;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=34;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=45;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=45;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=45;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=45;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=45;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=27;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=27;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=27;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=27;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=27;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=67;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=67;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=67;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=67;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=67;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=75;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=75;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=75;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=75;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=75;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=53;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=42;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=42;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=42;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=42;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=42;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=13, my_classifier__n_estimators=64;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=13, my_classifier__n_estimators=64;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=13, my_classifier__n_estimators=64;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=13, my_classifier__n_estimators=64;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=13, my_classifier__n_estimators=64;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=26;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=26;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=26;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=26;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=26;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=18, my_classifier__n_estimators=68;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=18, my_classifier__n_estimators=68;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=18, my_classifier__n_estimators=68;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=18, my_classifier__n_estimators=68;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=18, my_classifier__n_estimators=68;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=88;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=88;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=88;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=88;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=47;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=47;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=47;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=47;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=47;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=21;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=21;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=21;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=21;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=21;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=36;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=36;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=36;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=36;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=36;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=19, my_classifier__n_estimators=85;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=19, my_classifier__n_estimators=85;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=19, my_classifier__n_estimators=85;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=19, my_classifier__n_estimators=85;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=19, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=17, my_classifier__n_estimators=78;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=17, my_classifier__n_estimators=78;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=17, my_classifier__n_estimators=78;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=17, my_classifier__n_estimators=78;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=17, my_classifier__n_estimators=78;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=12, my_classifier__n_estimators=49;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=12, my_classifier__n_estimators=49;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=12, my_classifier__n_estimators=49;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=12, my_classifier__n_estimators=49;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=12, my_classifier__n_estimators=49;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=16, my_classifier__n_estimators=100;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=16, my_classifier__n_estimators=100;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=16, my_classifier__n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=16, my_classifier__n_estimators=100;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=16, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=22;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=22;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=22;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=22;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=22;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=11, my_classifier__n_estimators=10;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=11, my_classifier__n_estimators=10;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=11, my_classifier__n_estimators=10;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=11, my_classifier__n_estimators=10;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=11, my_classifier__n_estimators=10;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=29;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=29;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=29;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=29;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=29;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=59;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=59;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=59;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=59;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=59;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=93;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=93;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=93;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=93;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=73;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=73;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=73;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=73;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=73;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=55;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=55;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=55;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=55;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=55;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=43;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=43;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=43;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=43;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=43;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=89;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=89;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=89;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=89;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=89;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=38;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=38;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=38;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=38;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=38;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=62;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=62;, score=(train=0.800, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=62;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=62;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=62;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "best score 0.5866666666666667\n",
            "best score OrderedDict([('my_classifier__max_depth', 15), ('my_classifier__n_estimators', 71)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_XGB_PC5_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEnOhnRlLu5w",
        "outputId": "02a0246e-1595-419f-d918-56fa68c41324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV = 8 PCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', XGBClassifier(objective='binary:logistic', seed=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(10,100),\n",
        "    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "\n",
        "bayes_search_XGB_CV8 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_XGB_CV8.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_XGB_CV8.best_score_))\n",
        "print('best score {}'.format(bayes_search_XGB_CV8.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fokp-5HYLq29",
        "outputId": "48392302-75ff-4775-dfe3-c8e594d3382c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=0.667) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=86, pca__n_components=0.8864290643127976;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=77, pca__n_components=0.7173204892043838;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.707123916649506;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=53, pca__n_components=0.8972405177888545;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=99, pca__n_components=0.701800835352026;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8925650611368203;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8996390118873411;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=97, pca__n_components=0.8101218910019214;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.714857553010786;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=95, pca__n_components=0.7749285002094874;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=52, pca__n_components=0.8937618615384348;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8979649735776576;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.8473978876622478;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=53, pca__n_components=0.7007516976962;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8993245208842198;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7053748800684027;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=100, pca__n_components=0.7015143531500203;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=66, pca__n_components=0.848070512613704;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8899890488906312;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8986937899978424;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8975077316354252;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.701366454848588;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=91, pca__n_components=0.754843803442169;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8999486073073497;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=99, pca__n_components=0.7620056539313693;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=56, pca__n_components=0.774418723913394;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=96, pca__n_components=0.8180210321449234;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.8969632132509147;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.898260396963737;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=76, pca__n_components=0.8874425274402985;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.8977889854667127;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.824, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7052985443546025;, score=(train=0.769, test=0.000) total time=   0.0s\n",
            "best score 0.4583333333333333\n",
            "best score OrderedDict([('my_classifier__max_depth', 15), ('my_classifier__n_estimators', 84), ('pca__n_components', 0.8245419505258874)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_XGB_CV8.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdNLLdmULvZg",
        "outputId": "1b01365d-c383-44d0-8bb6-ef62b2575780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV = 8 PCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', XGBClassifier(objective='binary:logistic', seed=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(10,100),\n",
        "    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n",
        "}\n",
        "\n",
        "\n",
        "bayes_search_XGB_CV8_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_XGB_CV8_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_XGB_CV8_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_XGB_CV8_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2wEX2D1bREL",
        "outputId": "bfacb61f-62d4-4fd4-efe6-9238d05e702b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=85;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=93;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=15, my_classifier__n_estimators=89;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=16, my_classifier__n_estimators=94;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=41;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=96;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=97;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=82;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=85;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=14, my_classifier__n_estimators=100;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=12, my_classifier__n_estimators=88;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=40;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=17, my_classifier__n_estimators=92;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=88;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=81;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=30;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=76;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=24;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=83;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=66;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=46;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=86;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=11, my_classifier__n_estimators=87;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=95;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=90;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=36;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=84;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=80;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=54;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=20, my_classifier__n_estimators=82;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=97;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=90;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.833, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.824, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.875, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__max_depth=10, my_classifier__n_estimators=95;, score=(train=0.933, test=1.000) total time=   0.0s\n",
            "best score 0.8333333333333333\n",
            "best score OrderedDict([('my_classifier__max_depth', 13), ('my_classifier__n_estimators', 98)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_XGB_CV8_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSdmcjiubYDJ",
        "outputId": "9fabba05-db10-4228-eab9-a5e70c778239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV = 3  \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA(n_components = 0.9)),\n",
        "        ('my_classifier', XGBClassifier(objective='binary:logistic', seed=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(50,100),\n",
        "    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "\n",
        "bayes_search_XGB_PC3 = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=100, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_XGB_PC3.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_XGB_PC3.best_score_))\n",
        "print('best score {}'.format(bayes_search_XGB_PC3.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjINeRPULryw",
        "outputId": "16de92a9-349a-4a7e-9124-d419afa9a4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.769, test=0.857) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.769, test=0.857) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=84, pca__n_components=0.8245419505258874;, score=(train=0.857, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.769, test=0.857) total time=   0.1s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.769, test=0.857) total time=   0.1s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8816876747339949;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=53, pca__n_components=0.7684566898329397;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=89, pca__n_components=0.7939888080725834;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=62, pca__n_components=0.845636237836225;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=100, pca__n_components=0.8466813406745768;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=88, pca__n_components=0.7853764973307044;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8443554715972069;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=95, pca__n_components=0.8586964092132908;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=72, pca__n_components=0.7523477549625519;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7010332422349467;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.7003786061583768;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.7003786061583768;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.7003786061583768;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=95, pca__n_components=0.8584166499858901;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=55, pca__n_components=0.7159047940302226;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=100, pca__n_components=0.7893175151099356;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8950234011682322;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7088511393970062;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7088511393970062;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7088511393970062;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=78, pca__n_components=0.8056140362751241;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=64, pca__n_components=0.724928134513401;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=77, pca__n_components=0.7515142735318782;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.7082563082852908;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=58, pca__n_components=0.7554879558126228;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=95, pca__n_components=0.8819067331827566;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8972235955768834;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8972235955768834;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=52, pca__n_components=0.8972235955768834;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=78, pca__n_components=0.7583623064052701;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=62, pca__n_components=0.8633441194001559;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=84, pca__n_components=0.8068299269759227;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=94, pca__n_components=0.7716385736347207;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=63, pca__n_components=0.8900546975255069;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=81, pca__n_components=0.7572884300823254;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=90, pca__n_components=0.7727841135511178;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.700101203442657;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8956880658186571;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8956880658186571;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.8956880658186571;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=74, pca__n_components=0.7980669935420452;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=76, pca__n_components=0.8394370057900642;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=75, pca__n_components=0.715623052502831;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=69, pca__n_components=0.8541798882566715;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=96, pca__n_components=0.8177451521622612;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7038047948153369;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7038047948153369;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7038047948153369;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=79, pca__n_components=0.8318102457970072;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.864101673315425;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=75, pca__n_components=0.7279084022218196;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8783791577453727;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=73, pca__n_components=0.7427756861032938;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=89, pca__n_components=0.7544833844480411;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7025908580164909;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7025908580164909;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7025908580164909;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7059912674080359;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7059912674080359;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=51, pca__n_components=0.7059912674080359;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=59, pca__n_components=0.7700043214732297;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=83, pca__n_components=0.7158802623487941;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=99, pca__n_components=0.8317348276383094;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=81, pca__n_components=0.8293854811352876;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=59, pca__n_components=0.7634059051257215;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=66, pca__n_components=0.771733291977297;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8937076797167096;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8937076797167096;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8937076797167096;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=85, pca__n_components=0.8371425603586672;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=56, pca__n_components=0.8307372716810562;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=79, pca__n_components=0.7373947862535265;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=80, pca__n_components=0.7926291823500831;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=61, pca__n_components=0.7886626429157079;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.7074367049159012;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8991780283374787;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8991780283374787;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100, pca__n_components=0.8991780283374787;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8973602937181298;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8973602937181298;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.8973602937181298;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=73, pca__n_components=0.8076441491732568;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=93, pca__n_components=0.7123405637317881;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=68, pca__n_components=0.8916500127053925;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=84, pca__n_components=0.8140973613502192;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=92, pca__n_components=0.8626109934673344;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=85, pca__n_components=0.8593768411836087;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=85, pca__n_components=0.8593768411836087;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=85, pca__n_components=0.8593768411836087;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7004832057105381;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7004832057105381;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.7004832057105381;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=74, pca__n_components=0.810054758807614;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=63, pca__n_components=0.7830879043003387;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=82, pca__n_components=0.7699622475144087;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=83, pca__n_components=0.7396942921810606;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=74, pca__n_components=0.7045403900306638;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=87, pca__n_components=0.8410706678966726;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8947801768421983;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8947801768421983;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=51, pca__n_components=0.8947801768421983;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=92, pca__n_components=0.7567548263794402;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=98, pca__n_components=0.8517334600664167;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=61, pca__n_components=0.7119927151731421;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=83, pca__n_components=0.8154518703281413;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=52, pca__n_components=0.8022448715431404;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7058404027695787;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7058404027695787;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=50, pca__n_components=0.7058404027695787;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=83, pca__n_components=0.8267132832194539;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=59, pca__n_components=0.7817546059149911;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=92, pca__n_components=0.871640778778933;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=65, pca__n_components=0.8568402176195901;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=53, pca__n_components=0.8887561767290391;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=74, pca__n_components=0.7360062967570514;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100, pca__n_components=0.7;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=78, pca__n_components=0.776542990668382;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=69, pca__n_components=0.8788616345081348;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=81, pca__n_components=0.7184453474285639;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "best score 0.7936507936507936\n",
            "best score OrderedDict([('my_classifier__max_depth', 15), ('my_classifier__n_estimators', 84), ('pca__n_components', 0.8245419505258874)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_XGB_PC3.score(X_test,y_test)\n",
        "y_score\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyB0bxEYLv3s",
        "outputId": "0819e270-debf-41cd-b1cf-b3b865a67714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV = 3 NOPCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('my_classifier', XGBClassifier(objective='binary:logistic', seed=1)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__n_estimators': Integer(10,100),\n",
        "    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n",
        "}\n",
        "\n",
        "\n",
        "bayes_search_XGB_CV3_NOPCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_XGB_CV3_NOPCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_XGB_CV3_NOPCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_XGB_CV3_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jnzdoPeLrYl",
        "outputId": "5a03b57e-ba2f-4e13-bc29-61d76669ebad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=71;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=98;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=15;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=80;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=32;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=18, my_classifier__n_estimators=99;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=78;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=57;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=91;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=50;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=11;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=11;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=11;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=21;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=21;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=21;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=32;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=32;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=32;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=80;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=80;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=80;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=22;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=22;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=22;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=13;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=13;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=13;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=61;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=15;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=15;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=15;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=11, my_classifier__n_estimators=28;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=11, my_classifier__n_estimators=28;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=11, my_classifier__n_estimators=28;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=87;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=87;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=87;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=55;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=55;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=55;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=93;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=93;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=93;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=70;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=70;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=70;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=13, my_classifier__n_estimators=93;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=29;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=29;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=29;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=14, my_classifier__n_estimators=66;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=14, my_classifier__n_estimators=66;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=14, my_classifier__n_estimators=66;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=81;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=81;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=81;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=84;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=98;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=98;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=98;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=15, my_classifier__n_estimators=48;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=15, my_classifier__n_estimators=48;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=15, my_classifier__n_estimators=48;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=89;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=89;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=89;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=17, my_classifier__n_estimators=91;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=17, my_classifier__n_estimators=91;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=17, my_classifier__n_estimators=91;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=75;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=75;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=50;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=50;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=50;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=16, my_classifier__n_estimators=60;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=16, my_classifier__n_estimators=60;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=16, my_classifier__n_estimators=60;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=19, my_classifier__n_estimators=72;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=19, my_classifier__n_estimators=72;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=19, my_classifier__n_estimators=72;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=12, my_classifier__n_estimators=72;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=12, my_classifier__n_estimators=72;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=12, my_classifier__n_estimators=72;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.769, test=0.857) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "best score 0.7936507936507936\n",
            "best score OrderedDict([('my_classifier__max_depth', 15), ('my_classifier__n_estimators', 71)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_XGB_CV3_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piJHVw1aLwpk",
        "outputId": "64750c1a-186b-4c3e-ca41-844cc8caf98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import NuSVC\n",
        "\n",
        "#NuSVC CV = 5 NOPCA\n",
        "\n",
        "model = NuSVC(class_weight='balanced',nu = 0.5, kernel = 'linear')\n",
        "\n",
        "param_grid = {\n",
        "    'nu' : Real(0.2,0.5,'log-uniform',transform = 'normalize',dtype = 'float'),\n",
        "    'kernel' : Categorical(['linear', 'poly' ,'rbf'])\n",
        "}\n",
        "\n",
        "bayes_search_SVC_5_NOPCA = BayesSearchCV(\n",
        "     model,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_SVC_5_NOPCA.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(bayes_search_SVC_5_NOPCA.best_score_))\n",
        "print('best n_neighbors selection {}'.format(bayes_search_SVC_5_NOPCA.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeQFlNfNWBww",
        "outputId": "37aee811-5748-4072-ffb0-a9125ce00214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.3704829112916265;, score=(train=1.000, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.3704829112916265;, score=(train=0.818, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.3704829112916265;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.3704829112916265;, score=(train=0.900, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.3704829112916265;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.4955440720619276;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.4955440720619276;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.4955440720619276;, score=(train=0.957, test=0.400) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.4955440720619276;, score=(train=0.957, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.4955440720619276;, score=(train=0.960, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.2331718887428365;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.2331718887428365;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.2331718887428365;, score=(train=1.000, test=0.667) total time=   0.3s\n",
            "[CV 4/5] END kernel=linear, nu=0.2331718887428365;, score=(train=1.000, test=0.500) total time=   0.3s\n",
            "[CV 5/5] END kernel=linear, nu=0.2331718887428365;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.42663640463455665;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.42663640463455665;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.42663640463455665;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.42663640463455665;, score=(train=0.952, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.42663640463455665;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.2961501411611269;, score=(train=0.917, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.2961501411611269;, score=(train=0.952, test=0.667) total time=   0.1s\n",
            "[CV 3/5] END kernel=linear, nu=0.2961501411611269;, score=(train=0.909, test=0.400) total time=   0.1s\n",
            "[CV 4/5] END kernel=linear, nu=0.2961501411611269;, score=(train=0.952, test=0.500) total time=   0.1s\n",
            "[CV 5/5] END kernel=linear, nu=0.2961501411611269;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.35389843088991163;, score=(train=0.917, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.35389843088991163;, score=(train=0.952, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.35389843088991163;, score=(train=0.957, test=0.400) total time=   0.0s\n",
            "[CV 4/5] END kernel=linear, nu=0.35389843088991163;, score=(train=0.952, test=0.500) total time=   0.2s\n",
            "[CV 5/5] END kernel=linear, nu=0.35389843088991163;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.3757536163830176;, score=(train=0.917, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.3757536163830176;, score=(train=0.952, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.3757536163830176;, score=(train=0.957, test=0.400) total time=   0.1s\n",
            "[CV 4/5] END kernel=linear, nu=0.3757536163830176;, score=(train=0.909, test=0.857) total time=   0.2s\n",
            "[CV 5/5] END kernel=linear, nu=0.3757536163830176;, score=(train=0.960, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.43200850150477343;, score=(train=0.917, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.43200850150477343;, score=(train=0.952, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.43200850150477343;, score=(train=0.957, test=0.500) total time=   0.1s\n",
            "[CV 4/5] END kernel=linear, nu=0.43200850150477343;, score=(train=0.909, test=0.857) total time=   0.1s\n",
            "[CV 5/5] END kernel=linear, nu=0.43200850150477343;, score=(train=0.960, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.4245033477466001;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.4245033477466001;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.4245033477466001;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.4245033477466001;, score=(train=0.952, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.4245033477466001;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.43094048879800606;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.43094048879800606;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.43094048879800606;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.43094048879800606;, score=(train=0.900, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.43094048879800606;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.4848331535248018;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.4848331535248018;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.4848331535248018;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.4848331535248018;, score=(train=0.880, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.4848331535248018;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.20027798334343472;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.20027798334343472;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.20027798334343472;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.20027798334343472;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.20027798334343472;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.20000000000000004;, score=(train=1.000, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.20000000000000004;, score=(train=0.833, test=0.857) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.20000000000000004;, score=(train=0.353, test=0.500) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.20000000000000004;, score=(train=0.762, test=0.400) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.20000000000000004;, score=(train=0.667, test=0.800) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.3068825306047823;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.3068825306047823;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.3068825306047823;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.3068825306047823;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.3068825306047823;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.2532674058065803;, score=(train=1.000, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.2532674058065803;, score=(train=0.833, test=0.857) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.2532674058065803;, score=(train=0.400, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.2532674058065803;, score=(train=0.900, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.2532674058065803;, score=(train=0.833, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.29058394611280386;, score=(train=1.000, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.29058394611280386;, score=(train=0.870, test=0.857) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.29058394611280386;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.29058394611280386;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.29058394611280386;, score=(train=0.957, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.49248238868310085;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.49248238868310085;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.49248238868310085;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.49248238868310085;, score=(train=0.880, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.49248238868310085;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 4/5] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/5] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.3843970824201309;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.3843970824201309;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.3843970824201309;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.3843970824201309;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.3843970824201309;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.47056399331374815;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.47056399331374815;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.47056399331374815;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.47056399331374815;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.47056399331374815;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.22853468559101808;, score=(train=1.000, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.22853468559101808;, score=(train=0.880, test=0.857) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.22853468559101808;, score=(train=0.526, test=0.500) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.22853468559101808;, score=(train=0.667, test=0.400) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.22853468559101808;, score=(train=0.957, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.247852764271215;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.247852764271215;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.247852764271215;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.247852764271215;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.247852764271215;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.4228746654673362;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.4228746654673362;, score=(train=0.952, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.4228746654673362;, score=(train=0.957, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.4228746654673362;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.4228746654673362;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.48816692808592865;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.48816692808592865;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.48816692808592865;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.48816692808592865;, score=(train=0.880, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.48816692808592865;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.35020233373969356;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.35020233373969356;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.35020233373969356;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.35020233373969356;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.35020233373969356;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.496688670062649;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.496688670062649;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.496688670062649;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.496688670062649;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.496688670062649;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.5;, score=(train=0.917, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.5;, score=(train=0.900, test=0.857) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.5;, score=(train=0.909, test=0.500) total time=   0.0s\n",
            "[CV 4/5] END kernel=linear, nu=0.5;, score=(train=0.857, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=linear, nu=0.5;, score=(train=0.880, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.27265982593069826;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.27265982593069826;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.27265982593069826;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.27265982593069826;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.27265982593069826;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=linear, nu=0.261309663647916;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=linear, nu=0.261309663647916;, score=(train=0.952, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=linear, nu=0.261309663647916;, score=(train=0.952, test=0.667) total time=   0.1s\n",
            "[CV 4/5] END kernel=linear, nu=0.261309663647916;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/5] END kernel=linear, nu=0.261309663647916;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=rbf, nu=0.22519370576984632;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END kernel=rbf, nu=0.22519370576984632;, score=(train=1.000, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=rbf, nu=0.22519370576984632;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=rbf, nu=0.22519370576984632;, score=(train=1.000, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=rbf, nu=0.22519370576984632;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.45659177185273564;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.45659177185273564;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.45659177185273564;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.45659177185273564;, score=(train=0.818, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.45659177185273564;, score=(train=0.957, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.3240783279990688;, score=(train=1.000, test=0.333) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.3240783279990688;, score=(train=0.857, test=0.400) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.3240783279990688;, score=(train=0.333, test=0.800) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.3240783279990688;, score=(train=0.667, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.3240783279990688;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.44426785923137146;, score=(train=1.000, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.44426785923137146;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.44426785923137146;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.44426785923137146;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.44426785923137146;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END kernel=poly, nu=0.5;, score=(train=0.880, test=0.571) total time=   0.0s\n",
            "[CV 2/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END kernel=poly, nu=0.5;, score=(train=0.846, test=0.857) total time=   0.0s\n",
            "[CV 5/5] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "best score 0.7238095238095238\n",
            "best n_neighbors selection OrderedDict([('kernel', 'poly'), ('nu', 0.496688670062649)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_SVC_5_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fXCXJDTWWsR",
        "outputId": "6f807f59-396c-4223-e371-7809d8c5cb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NuSVC CV = 5 PCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA()),\n",
        "        ('my_classifier', NuSVC(class_weight='balanced',nu = 0.5, kernel = 'linear')),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__nu' : Real(0.2,0.5,'log-uniform',transform = 'normalize',dtype = 'float'),\n",
        "    'my_classifier__kernel' : Categorical(['linear', 'poly' ,'rbf']),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "bayes_search_SVC_5_PCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=5, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_SVC_5_PCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_SVC_5_PCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_SVC_5_PCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDQc0VvTVFmK",
        "outputId": "bafc1eba-b954-403d-8538-2557c22943f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.40003009529963934, pca__n_components=0.7853764973307044;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.40003009529963934, pca__n_components=0.7853764973307044;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.40003009529963934, pca__n_components=0.7853764973307044;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.40003009529963934, pca__n_components=0.7853764973307044;, score=(train=0.875, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.40003009529963934, pca__n_components=0.7853764973307044;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.000, test=0.000) total time=   2.0s\n",
            "[CV 2/5] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.000, test=0.000) total time=  12.0s\n",
            "[CV 4/5] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.000, test=0.000) total time=   2.4s\n",
            "[CV 5/5] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.750, test=0.667) total time=   2.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20206767031382425, pca__n_components=0.7872143378489563;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20206767031382425, pca__n_components=0.7872143378489563;, score=(train=0.833, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20206767031382425, pca__n_components=0.7872143378489563;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20206767031382425, pca__n_components=0.7872143378489563;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20206767031382425, pca__n_components=0.7872143378489563;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   2.1s\n",
            "[CV 2/5] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   2.8s\n",
            "[CV 4/5] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   0.8s\n",
            "[CV 5/5] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.824, test=0.667) total time=   4.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.21535842803685426, pca__n_components=0.8789514424005191;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.21535842803685426, pca__n_components=0.8789514424005191;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.21535842803685426, pca__n_components=0.8789514424005191;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.21535842803685426, pca__n_components=0.8789514424005191;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.21535842803685426, pca__n_components=0.8789514424005191;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.2604231663384996, pca__n_components=0.8167763123150735;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.2604231663384996, pca__n_components=0.8167763123150735;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.2604231663384996, pca__n_components=0.8167763123150735;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.2604231663384996, pca__n_components=0.8167763123150735;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.2604231663384996, pca__n_components=0.8167763123150735;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.32158565991907817, pca__n_components=0.7725488057223879;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.32158565991907817, pca__n_components=0.7725488057223879;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.32158565991907817, pca__n_components=0.7725488057223879;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.32158565991907817, pca__n_components=0.7725488057223879;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.32158565991907817, pca__n_components=0.7725488057223879;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.359704907242671, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.359704907242671, pca__n_components=0.9;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.359704907242671, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.359704907242671, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.359704907242671, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.26049061805244406, pca__n_components=0.9;, score=(train=0.923, test=0.800) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.26049061805244406, pca__n_components=0.9;, score=(train=0.909, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.26049061805244406, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.26049061805244406, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.26049061805244406, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4376529121313637, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4376529121313637, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4376529121313637, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4376529121313637, pca__n_components=0.7;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4376529121313637, pca__n_components=0.7;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.33870809305513416, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.33870809305513416, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.33870809305513416, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.33870809305513416, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.33870809305513416, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=linear, my_classifier__nu=0.5, pca__n_components=0.7767480154503362;, score=(train=0.444, test=0.000) total time=   1.8s\n",
            "[CV 2/5] END my_classifier__kernel=linear, my_classifier__nu=0.5, pca__n_components=0.7767480154503362;, score=(train=0.615, test=0.500) total time=   1.5s\n",
            "[CV 3/5] END my_classifier__kernel=linear, my_classifier__nu=0.5, pca__n_components=0.7767480154503362;, score=(train=0.667, test=0.000) total time=   5.8s\n",
            "[CV 4/5] END my_classifier__kernel=linear, my_classifier__nu=0.5, pca__n_components=0.7767480154503362;, score=(train=0.824, test=0.667) total time=   0.3s\n",
            "[CV 5/5] END my_classifier__kernel=linear, my_classifier__nu=0.5, pca__n_components=0.7767480154503362;, score=(train=0.750, test=0.000) total time=   1.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4211230819167013, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4211230819167013, pca__n_components=0.9;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4211230819167013, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4211230819167013, pca__n_components=0.9;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.4211230819167013, pca__n_components=0.9;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.20000000000000004, pca__n_components=0.7341753133141713;, score=(train=0.667, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.20000000000000004, pca__n_components=0.7341753133141713;, score=(train=0.500, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.20000000000000004, pca__n_components=0.7341753133141713;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.20000000000000004, pca__n_components=0.7341753133141713;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.20000000000000004, pca__n_components=0.7341753133141713;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.37549015027292143, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.37549015027292143, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.37549015027292143, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.37549015027292143, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.37549015027292143, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3745971164617385, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3745971164617385, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3745971164617385, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3745971164617385, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3745971164617385, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3583907942846123, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3583907942846123, pca__n_components=0.9;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3583907942846123, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3583907942846123, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3583907942846123, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3043047303928375, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3043047303928375, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3043047303928375, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3043047303928375, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3043047303928375, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.7674769311624857;, score=(train=0.667, test=0.800) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.7674769311624857;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.7674769311624857;, score=(train=0.000, test=0.000) total time=   6.0s\n",
            "[CV 4/5] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.7674769311624857;, score=(train=0.000, test=0.000) total time=   1.0s\n",
            "[CV 5/5] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.7674769311624857;, score=(train=0.222, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.45917787762740764, pca__n_components=0.9;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.45917787762740764, pca__n_components=0.9;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.45917787762740764, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.45917787762740764, pca__n_components=0.9;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.45917787762740764, pca__n_components=0.9;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.34656967361223456, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.34656967361223456, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.34656967361223456, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.34656967361223456, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.34656967361223456, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.42012276905484064, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.42012276905484064, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.42012276905484064, pca__n_components=0.7;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.42012276905484064, pca__n_components=0.7;, score=(train=0.800, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.42012276905484064, pca__n_components=0.7;, score=(train=0.933, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=poly, my_classifier__nu=0.5, pca__n_components=0.8989918052786634;, score=(train=0.286, test=0.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=poly, my_classifier__nu=0.5, pca__n_components=0.8989918052786634;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=poly, my_classifier__nu=0.5, pca__n_components=0.8989918052786634;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=poly, my_classifier__nu=0.5, pca__n_components=0.8989918052786634;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=poly, my_classifier__nu=0.5, pca__n_components=0.8989918052786634;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2926203905364645, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2926203905364645, pca__n_components=0.9;, score=(train=0.909, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2926203905364645, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2926203905364645, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2926203905364645, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.336371007481043, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.336371007481043, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.336371007481043, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.336371007481043, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.336371007481043, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3918257065574045, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3918257065574045, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3918257065574045, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3918257065574045, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3918257065574045, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3112436590976772, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3112436590976772, pca__n_components=0.9;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3112436590976772, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3112436590976772, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3112436590976772, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22776272712366585, pca__n_components=0.7;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22776272712366585, pca__n_components=0.7;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22776272712366585, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22776272712366585, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22776272712366585, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2225706389924855, pca__n_components=0.9;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2225706389924855, pca__n_components=0.9;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2225706389924855, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2225706389924855, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2225706389924855, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7149002539634896;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7149002539634896;, score=(train=0.833, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7149002539634896;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7149002539634896;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7149002539634896;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22548884269743116, pca__n_components=0.9;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22548884269743116, pca__n_components=0.9;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22548884269743116, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22548884269743116, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22548884269743116, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=linear, my_classifier__nu=0.40158702933828727, pca__n_components=0.7134491151040973;, score=(train=0.000, test=0.000) total time=   2.1s\n",
            "[CV 2/5] END my_classifier__kernel=linear, my_classifier__nu=0.40158702933828727, pca__n_components=0.7134491151040973;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 3/5] END my_classifier__kernel=linear, my_classifier__nu=0.40158702933828727, pca__n_components=0.7134491151040973;, score=(train=0.667, test=0.000) total time=  13.0s\n",
            "[CV 4/5] END my_classifier__kernel=linear, my_classifier__nu=0.40158702933828727, pca__n_components=0.7134491151040973;, score=(train=0.000, test=0.000) total time=   4.5s\n",
            "[CV 5/5] END my_classifier__kernel=linear, my_classifier__nu=0.40158702933828727, pca__n_components=0.7134491151040973;, score=(train=0.750, test=0.000) total time=   1.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22408194250030564, pca__n_components=0.7;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22408194250030564, pca__n_components=0.7;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22408194250030564, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22408194250030564, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22408194250030564, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2348775964443613, pca__n_components=0.9;, score=(train=0.400, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2348775964443613, pca__n_components=0.9;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2348775964443613, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2348775964443613, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.2348775964443613, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22484760328074777, pca__n_components=0.7;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22484760328074777, pca__n_components=0.7;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22484760328074777, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22484760328074777, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22484760328074777, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22486080552396615, pca__n_components=0.7;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22486080552396615, pca__n_components=0.7;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22486080552396615, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22486080552396615, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22486080552396615, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.21896982186750336, pca__n_components=0.7;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.21896982186750336, pca__n_components=0.7;, score=(train=0.833, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.21896982186750336, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.21896982186750336, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.21896982186750336, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22266576902592783, pca__n_components=0.7;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22266576902592783, pca__n_components=0.7;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22266576902592783, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22266576902592783, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22266576902592783, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22223541023840215, pca__n_components=0.7;, score=(train=0.444, test=0.500) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22223541023840215, pca__n_components=0.7;, score=(train=0.545, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22223541023840215, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22223541023840215, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22223541023840215, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.27505335238125783, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.27505335238125783, pca__n_components=0.7;, score=(train=0.909, test=0.800) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.27505335238125783, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.27505335238125783, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.27505335238125783, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=linear, my_classifier__nu=0.23828761610358973, pca__n_components=0.7057474443488324;, score=(train=0.667, test=1.000) total time=   0.1s\n",
            "[CV 2/5] END my_classifier__kernel=linear, my_classifier__nu=0.23828761610358973, pca__n_components=0.7057474443488324;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=linear, my_classifier__nu=0.23828761610358973, pca__n_components=0.7057474443488324;, score=(train=0.667, test=0.000) total time=  54.0s\n",
            "[CV 4/5] END my_classifier__kernel=linear, my_classifier__nu=0.23828761610358973, pca__n_components=0.7057474443488324;, score=(train=0.000, test=0.000) total time=   2.8s\n",
            "[CV 5/5] END my_classifier__kernel=linear, my_classifier__nu=0.23828761610358973, pca__n_components=0.7057474443488324;, score=(train=0.462, test=0.667) total time=   0.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.30468376701196875, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.30468376701196875, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.30468376701196875, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.30468376701196875, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.30468376701196875, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3045333202719916, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3045333202719916, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3045333202719916, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3045333202719916, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3045333202719916, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3044985110197201, pca__n_components=0.7;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3044985110197201, pca__n_components=0.7;, score=(train=0.909, test=1.000) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3044985110197201, pca__n_components=0.7;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3044985110197201, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.3044985110197201, pca__n_components=0.7;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22024301397235502, pca__n_components=0.9;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22024301397235502, pca__n_components=0.9;, score=(train=0.833, test=0.500) total time=   0.0s\n",
            "[CV 3/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22024301397235502, pca__n_components=0.9;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 4/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22024301397235502, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 5/5] END my_classifier__kernel=rbf, my_classifier__nu=0.22024301397235502, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "best score 0.8333333333333333\n",
            "best score OrderedDict([('my_classifier__kernel', 'rbf'), ('my_classifier__nu', 0.22776272712366585), ('pca__n_components', 0.7)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_SVC_5_PCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w6dULy4XrO7",
        "outputId": "fc80c492-3a58-4ab3-d726-5ab520513f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NuSVC CV = 8 NOPCA\n",
        "\n",
        "model = NuSVC(class_weight='balanced',nu = 0.5, kernel = 'linear')\n",
        "\n",
        "param_grid = {\n",
        "    'nu' : Real(0.2,0.5,'log-uniform',transform = 'normalize',dtype = 'float'),\n",
        "    'kernel' : Categorical(['linear', 'poly' ,'rbf'])\n",
        "}\n",
        "\n",
        "bayes_search_SVC_8_NOPCA = BayesSearchCV(\n",
        "     model,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_SVC_8_NOPCA.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(bayes_search_SVC_8_NOPCA.best_score_))\n",
        "print('best n_neighbors selection {}'.format(bayes_search_SVC_8_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDAyYvN-ZYFm",
        "outputId": "5f139528-7b5f-4966-842b-4e05a9ed23de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.23566488453292525;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.870, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.833, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.870, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.889, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.49272328119561565;, score=(train=0.867, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=0.909, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.3481750362638874;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.857, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.917, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.917, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.963, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.47103145268742025;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.24257072381034062;, score=(train=1.000, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END kernel=linear, nu=0.24257072381034062;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.24257072381034062;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.24257072381034062;, score=(train=0.957, test=0.500) total time=   0.1s\n",
            "[CV 5/8] END kernel=linear, nu=0.24257072381034062;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.24257072381034062;, score=(train=0.957, test=0.667) total time=   0.1s\n",
            "[CV 7/8] END kernel=linear, nu=0.24257072381034062;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.24257072381034062;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.957, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.880, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.46321831564589266;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.870, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.870, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.870, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.700, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.36831919558308945;, score=(train=0.880, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.818, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.917, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.917, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.963, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.45791121804792323;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.923, test=0.667) total time=   0.2s\n",
            "[CV 2/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.909, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.960, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.960, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.39190745781014663;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.200931966653085;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.846, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.800, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.769, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.200931966653085;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.3430579129469865;, score=(train=0.222, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.3430579129469865;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.3430579129469865;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.3430579129469865;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.3430579129469865;, score=(train=0.909, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.3430579129469865;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.3430579129469865;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.3430579129469865;, score=(train=0.963, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.34015926040597066;, score=(train=0.870, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.34015926040597066;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.34015926040597066;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.34015926040597066;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.34015926040597066;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.34015926040597066;, score=(train=0.957, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.34015926040597066;, score=(train=0.960, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.34015926040597066;, score=(train=0.818, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.870, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.3457704123293845;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.870, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.880, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.3457704123293845;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.923, test=0.667) total time=   0.1s\n",
            "[CV 2/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.909, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.960, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.960, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.3713212927085405;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=0.870, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.36617288986258834;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.4974476239936241;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.49361024807430637;, score=(train=0.963, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.3728260721078499;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.3728260721078499;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.3728260721078499;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.3728260721078499;, score=(train=0.917, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.3728260721078499;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.3728260721078499;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.3728260721078499;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.3728260721078499;, score=(train=0.963, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.917, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.960, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.917, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.870, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.762, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.917, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.3644607989592228;, score=(train=0.917, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.923, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.4871246896161165;, score=(train=0.929, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.957, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.48176866841729565;, score=(train=0.929, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=1.000) total time=   0.1s\n",
            "[CV 7/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.20001463697928487;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.846, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.727, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.667, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.769, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.815, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.20001463697928487;, score=(train=0.800, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.880, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.20451300992085897;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.846, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.750, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.696, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.769, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.20451300992085897;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.4978412563810605;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.20030143269509004;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.857, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.957, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.880, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.923, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.880, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.963, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=rbf, nu=0.4957868634853888;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.957, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.960, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.46023318119625656;, score=(train=0.880, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=1.000) total time=   0.1s\n",
            "[CV 7/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.20002055737298433;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.923, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.909, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.46732346000853847;, score=(train=0.846, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.265623940061799;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.265623940061799;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.265623940061799;, score=(train=0.833, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.265623940061799;, score=(train=0.727, test=0.500) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.265623940061799;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.265623940061799;, score=(train=0.833, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.265623940061799;, score=(train=0.846, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.265623940061799;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.960, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.833, test=0.800) total time=   0.0s\n",
            "[CV 4/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.870, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.846, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END kernel=linear, nu=0.46687364893315575;, score=(train=0.929, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 2/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.500) total time=   0.0s\n",
            "[CV 4/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 5/8] END kernel=poly, nu=0.5;, score=(train=0.857, test=0.800) total time=   0.0s\n",
            "[CV 6/8] END kernel=poly, nu=0.5;, score=(train=0.870, test=0.667) total time=   0.0s\n",
            "[CV 7/8] END kernel=poly, nu=0.5;, score=(train=0.963, test=0.667) total time=   0.0s\n",
            "[CV 8/8] END kernel=poly, nu=0.5;, score=(train=0.889, test=0.667) total time=   0.0s\n",
            "best score 0.7041666666666666\n",
            "best n_neighbors selection OrderedDict([('kernel', 'poly'), ('nu', 0.3430579129469865)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_SVC_8_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GhOaaUjZaY0",
        "outputId": "a9f01c2c-813e-43dd-dbad-3b2a0eea7fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NuSVC CV = 8 PCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA()),\n",
        "        ('my_classifier', NuSVC(class_weight='balanced',nu = 0.5, kernel = 'linear')),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__nu' : Real(0.2,0.5,'log-uniform',transform = 'normalize',dtype = 'float'),\n",
        "    'my_classifier__kernel' : Categorical(['linear', 'poly' ,'rbf']),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "bayes_search_SVC_8_PCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=8, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_SVC_8_PCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_SVC_8_PCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_SVC_8_PCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOksn4ZCZgt7",
        "outputId": "41a03450-7d98-46c9-bc86-f8c7bad04e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=poly, my_classifier__nu=0.2993620021083836, pca__n_components=0.7523477549625519;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=poly, my_classifier__nu=0.348353829123697, pca__n_components=0.7496313711057576;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.364, test=0.000) total time=  31.9s\n",
            "[CV 2/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.222, test=1.000) total time=  13.6s\n",
            "[CV 7/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.444, test=1.000) total time=  16.7s\n",
            "[CV 8/8] END my_classifier__kernel=linear, my_classifier__nu=0.37201924427576755, pca__n_components=0.7732618183441322;, score=(train=0.727, test=0.000) total time=   6.1s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.500, test=0.000) total time=   5.2s\n",
            "[CV 2/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   0.5s\n",
            "[CV 3/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 4/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.714, test=1.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.364, test=1.000) total time=   1.5s\n",
            "[CV 7/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.444, test=1.000) total time=  12.6s\n",
            "[CV 8/8] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.727, test=0.000) total time=   5.6s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=poly, my_classifier__nu=0.32910530793966164, pca__n_components=0.8379282690407952;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=poly, my_classifier__nu=0.3970491264431018, pca__n_components=0.7883440420645156;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.615, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.21108528850371838, pca__n_components=0.8411631660519387;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31212981224043507, pca__n_components=0.8424823985954504;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.250, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.600, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=poly, my_classifier__nu=0.271049915060292, pca__n_components=0.7601449957349671;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.750, test=0.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7019813704438387;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8199732199069144;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.832706741658308;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.843371836381046;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20740723087177712, pca__n_components=0.7994333817993573;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.796356033048267;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4961694499292719, pca__n_components=0.7978890852228002;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8414087381564431;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3941116170152597, pca__n_components=0.8999431099869072;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4759798809990799, pca__n_components=0.8997116517488631;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.500, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.615, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.714, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.8433740307298799;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4512396775173964, pca__n_components=0.7001117753079258;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.933, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.4274210087651428, pca__n_components=0.7000063168605171;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3050712744854081, pca__n_components=0.8231950511822596;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3018256939999028, pca__n_components=0.8314366292370973;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3089958865362934, pca__n_components=0.8993890896273842;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29991801365995113, pca__n_components=0.8258501587737537;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.31725881416234936, pca__n_components=0.7842430970103429;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.3027087893531382, pca__n_components=0.899608917505673;, score=(train=0.923, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2915346718564165, pca__n_components=0.8417092229834138;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.000, test=0.000) total time=   1.5s\n",
            "[CV 3/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.000, test=0.000) total time=   0.2s\n",
            "[CV 4/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 5/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.000, test=0.000) total time=  19.5s\n",
            "[CV 7/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.727, test=1.000) total time=   1.7s\n",
            "[CV 8/8] END my_classifier__kernel=linear, my_classifier__nu=0.20021073749632334, pca__n_components=0.7097825673196336;, score=(train=0.600, test=0.000) total time=   2.2s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.400, test=0.000) total time=   0.1s\n",
            "[CV 2/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.000, test=0.000) total time=   0.1s\n",
            "[CV 3/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.000, test=0.000) total time=   0.8s\n",
            "[CV 5/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.533, test=1.000) total time=   0.4s\n",
            "[CV 6/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.833, test=0.000) total time=   4.8s\n",
            "[CV 7/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.444, test=1.000) total time=   1.9s\n",
            "[CV 8/8] END my_classifier__kernel=linear, my_classifier__nu=0.4991134184256476, pca__n_components=0.8961586460191353;, score=(train=0.727, test=0.000) total time=   4.3s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24658571066032858, pca__n_components=0.8454718159483787;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24903547950651087, pca__n_components=0.7666527073979608;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24283606849836012, pca__n_components=0.8922094601441124;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.769, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2497789039580291, pca__n_components=0.7896212998950844;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24831814699971133, pca__n_components=0.7955803249356973;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24763075146302915, pca__n_components=0.7945063990788193;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.24740538960302325, pca__n_components=0.797150113274132;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.27353380680589356, pca__n_components=0.7;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.25862849290892453, pca__n_components=0.7356129488980396;, score=(train=0.444, test=0.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.29090476483302724, pca__n_components=0.8040881661172554;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2885177221016778, pca__n_components=0.8025447629356942;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.833, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2853106978832991, pca__n_components=0.8019622660038171;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.2805485866127784, pca__n_components=0.8029500456726875;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "[CV 1/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.857, test=1.000) total time=   0.0s\n",
            "[CV 2/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 3/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 4/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.923, test=0.667) total time=   0.0s\n",
            "[CV 5/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 6/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 7/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "[CV 8/8] END my_classifier__kernel=rbf, my_classifier__nu=0.274063257414377, pca__n_components=0.8061409667854883;, score=(train=0.923, test=1.000) total time=   0.0s\n",
            "best score 0.7916666666666666\n",
            "best score OrderedDict([('my_classifier__kernel', 'rbf'), ('my_classifier__nu', 0.2915346718564165), ('pca__n_components', 0.8417092229834138)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_SVC_8_PCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBhtmPUKZTE1",
        "outputId": "e0dfe800-5d8c-4a9e-f562-9c7f5b3dd06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NuSVC CV = 3 NOPCA\n",
        "\n",
        "model = NuSVC(class_weight='balanced',nu = 0.5, kernel = 'linear')\n",
        "\n",
        "param_grid = {\n",
        "    'nu' : Real(0.2,0.5,'log-uniform',transform = 'normalize',dtype = 'float'),\n",
        "    'kernel' : Categorical(['linear', 'poly' ,'rbf'])\n",
        "}\n",
        "\n",
        "bayes_search_SVC_3_NOPCA = BayesSearchCV(\n",
        "     model,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_SVC_3_NOPCA.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(bayes_search_SVC_3_NOPCA.best_score_))\n",
        "print('best n_neighbors selection {}'.format(bayes_search_SVC_3_NOPCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le58vNHUZt4e",
        "outputId": "482f8b79-3d49-4fe1-e85a-3b9c69ab63a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2175469409638954;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2175469409638954;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2175469409638954;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.3918954836538337;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.3918954836538337;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.3918954836538337;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.33431349450532305;, score=(train=1.000, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.33431349450532305;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.33431349450532305;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.34973689876345804;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.34973689876345804;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.34973689876345804;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.3689180110424184;, score=(train=1.000, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.3689180110424184;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.3689180110424184;, score=(train=1.000, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.31535648296793484;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.31535648296793484;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.31535648296793484;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.44468885866011204;, score=(train=0.900, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.44468885866011204;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.44468885866011204;, score=(train=0.952, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.3401301051403318;, score=(train=1.000, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.3401301051403318;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.3401301051403318;, score=(train=0.800, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.4539174343814712;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.4539174343814712;, score=(train=0.900, test=0.600) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.4539174343814712;, score=(train=0.947, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.4269003978201798;, score=(train=0.900, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.4269003978201798;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.4269003978201798;, score=(train=0.952, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.20000000000000004;, score=(train=1.000, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.20000000000000004;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.20000000000000004;, score=(train=0.737, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.20086851898181474;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.20086851898181474;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.20086851898181474;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.24875301686302467;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.24875301686302467;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.24875301686302467;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2292617569482911;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2292617569482911;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2292617569482911;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.22372974287791858;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.22372974287791858;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.22372974287791858;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2994975810591369;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2994975810591369;, score=(train=0.947, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2994975810591369;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.20000000000000004;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.20000000000000004;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.20000000000000004;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.23890409264476503;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.23890409264476503;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.23890409264476503;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.21114248710432748;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.21114248710432748;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.21114248710432748;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.5;, score=(train=0.900, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.5;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.5;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2568869996713884;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2568869996713884;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2568869996713884;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.24198371086743203;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.24198371086743203;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.24198371086743203;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2631035536110464;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2631035536110464;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2631035536110464;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2177539619873645;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2177539619873645;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2177539619873645;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.21966770203665986;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.21966770203665986;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.21966770203665986;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.22042855116471216;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.22042855116471216;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.22042855116471216;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.20000000000000004;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.22200102383741302;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.22200102383741302;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.22200102383741302;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.22848896318482917;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.22848896318482917;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.22848896318482917;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.34985650587038947;, score=(train=0.900, test=0.727) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.34985650587038947;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.34985650587038947;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.21809053933109376;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.21809053933109376;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.21809053933109376;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.25307499480551054;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.25307499480551054;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.25307499480551054;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.24654310911135838;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.24654310911135838;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.24654310911135838;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.2452630909497456;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.2452630909497456;, score=(train=0.900, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.2452630909497456;, score=(train=0.842, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.5;, score=(train=0.900, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.5;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.5;, score=(train=0.909, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.257883952410841;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.257883952410841;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.257883952410841;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.23436480719554692;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.23436480719554692;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.23436480719554692;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2344067789489392;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2344067789489392;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2344067789489392;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.22982016949288553;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.22982016949288553;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.22982016949288553;, score=(train=0.778, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.4376776746839703;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.4376776746839703;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.4376776746839703;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.38795959634276794;, score=(train=0.900, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.38795959634276794;, score=(train=0.889, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.38795959634276794;, score=(train=0.952, test=0.444) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.31770746276212475;, score=(train=0.947, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.31770746276212475;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.31770746276212475;, score=(train=0.947, test=0.444) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=rbf, nu=0.22842367174517292;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 2/3] END kernel=rbf, nu=0.22842367174517292;, score=(train=1.000, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=rbf, nu=0.22842367174517292;, score=(train=1.000, test=0.727) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.2063879002028754;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.2063879002028754;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.2063879002028754;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=poly, nu=0.2907287557362326;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=poly, nu=0.2907287557362326;, score=(train=0.947, test=0.250) total time=   0.0s\n",
            "[CV 3/3] END kernel=poly, nu=0.2907287557362326;, score=(train=0.842, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.21400986200153915;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.21400986200153915;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.21400986200153915;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END kernel=linear, nu=0.25528081795849045;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "[CV 2/3] END kernel=linear, nu=0.25528081795849045;, score=(train=1.000, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END kernel=linear, nu=0.25528081795849045;, score=(train=1.000, test=0.600) total time=   0.0s\n",
            "best score 0.5666666666666668\n",
            "best n_neighbors selection OrderedDict([('kernel', 'linear'), ('nu', 0.2175469409638954)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = bayes_search_SVC_3_NOPCA.score(X_test,y_test)\n",
        "y_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uuxDxe7ZvFy",
        "outputId": "0c35bd05-44af-4438-8663-1b8f76ede831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9090909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NuSVC CV = 3 PCA \n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('pca', PCA()),\n",
        "        ('my_classifier', NuSVC(class_weight='balanced',nu = 0.5, kernel = 'linear')),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'my_classifier__nu' : Real(0.2,0.5,'log-uniform',transform = 'normalize',dtype = 'float'),\n",
        "    'my_classifier__kernel' : Categorical(['linear', 'poly' ,'rbf']),\n",
        "    'pca__n_components':Real(0.7,0.9)\n",
        "}\n",
        "\n",
        "bayes_search_SVC_3_PCA = BayesSearchCV(\n",
        "     full_pipline,param_grid, cv=3, verbose=3, n_jobs=1,n_iter=50, \n",
        "    scoring='f1',return_train_score=True)\n",
        "\n",
        "bayes_search_SVC_3_PCA.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search_SVC_3_PCA.best_score_))\n",
        "print('best score {}'.format(bayes_search_SVC_3_PCA.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGn8-MpTZhrF",
        "outputId": "5af67bbd-ef9d-44ba-93c3-170f978c0c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.37159433225223804, pca__n_components=0.8245419505258874;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.24995573169168192, pca__n_components=0.845636237836225;, score=(train=0.769, test=0.857) total time=  30.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.24995573169168192, pca__n_components=0.845636237836225;, score=(train=0.000, test=0.000) total time=   1.3s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.24995573169168192, pca__n_components=0.845636237836225;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.4546246031781005, pca__n_components=0.8586964092132908;, score=(train=0.769, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.4546246031781005, pca__n_components=0.8586964092132908;, score=(train=0.800, test=0.400) total time=   0.6s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.4546246031781005, pca__n_components=0.8586964092132908;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=0.600, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.2327670520691062, pca__n_components=0.8822246845208801;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.3754819336822684, pca__n_components=0.7129813122435253;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.3754819336822684, pca__n_components=0.7129813122435253;, score=(train=0.333, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.3754819336822684, pca__n_components=0.7129813122435253;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.3323826006616402, pca__n_components=0.8991112636363514;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.3323826006616402, pca__n_components=0.8991112636363514;, score=(train=1.000, test=0.000) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.3323826006616402, pca__n_components=0.8991112636363514;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.571, test=0.000) total time=  20.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.571, test=0.500) total time=   0.5s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.2924320268278183, pca__n_components=0.8826254131921564;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.39523848953359614, pca__n_components=0.8765402751194964;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.39523848953359614, pca__n_components=0.8765402751194964;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.39523848953359614, pca__n_components=0.8765402751194964;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.4573621655783073, pca__n_components=0.8119063716476298;, score=(train=0.769, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.4573621655783073, pca__n_components=0.8119063716476298;, score=(train=0.800, test=0.400) total time=   0.6s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.4573621655783073, pca__n_components=0.8119063716476298;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.571, test=0.000) total time=  20.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.571, test=0.500) total time=   0.8s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.31292143272200135, pca__n_components=0.8828473669216679;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.4728402662296233, pca__n_components=0.8209378236609094;, score=(train=0.769, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.4728402662296233, pca__n_components=0.8209378236609094;, score=(train=0.800, test=0.400) total time=   0.6s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.4728402662296233, pca__n_components=0.8209378236609094;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.49246504582957185, pca__n_components=0.7369617509026738;, score=(train=0.667, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.49246504582957185, pca__n_components=0.7369617509026738;, score=(train=0.333, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.49246504582957185, pca__n_components=0.7369617509026738;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.8164211928112188;, score=(train=0.769, test=0.857) total time=  29.4s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.8164211928112188;, score=(train=0.000, test=0.000) total time=   1.3s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.20000000000000004, pca__n_components=0.8164211928112188;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.4568186938533054, pca__n_components=0.8354963632593273;, score=(train=0.769, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.4568186938533054, pca__n_components=0.8354963632593273;, score=(train=0.800, test=0.400) total time=   0.6s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.4568186938533054, pca__n_components=0.8354963632593273;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.42983907233928526, pca__n_components=0.7701294843968379;, score=(train=0.545, test=0.667) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.42983907233928526, pca__n_components=0.7701294843968379;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.42983907233928526, pca__n_components=0.7701294843968379;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.4885488866867785, pca__n_components=0.8528907198067572;, score=(train=0.769, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.4885488866867785, pca__n_components=0.8528907198067572;, score=(train=0.800, test=0.400) total time=   0.6s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.4885488866867785, pca__n_components=0.8528907198067572;, score=(train=0.286, test=0.667) total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=poly, my_classifier__nu=0.4606605373304996, pca__n_components=0.9;, score=(train=0.667, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=poly, my_classifier__nu=0.4606605373304996, pca__n_components=0.9;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=poly, my_classifier__nu=0.4606605373304996, pca__n_components=0.9;, score=(train=0.000, test=0.000) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.3708056497785872, pca__n_components=0.8195682882980339;, score=(train=0.571, test=0.000) total time=   0.4s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.3708056497785872, pca__n_components=0.8195682882980339;, score=(train=0.889, test=0.400) total time=   0.8s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.3708056497785872, pca__n_components=0.8195682882980339;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.4788858291420359, pca__n_components=0.9;, score=(train=0.769, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.4788858291420359, pca__n_components=0.9;, score=(train=0.800, test=0.400) total time=   0.6s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.4788858291420359, pca__n_components=0.9;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=linear, my_classifier__nu=0.42699798704231523, pca__n_components=0.7;, score=(train=0.545, test=0.857) total time=   0.2s\n",
            "[CV 2/3] END my_classifier__kernel=linear, my_classifier__nu=0.42699798704231523, pca__n_components=0.7;, score=(train=0.000, test=0.000) total time=  11.5s\n",
            "[CV 3/3] END my_classifier__kernel=linear, my_classifier__nu=0.42699798704231523, pca__n_components=0.7;, score=(train=0.286, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20799798471152278, pca__n_components=0.8330213322211749;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20799798471152278, pca__n_components=0.8330213322211749;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20799798471152278, pca__n_components=0.8330213322211749;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22291513219449752, pca__n_components=0.8235260824487036;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22291513219449752, pca__n_components=0.8235260824487036;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22291513219449752, pca__n_components=0.8235260824487036;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.21532351125786467, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.21532351125786467, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.21532351125786467, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.21529840989846932, pca__n_components=0.7977143170055907;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.21529840989846932, pca__n_components=0.7977143170055907;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.21529840989846932, pca__n_components=0.7977143170055907;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.24738424781599072, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.24738424781599072, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.24738424781599072, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23449287121146326, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23449287121146326, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23449287121146326, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.24390064689423216, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.24390064689423216, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.24390064689423216, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3491927110692724, pca__n_components=0.8917574662827203;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3491927110692724, pca__n_components=0.8917574662827203;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3491927110692724, pca__n_components=0.8917574662827203;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22867627881049662, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22867627881049662, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22867627881049662, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.7055014723308066;, score=(train=0.889, test=1.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.7055014723308066;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.7055014723308066;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.45560627256627384, pca__n_components=0.9;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.45560627256627384, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.45560627256627384, pca__n_components=0.9;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22465513101829257, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22465513101829257, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.22465513101829257, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.27408669046829126, pca__n_components=0.7;, score=(train=0.889, test=0.500) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.27408669046829126, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.27408669046829126, pca__n_components=0.7;, score=(train=0.727, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.889, test=1.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23472954208267646, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23472954208267646, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23472954208267646, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2352792425971381, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2352792425971381, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2352792425971381, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3903428126597018, pca__n_components=0.7;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3903428126597018, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3903428126597018, pca__n_components=0.7;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23551892967700597, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23551892967700597, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.23551892967700597, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.889, test=1.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.9;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.7;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8029281729635566;, score=(train=0.889, test=1.000) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8029281729635566;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.5, pca__n_components=0.8029281729635566;, score=(train=0.857, test=0.667) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.49206681468877805, pca__n_components=0.8209907710391154;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.49206681468877805, pca__n_components=0.8209907710391154;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.49206681468877805, pca__n_components=0.8209907710391154;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2302487935091956, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2302487935091956, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2302487935091956, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2094286174767909, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2094286174767909, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2094286174767909, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.4275942757802052, pca__n_components=0.8907641946363601;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.4275942757802052, pca__n_components=0.8907641946363601;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.4275942757802052, pca__n_components=0.8907641946363601;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.20000000000000004, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2344826762075352, pca__n_components=0.9;, score=(train=0.909, test=0.857) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2344826762075352, pca__n_components=0.9;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.2344826762075352, pca__n_components=0.9;, score=(train=0.727, test=0.800) total time=   0.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3162581810882741, pca__n_components=0.8611190798984178;, score=(train=0.889, test=0.800) total time=   0.0s\n",
            "[CV 2/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3162581810882741, pca__n_components=0.8611190798984178;, score=(train=1.000, test=0.800) total time=   0.0s\n",
            "[CV 3/3] END my_classifier__kernel=rbf, my_classifier__nu=0.3162581810882741, pca__n_components=0.8611190798984178;, score=(train=0.923, test=0.500) total time=   0.0s\n",
            "best score 0.8222222222222223\n",
            "best score OrderedDict([('my_classifier__kernel', 'rbf'), ('my_classifier__nu', 0.5), ('pca__n_components', 0.7055014723308066)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lazy Predict"
      ],
      "metadata": {
        "id": "ghTkfGHo-TXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEJPt3lvUrUI",
        "outputId": "1fae4a0f-8a98-4fda-ba59-873d3c1d4c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (from lazypredict) (2.2.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from lazypredict) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from lazypredict) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from lazypredict) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from lazypredict) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from lazypredict) (4.64.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (from lazypredict) (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lightgbm->lazypredict) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightgbm->lazypredict) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->lazypredict) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->lazypredict) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lazypredict"
      ],
      "metadata": {
        "id": "EdXnXGWbUx6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lazypredict.Supervised import LazyClassifier"
      ],
      "metadata": {
        "id": "tyUBca8eU0ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print('\\n')\n",
        "print(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17BVdrMYU3Rg",
        "outputId": "3357eb96-9bd5-4494-edf8-df0ce7c4bd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 21.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
            "Model                                                                           \n",
            "GaussianNB                         0.56               0.67     0.67      0.53   \n",
            "QuadraticDiscriminantAnalysis      0.56               0.67     0.67      0.53   \n",
            "NearestCentroid                    0.56               0.67     0.67      0.53   \n",
            "LabelSpreading                     0.56               0.67     0.67      0.53   \n",
            "LabelPropagation                   0.56               0.67     0.67      0.53   \n",
            "NuSVC                              0.67               0.67     0.67      0.68   \n",
            "CalibratedClassifierCV             0.67               0.58     0.58      0.65   \n",
            "RidgeClassifierCV                  0.67               0.58     0.58      0.65   \n",
            "ExtraTreeClassifier                0.56               0.58     0.58      0.57   \n",
            "DummyClassifier                    0.67               0.50     0.50      0.53   \n",
            "SVC                                0.67               0.50     0.50      0.53   \n",
            "LGBMClassifier                     0.67               0.50     0.50      0.53   \n",
            "KNeighborsClassifier               0.56               0.42     0.42      0.48   \n",
            "BernoulliNB                        0.56               0.42     0.42      0.48   \n",
            "SGDClassifier                      0.33               0.42     0.42      0.30   \n",
            "RidgeClassifier                    0.33               0.42     0.42      0.30   \n",
            "RandomForestClassifier             0.44               0.42     0.42      0.46   \n",
            "LinearSVC                          0.33               0.42     0.42      0.30   \n",
            "PassiveAggressiveClassifier        0.33               0.42     0.42      0.30   \n",
            "BaggingClassifier                  0.44               0.42     0.42      0.46   \n",
            "ExtraTreesClassifier               0.44               0.42     0.42      0.46   \n",
            "LogisticRegression                 0.33               0.33     0.33      0.35   \n",
            "XGBClassifier                      0.33               0.33     0.33      0.35   \n",
            "Perceptron                         0.22               0.25     0.25      0.22   \n",
            "LinearDiscriminantAnalysis         0.22               0.25     0.25      0.22   \n",
            "DecisionTreeClassifier             0.22               0.25     0.25      0.22   \n",
            "AdaBoostClassifier                 0.22               0.25     0.25      0.22   \n",
            "\n",
            "                               Time Taken  \n",
            "Model                                      \n",
            "GaussianNB                           0.02  \n",
            "QuadraticDiscriminantAnalysis        0.02  \n",
            "NearestCentroid                      0.02  \n",
            "LabelSpreading                       0.02  \n",
            "LabelPropagation                     0.02  \n",
            "NuSVC                                0.02  \n",
            "CalibratedClassifierCV               0.08  \n",
            "RidgeClassifierCV                    0.02  \n",
            "ExtraTreeClassifier                  0.02  \n",
            "DummyClassifier                      0.02  \n",
            "SVC                                  0.02  \n",
            "LGBMClassifier                       0.02  \n",
            "KNeighborsClassifier                 0.02  \n",
            "BernoulliNB                          0.02  \n",
            "SGDClassifier                        0.02  \n",
            "RidgeClassifier                      0.02  \n",
            "RandomForestClassifier               0.28  \n",
            "LinearSVC                            0.03  \n",
            "PassiveAggressiveClassifier          0.02  \n",
            "BaggingClassifier                    0.06  \n",
            "ExtraTreesClassifier                 0.22  \n",
            "LogisticRegression                   0.03  \n",
            "XGBClassifier                        0.03  \n",
            "Perceptron                           0.02  \n",
            "LinearDiscriminantAnalysis           0.02  \n",
            "DecisionTreeClassifier               0.02  \n",
            "AdaBoostClassifier                   0.17  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}